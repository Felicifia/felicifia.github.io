<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Felicifia: global utilitarian discussion &bull; View topic - How Do You Argue With Libertarians and Anarcho-Capitalists</title>
        <script type="text/javascript" src="../styles/nexus/template/styleswitcher.js"></script>
        <script type="text/javascript" src="../styles/nexus/template/forum_fn.js"></script>
        <script type="text/javascript" src="../styles/custom.js"></script>
        <link href="../styles/nexus/theme/print.css" rel="stylesheet" type="text/css" media="print" title="printonly"/>
        <link href="../styles/prosilver.css" rel="stylesheet" type="text/css" media="screen, projection"/>
        <link href="../styles/nexus/theme/normal.css" rel="stylesheet" type="text/css" title="A"/>
        <link href="../styles/nexus/theme/medium.css" rel="alternate stylesheet" type="text/css" title="A+"/>
        <link href="../styles/nexus/theme/large.css" rel="alternate stylesheet" type="text/css" title="A++"/>
        <link href="../styles/custom.css" rel="stylesheet" type="text/css"/>
        <script type="text/javascript"><!--
            var spoiler_show = "[Reveal]";
            var spoiler_hide = "[Obscure]";
            //-->
        </script>
        <script type="text/javascript" src="../styles/nexus/template/prime_bbcode_spoiler.js"></script>
        <link href="../styles/nexus/theme/prime_bbcode_spoiler.css" rel="stylesheet" type="text/css"/>
    </head>
    <body id="phpbb" class="section-viewtopic ltr">
        <div id="mainframe">
        <div class="top-left"></div>
        <div class="top-middle"></div>
        <div class="top-right"></div>
        <div class="inner-wrap">
            <div class="positioncorrection-top">
                <div id="wrap">
                    <a id="top" name="top" accesskey="t"></a>
                    <div id="page-header">
                        <div class="headerbar">
                            <div class="inner">
                                <span class="corners-top"><span></span></span>
                                <div id="site-description">
                                    <a href="../forum/index.html" title="Board index" id="logo"><img src="../styles/nexus/imageset/simple%20logo.png" alt="" title="" width="766" height="126"></a>
                                    <p style="display: none;"><a href="#start_here">Skip to content</a></p>
                                </div>
                                <span class="corners-bottom"><span></span></span>
                            </div>
                        </div>
                        <div class="navbar">
                            <div class="inner">
                                <span class="corners-top"><span></span></span>
                                <ul class="linklist navlinks">
                                    <li class="icon-home"><a href="../forum/index.html" accesskey="h">Board index</a>  <strong>‹</strong> <a href="../forum/10.html">General discussion</a></li>
                                    <li class="rightside"><a href="#" onclick="fontsizeup(); return false;" onkeypress="fontsizeup(); return false;" class="fontsize" title="Change font size">Change font size</a></li>
                                </ul>
                                <span class="corners-bottom"><span></span></span>
                            </div>
                        </div>
                    </div>
                    <!--
                        <div class="google">

                        </div>
                        -->
                    <a name="start_here"></a>
                    <div id="page-body">
                        <h2><a href="#">How Do You Argue With Libertarians and Anarcho-Capitalists</a></h2>
                        <!-- NOTE: remove the style="display: none" when you want to have the forum description on the topic body --><span style="display: none">Whether it's pushpin, poetry or neither, you can discuss it here.<br></span>
                        <div class="topic-actions">
                            <div class="buttons">
                            </div>
                            <div class="pagination">
                                49 posts
                            </div>
                        </div>
                        <div class="clear"></div>
                        <div class="post bg2" id="p9003">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9003">How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-01-31T21:43:00</p>
<div class="content"><div class="postrev" data-snap="1">I don't know about you, but I've found that a lot of the political debates I end up having online tend to be with self-professed Libertarians and Anarcho-Capitalists.<br/><br/>I'm curious, how does a Utilitarian best go about countering the arguments of these folk?  I find that of all the other political and ethical philosophies that are around, the Libertarians and Anarcho-Capitalists, as well as the Objectivists and similar philosophies, tend to be the most logically structured, and at first glance, appear very challenging from an intellectual perspective.<br/><br/>Nevertheless, I noticed that fundamentally the arguments for these philosophies tend to be founded upon a base of either Natural Law Deontology, or Consequentialist Egoism.  In particular, it seems like their morality is almost diametrically opposed to Utilitarianism.  The Non-Aggression Principle (NAP) for instance, is often held up to be this axiom that is both self-evident, and also happens to generally produce the best consequences.  At first glance it is actually a very appealing idea that reminds one of John Stuart Mill's Harm principle.<br/><br/>And yet, when you get down to the details, NAP is actually quite immoral from a Utilitarian perspective.  In the case of the trolley problem for instance, NAP suggests that it doesn't matter if there are a million people tied to the track, flipping the switch to send the trolley down the track with only one person is aggression against that person and therefore wrong.<br/><br/>And yet, the Libertarians and Anarcho-Capitalists I've met have often bit the bullet and accepted this seemingly repugnant conclusion of NAP.  In fact, one friend of mine, who saw nothing wrong with someone monopolizing the water supply and selling bottles for $100 each, went so far as to claim that "we do not have any responsibility towards anyone else".  Another friend claimed to quote Heinlein when he said that, "The most important freedom is the freedom to starve.  Without that we are slaves."<br/><br/>How do you argue with a person who has this kind of mindset and morality?</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9003">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9004">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9004">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/59.html">DanielLC</a></strong> on 2014-02-01T04:37:00</p>
<div class="content"><div class="postrev" data-snap="1">I consider myself quasi-libertarian, and I base it solely on utilitarian principles.<br/><br/>I suggest a thought experiment where there are two countries: one obeys the NAP and the other does not. For the sake of argument, NAP is not producing the best outcomes, and life in that country sucks. Due to the NAP, they can't actually stop anyone from leaving. As a result, everyone does. Each individual does not like the country with NAP, so how is it good for them? If it is, does that mean that they acted immorally by acting in their own self-interest and leaving the NAP country?<br/><br/>Also, I'd point out that whether or not the NAP is moral for reasons unrelated to its consequences are completely irrelevant to whether or not its consequences are good, yet you always seem to end up with people who think it's moral and it produces the best consequences and people who think socialism is morally ideal for philosophical reasons and that it produces the best consequences, but nobody who thinks one is moral and the other has good consequences. That seems pretty suspicious.<br/><br/>I suppose I'm going to actually need someone to test it out. I don't get into those arguments much, since I'm not all that against their political beliefs and so the argument never really starts.</div><div class="diff hidden"></div></div>
<div class="signature">Consequentialism: The belief that doing the right thing makes the world a better place.</div>
</div>
<dl class="postprofile" id="profile9004">
<dt>
<a href="../user/59.html"></a><br/>
<a href="../user/59.html">DanielLC</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 703</dd>
<dd><strong>Joined:</strong> Fri Oct 10, 2008 4:29 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9005">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9005">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-01T20:20:00</p>
<div class="content"><div class="postrev" data-snap="1">Hi Daniel, I'm curious actually how you came to quasi-libertarian beliefs from utilitarian principles.<br/><br/>Your thought experiment is interesting.  Though I don't know if it would work on a die-hard libertarian.  They would probably dispute that NAP would not produce the best outcomes.  For them, it's like an article of faith that NAP would create the perfect world if only everyone followed it to the letter.<br/><br/>Isn't it the fundamental assumption of any sort of consequentalism that doing what is moral is the same as doing what will produce the best consequences?  Thus, perhaps both the followers of NAP and socialism are implicitly using consequentialist reasoning even when they claim otherwise.  The other thing to consider is that it is very unlikely anyone would want to hold onto a theory that was moral but had bad consequences (except perhaps Kantians), or was immoral but had supposedly good consequences (except perhaps... Nietzscheans? Social Darwinists?).<br/><br/>I suppose I should explain that I would consider myself a moderate liberal, and that I generally justify my political stance from utilitarian principles as well.  I have, in the past, considered libertarianism and even anarcho-capitalism in my search for the optimal political philosophy, and in the end, I chose against them primarily because I don't believe that such systems, actually implemented, would produce the greatest good.<br/><br/>Historically, many utilitarians such as Jeremy Bentham and John Stuart Mill were classical liberals.  This is not accidental.  Liberalism, like utilitarianism, was very much a product of the Enlightenment.  Many libertarians in fact, like to claim the influence of classical liberalism in the history of their philosophy, and it's arguable that many moderate libertarians are actually classical liberals.  So what happened that caused modern liberalism to diverge from classical liberalism?  Primarily it was the recognition that the market was not perfect, and that the state could be used for good.  The history of the Gilded Age and the later Great Depression showed that capitalism, while an effective creator of wealth, was not without its flaws.<br/><br/>A utilitarian justification for liberalism is actually quite simple.  Given that utilitarianism can be simply formulated as being about maximizing the happiness of everyone (or minimizing suffering), we ask, what enables people to best maximize their happiness?  The answer that both classical and modern liberals agree on, is liberty.  Freedom is essential to allowing people to make decisions and take actions that maximize their utility.  This, I think, libertarians and liberals agree on.  The difference between the two camps is a matter of asking, what is liberty?<br/><br/>There are two kinds of liberty.  Negative liberty, which entails the freedom from interference, is one that both libertarians and liberals agree on.  Positive liberty, which entails the freedom to be able to do things however, is where libertarians and liberals part ways.  Libertarians generally don't recognize positive liberty.  They exalt negative liberty, and question the existence of positive liberty.  But for a utilitarian, it is positive liberty that actually is required to maximize happiness.<br/><br/>Think of it this way.  An example of negative liberty is the freedom from being stopped from making a healthy income that can pay the cost of living.  An example of positive liberty is the freedom to actually be able to make that healthy income that can pay the cost of living.  The difference here is nuanced and important.  Negative liberty does not imply that you can actually achieve your goals.  For instance, no one right now is stopping you from making a billion dollars, so you have the negative liberty to do so.  But you probably don't have the positive liberty right now to make a billion dollars.  You don't have means by which to do so.<br/><br/>Modern liberalism thus is about balancing negative and positive liberty and trying to maximize both.  The consequences of being free from interference are generally considered good, but so are the consequences of being able to achieve one's potential and accomplish one's goals.<br/><br/>So what kind of society truly maximizes both negative and positive liberty?  What is wrong with the libertarian ideal of laissez-faire capitalism?  Fundamentally, it is that laissez-faire capitalism is only positive liberty maximizing if everyone begins as equals and have the same opportunities as everyone else.  Unfortunately, the reality is that some people are born into richer families or have better genetics.  Human beings are products of their genetics, experiences, and circumstances.  Some people have a higher IQ, because they won the genetic lottery.  Others have stronger family connections that allow them to establish themselves on the top of the pyramid of humanity so to speak.<br/><br/>The history of capitalism has shown that in the absence of some redistributive framework, the rich tend to get richer, and the poor tend to stay poor.  Given that the majority of humanity tends to be on the bottom end of this pyramid, it should be clear that pure capitalism is simply not utility maximizing, because of the diminishing marginal utility of wealth.  It has been shown in a number of psychology studies that money only buys happiness up to a certain point, where it provides for essential needs, after which diminishing returns make it less and less important to people's happiness.<br/><br/>From a utilitarian perspective then, some amount of redistribution is justified purely on the grounds that it will maximize utility.  How much redistribution is a very complex question, as too much redistribution is bound to reduce the incentive to work and cause the overall amount of wealth in the world to decrease.<br/><br/>There are other considerations that a utilitarian would use to justify modern liberalism as well.  For instance, modern liberal democracy is consistent with the utilitarian compromise of "the greatest good for the greatest number".  Ideally we want everyone to be happy, but given that this is not always possible (because rule by consensus is generally not feasible), democratic decision making is the next best thing.<br/><br/>Equality of opportunity is also a very useful principle, because it creates a more meritocratic society in which hard work, rather than the luck of birth can decide one's position within it.  Rewarding productivity creates more utility in general.  And fundamentally, equality of opportunity recognizes the basis of utilitarian thought.  Implicit within the whole notion of utilitarianism is that people should be treated as moral equals, that to be fair, each person counts for one and only one in the grand calculus of morality.<br/><br/>Wealth is a form of power.  Power is the capacity to achieve one's goals and thus, be happy.  Thus, as utilitarians, we should always be aware that unequal distributions of power mean unequal capacities to achieve happiness for oneself and others.  To maximize happiness, everyone should have enough power to achieve their goals.  This does not imply that we must all have equal power or equality of outcome as a socialist might suggest.  Rather, in combination with the aforementioned diminishing marginal utility of wealth, it means that we should look to create a system where everyone at least has a minimum threshold of power, and are protected from the abuse of power by others.<br/><br/>Also, I probably should mention externalities.  Externalities are when the market fails to factor into a transaction the cost or benefit to a third party outside the transaction.  The most obvious example is pollution, but it also includes things like the spillover effects of having an educated society, or roads.  There are many things that affect people not involved in the market transaction that produces it, which make the free market somewhat imperfect.<br/><br/>Another thing to consider is the Cultural Inheritance of Human Civilization.  None of us living today invented the wheel, writing, agriculture, and a host of other technologies that we take for granted but which we as individuals would not be able to benefit from were it not for the actions of our distant ancestors.  From a utilitarian perspective, we gain an enormous amount of utility from these actions, but have no way of directly paying back our now long-dead ancestors.  Such things could be described as the common intellectual property of human civilization, and we are all very lucky to have been born in this era, rather than say, a hundred thousand years ago when life for the average human was nasty, brutish, and short.  I say this mostly to counter the common image among conservatives and libertarians of the self-made man.  No one who actually spends time in civilization, can truly claim to be self-made.  As a utilitarian, it is important to realize that a great deal of utility comes from luck and outside sources beyond our control.<br/><br/>It is for these reasons, why I feel that modern liberalism is the most utility maximizing political philosophy.  Modern liberalism tries to control for luck and outside influences.  It attempts to create a fair playing field for everyone, and grant them moral equality.  And it recognizes the need to balance redistribution with wealth generation.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9005">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9006">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9006">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/59.html">DanielLC</a></strong> on 2014-02-02T06:54:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>Hi Daniel, I'm curious actually how you came to quasi-libertarian beliefs from utilitarian principles.</div></blockquote><br/><br/>A lot of what separates me from most people isn't how much I think the government should interfere, but how it should interfere. Whenever I've seen libertarian stuff, they always would talk about things like how price caps cause shortages. As such, I feel like libertarianism is as much about particular ways that the government shouldn't interfere as it is about that it should avoid interfering in general.<br/><br/>One interesting thing is that I'm against minimum wage. It's a price floor, and has all the associated problems. I am pretty much okay with just giving everyone money though, which I think is generally considered much more on the liberal side.<br/><br/>I do think the government should try not to interfere, if only because it's a Schelling point. You can go crazy with too many taxes or too many subsidies, but doing nothing can only be so extreme.<br/><br/>I also am generally against the government doing things directly. For example, instead of the government building roads, I'd prefer them to hire the lowest bidder (that can fulfill certain quality standards).<br/><br/>I am not against child labor. More accurately, while I would suggest setting things up in such a way that children don't need to work, you shouldn't actively stop them. If you failed and they're desperate enough that working is the better alternative, then don't force them to take the worse one. I also would say this about quite a few similar regulations. If you're so desperate for a job that you'll take a dangerous one, or your company is so desperate for a worker that they'll pay you enough to make it worth your while, I'm not going to stop you.<br/><br/>It's possible I'm being too loose with the terminology. Perhaps I'm better off just talking about my beliefs more in-depth, rather than attempting to classify them.<br/><br/><blockquote class="uncited"><div>They would probably dispute that NAP would not produce the best outcomes.</div></blockquote><br/><br/>That makes it a heck of a lot easier to argue. Economics is the dismal science, but it's still science. They're arguing a question of fact. That I can handle. What's impossible is arguing values.<br/><br/>If someone gets a monopoly on water, and sells it for $100 a bottle, that is clearly not the best outcome. In fact, they could just not sell them, and let everyone die of thirst, and it would still follow NAP.<br/><br/>There's also times where it's clearly not feasible. Your air is on your property. You own it. If I toss a can of mustard gas in there, that's a clear violation of the NAP. If I drive a car near your home, some carbon monoxide will mix with your air. It's a much lower scale, but it's the same violation. If I light a match on the other side of the world, it still applies. Or even if I breathe, for that matter. At some point, we have to just let people poison the air. At some point before that, we should probably let them, but tax them for it.<br/><br/><blockquote class="uncited"><div>The difference between the two camps is a matter of asking, what is liberty?</div></blockquote><br/><br/>I've seen that question come up too many times. I recommend just <a class="postlink" href="http://wiki.lesswrong.com/wiki/Rationalist_taboo">tabooing</a> "liberty" and "freedom".</div><div class="diff hidden"></div></div>
<div class="signature">Consequentialism: The belief that doing the right thing makes the world a better place.</div>
</div>
<dl class="postprofile" id="profile9006">
<dt>
<a href="../user/59.html"></a><br/>
<a href="../user/59.html">DanielLC</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 703</dd>
<dd><strong>Joined:</strong> Fri Oct 10, 2008 4:29 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9007">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9007">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-02T18:00:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>A lot of what separates me from most people isn't how much I think the government should interfere, but how it should interfere. Whenever I've seen libertarian stuff, they always would talk about things like how price caps cause shortages. As such, I feel like libertarianism is as much about particular ways that the government shouldn't interfere as it is about that it should avoid interfering in general.</div></blockquote><br/><br/>That actually has a lot in common with liberalism as well, and is arguably a place where libertarians and liberals will agree.  Whereas a hard-core socialist would want the government to take control of everything, a liberal recognizes that there are places where the government will do more good by leaving things alone.  I'm actually quite sympathetic to the moderate libertarian position that things like price caps and unnecessary interference are bad, and liberalism is pragmatic enough to accept such facts.  I'm more opposed to the ideological libertarianism that argues that all government is intrinsically bad.<br/><br/>Though, I'm a Canadian liberal, and here in Canada, our version of liberalism is seen as a relatively centrist viewpoint.<br/><br/><blockquote class="uncited"><div>One interesting thing is that I'm against minimum wage. It's a price floor, and has all the associated problems. I am pretty much okay with just giving everyone money though, which I think is generally considered much more on the liberal side.</div></blockquote><br/><br/>That's actually quite a similar position to Milton Friedman, who advocated against the minimum wage, and saw a guaranteed minimum income as a good idea.  I personally am ambivalent about the minimum wage.  I see it as somewhat necessary in a society without a basic income or guaranteed minimum income, but I would do away with it if we could have basic income or guaranteed minimum income.<br/><br/><blockquote class="uncited"><div>I do think the government should try not to interfere, if only because it's a Schelling point. You can go crazy with too many taxes or too many subsidies, but doing nothing can only be so extreme.<br/><br/>I also am generally against the government doing things directly. For example, instead of the government building roads, I'd prefer them to hire the lowest bidder (that can fulfill certain quality standards).</div></blockquote><br/><br/>I think as a utilitarian, we should leave our options open in terms of whether or not something should be procured or serviced publicly or privately.  If it can be done better with the private option, we should certainly take advantage of that, but there are some things that are morally more just when implemented by the government, such as health care and education.  But outside of these essentials to equality of opportunity, or public goods, I think it is usually better to limit government involvement as a heuristic.<br/><br/><blockquote class="uncited"><div>I am not against child labor. More accurately, while I would suggest setting things up in such a way that children don't need to work, you shouldn't actively stop them. If you failed and they're desperate enough that working is the better alternative, then don't force them to take the worse one. I also would say this about quite a few similar regulations. If you're so desperate for a job that you'll take a dangerous one, or your company is so desperate for a worker that they'll pay you enough to make it worth your while, I'm not going to stop you.</div></blockquote><br/><br/>I think there are moral grounds to opposing child labour.  Children are not sufficiently developed intellectually to be able to make rational judgments about these kinds of things, and often, it is actually the parents who push them into working.  Also, it is arguable that using childhood as a time to educate them is going to have better consequences in the long run, as an educated population tends to be able to make better decisions and be more productive as adults.  While I will agree that there are a lot of stupid regulations that are unnecessary, I would argue that regulations with good long term consequences should be kept.<br/><br/>Part of the reason why I think regulations that libertarians would consider "paternalistic" are acceptable, is because I know, as someone who's studied Cognitive Science, that human beings are not perfectly rational.  Herbert Simon came up with the notion of "Bounded Rationality" as a way of understanding how human beings actually behave.  In essence, human rationality is limited by the computational power of the mind, their biases, and their emotions.  Thus, it is quite common for people to make foolish decisions that do not maximize their actual utility.  Thus, if we as utilitarians are concerned about maximizing everyone's utility, then we must accept that occasionally we must regulate against certain biases or stupid behaviours.<br/><br/>I think one of the biases of many libertarians (as well as rationalists in general) is that, as a lot of libertarians (and rationalists) are of above average IQ, they assume that everyone else is able to think as rationally as themselves, or that stupid people deserve to be punished for their stupidity.  But the reality is that human beings are born into the world in a state of total ignorance, and must struggle to learn the truth in a world filled with biases, lies, and propaganda.  A strong example of this is the tobacco industry.  If it wasn't for government intervention, the tobacco industry would have continued to run propaganda claiming that there was no link between tobacco and cancer.  At least some percentage of the population would have believed them and made bad decisions as a result.  Strictly speaking, those decisions would have been "free choices of a rational individual", but they would have been flawed nevertheless because they were based on false information.<br/><br/>The idea that the market will somehow bring justice in the long run by punishing corporations and individuals that lie and use deceptive practices has, in my humble opinion, never been proven.  Otherwise, many corporations that currently exist, should have gone out of business long ago.  The reality is sadly, that the truth is often very uncertain, and entities, whether businesses or corrupt governments, or even mere individuals, can all take advantage of people's gullibility by being deceptive in ways that actually hurt people.  If it were otherwise, then the market of ideas would have long ago eliminated the more destructive belief systems out there, but instead we tend to see a proliferation of all sorts of ideas, religions, and conspiracy theories.  People tend to believe self-serving biases, rather than the actual truth.  But this does not mean that they deserve their fate.  Utilitarianism cares about the happiness even of those who are lost in their biases and belief systems.<br/><br/>It can perhaps be argued that we should let people who make bad decisions suffer so as to punish these bad decisions and reinforce good decisions, but this essentially means we are sacrificing these people's immediate happiness for some hypothetical future happiness.  Such decisions should always be carefully considered.  Maximizing utility requires a nuanced approach.  Too much interference in people's lives, and they will never learn between good and bad choices, but too little interference, and people may die or suffer horrendously.  Thus, we need to find the right balance between the two extremes to truly maximize utility in the long run.<br/><br/><blockquote class="uncited"><div>I've seen that question come up too many times. I recommend just tabooing "liberty" and "freedom".</div></blockquote><br/><br/>I find that, outside of the Less Wrong community, the notion of tabooing words is not a particularly popular one.  Words like "liberty" and "freedom", not only have emotional content that make people quite attached to them, but people tend to see such words as representing some symbolic ideal that stands for a very particular notion, and tabooing such words, to them at least, feels like a kind of censorship of ideas.  I will admit that forcing people to actually explain what they mean by such words is useful, but I think the more common philosophical method of requesting people define such terms carefully in their argument is less obtrusive.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9007">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9010">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9010">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/59.html">DanielLC</a></strong> on 2014-02-03T02:26:00</p>
<div class="content"><div class="postrev" data-snap="1">Should we make a new thread? This is turning into an interesting discussion that's unrelated to the original post.<br/><br/><blockquote class="uncited"><div>If it can be done better with the private option, we should certainly take advantage of that,</div></blockquote><br/><br/>I don't believe either option is intrinsically better, but I believe that the private option is usually better.<br/><br/>More precisely, I think that the government is uniformly bad at everything, whereas the market is good at most things, but extremely bad at others.<br/><br/><blockquote class="uncited"><div>but there are some things that are morally more just when implemented by the government, such as health care and education.</div></blockquote><br/><br/>Why do you say that?<br/><br/>I get the impression that people consider it unjust for the rich to get better healthcare than the poor. It's certainly unfair. But it's also unfair that the rich get better cars and better houses. If we made everything fair, then they wouldn't be rich. We have decided that it is a good idea to let more productive people get better stuff in order to incentivise people to be more productive. I don't see why it would be different with health care and education.<br/><br/>Education is particularly problematic, since the government has a tendency to give the same education to everyone, even though different people need different education. There are even jobs that require virtually no education, but they still require a high school diploma, just because the only reason you wouldn't have one in this cultural climate is that you're lazy, and they do require that you're not lazy.<br/><br/><blockquote class="uncited"><div>Thus, if we as utilitarians are concerned about maximizing everyone's utility, then we must accept that occasionally we must regulate against certain biases or stupid behaviours.</div></blockquote><br/><br/>True, but I think it should be pointed out that the people writing the laws are not above bias. For example, everything I've seen said that that there's little to no correlation between how illegal a drug is and how dangerous it is. It's not a question of having the government decide or let the individuals be idiots. It's a question of letting the government be idiots or letting the individuals be idiots. I'm against letting the government decide unless you can give me good evidence that they're less idiotic.<br/><br/><blockquote class="uncited"><div>The idea that the market will somehow bring justice in the long run by punishing corporations and individuals that lie and use deceptive practices has, in my humble opinion, never been proven.</div></blockquote><br/><br/>I am in favor of it being illegal to outright lie about that stuff. Being deceptive is too hard to measure, and all I can really do is hope people figure out that if an advertisement is being vague, then it's meaningless.<br/><br/><blockquote class="uncited"><div>I find that, outside of the Less Wrong community, the notion of tabooing words is not a particularly popular one. </div></blockquote><br/><br/>For what it's worth, I tabooed those words before I even heard of Less Wrong.</div><div class="diff hidden"></div></div>
<div class="signature">Consequentialism: The belief that doing the right thing makes the world a better place.</div>
</div>
<dl class="postprofile" id="profile9010">
<dt>
<a href="../user/59.html"></a><br/>
<a href="../user/59.html">DanielLC</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 703</dd>
<dd><strong>Joined:</strong> Fri Oct 10, 2008 4:29 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9017">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9017">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-03T22:00:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>How do you argue with a person who has this kind of mindset and morality?</div></blockquote><br/><br/>I don't think you can. Unless someone rejects an ethical view because of misconceptions they hold about it or what it entails, people are unlikely to change their mind about anything based on what anyone else has to say about it. If people influence other people to change their position on something, the influence will probably be emotional and not logical (if it is logical, I think they have to have some kind of emotional investment in being or being seen as a logical thinker). <br/><br/><blockquote class="uncited"><div>I consider myself quasi-libertarian, and I base it solely on utilitarian principles.</div></blockquote><br/><br/>I can understand a utilitarian argument for regulated or unregulated capitalism but only to the extent that I can understand a utilitarian argument for promoting ethical views other than utilitarianism. I'm willing to take seriously that utilitarianism can justify promoting non-utilitarian philosophies within limit (at the very least I think a utilitarian should always discourage sadism and cruelty and promote compassion for all beings and some degree of altruism if not H.U as an explicit value monist and completely agent neutral ethical philosophy but I still think promoting H.U explicitly is the best way to maximize happiness/minimize suffering on a wide scale and in the long run ).If someone wants to persuade other moral agents to adopt utilitarianism, I think they have to favor an eventual transition to a global communist society, even if some other system is what works now in practice in a world of primarily non-utilitarians. I agree with libertarians that the NAP is a good general rule to follow but libertarianism is about more than just minimizing government (which someone could argue for on a utilitarian basis), a utilitarian has to be willing to employ violence or the threat of violence for reasons other than defending autonomy or property in at least some scenarios which means that a utilitarians can't really be 'libertarians' any more than they can be pacifists. For now, in practice, I think regulated capitalism and a welfare state with as little restriction of personal autonomy as possible is what works but I think an eventual global communist economy and the kind of culture needed to facilitate it should be promoted.<br/><br/><blockquote class="uncited"><div> For instance, modern liberal democracy is consistent with the utilitarian compromise of "the greatest good for the greatest number"</div></blockquote><br/><br/>Not that I consider myself to be a practicing utilitarian, but I think the 'greatest happiness' principle is better ; it's the felt amount of happiness and suffering that matters (in my belief) and not the number of people who experience happiness or pain. That might be splitting hairs but I think it makes a difference. Also, democracy may be what works but I don't favor it in principle. I don't think moral equality (everyone having the same moral status and their interests being given equal consideration) necessarily implies political equality.<br/><br/><blockquote class="uncited"><div> As a utilitarian, it is important to realize that a great deal of utility comes from luck and outside sources beyond our control.</div></blockquote><br/><br/>That's true and it's relevant to which policies a utilitarian should support but why is that important for utilitarians specifically to realize? (Hedonistic) utilitarians care unconditionally about happiness and suffering, if people had unlimited control over how well-off they were but for some unusual reason some people chose or allowed themselves to not be better off, utilitarians wouldn't give their interests less consideration.<br/><br/><blockquote class="uncited"><div> It attempts to create a fair playing field for everyone</div></blockquote><br/><br/>I don't think utilitarians should care directly about 'fairness'. If there's any truth to Jonathon Haidt's claims about political psychology (I'm not convinced that there is) than hedonistic utilitarianism can be considered liberalism without the concern for fairness (he argues that liberal morality involves harm/care and fairness whereas conservative morality involves those 2 principles as well as in-group loyalty, respect to authority and purity/sanctity -I think this is based on disgust based gut responses, like sexually promiscuous women being 'dirty' and libertarian morality revolves around autonomy - he also claims libertarians have , on average, the lowest empathy).</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9017">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9019">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9019">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-04T01:10:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>I can understand a utilitarian argument for regulated or unregulated capitalism but only to the extent that I can understand a utilitarian argument for promoting ethical views other than utilitarianism. I'm willing to take seriously that utilitarianism can justify promoting non-utilitarian philosophies within limit (at the very least I think a utilitarian should always discourage sadism and cruelty and promote compassion for all beings and some degree of altruism if not H.U as an explicit value monist and completely agent neutral ethical philosophy but I still think promoting H.U explicitly is the best way to maximize happiness/minimize suffering on a wide scale and in the long run ).If someone wants to persuade other moral agents to adopt utilitarianism, I think they have to favor an eventual transition to a global communist society, even if some other system is what works now in practice in a world of primarily non-utilitarians. I agree with libertarians that the NAP is a good general rule to follow but libertarianism is about more than just minimizing government (which someone could argue for on a utilitarian basis), a utilitarian has to be willing to employ violence or the threat of violence for reasons other than defending autonomy or property in at least some scenarios which means that a utilitarians can't really be 'libertarians' any more than they can be pacifists. For now, in practice, I think regulated capitalism and a welfare state with as little restriction of personal autonomy as possible is what works but I think an eventual global communist economy and the kind of culture needed to facilitate it should be promoted.</div></blockquote><br/><br/>I'm of the opinion that Utilitarians shouldn't necessarily commit to a particular political ideology except for pragmatic reasons.    I like liberalism because it has worked very well historically.  Most of the ideas, like democracy, individuals rights, and the welfare state have become so successful that very few people argue about whether or not to implement them.  Communism on the other hand, I very much question because all historical experiments with it have generally been less successful.  And I don't just mean the "communist" states like the Soviet Union but actual implementations like the Israeli Kibbutz.  I think the problem with Communism, like Libertarianism, is that it tries to glorify one aspect of human nature, and suppress all the others.  Whereas Libertarianism glorifies self-interest, Communism glorifies altruism.  They're both Utopian ideologies that have yet to live up to their claims.  In practice, a reasonable society should allow all aspects of human nature to benefit everyone.  Thus, a society that includes a free market can benefit from self-interest, and a society that also has public elements can benefit from altruism.<br/><br/>Pure global communism I just don't see working out.  More than just the culture would have to change.  You would probably have to fundamentally change human nature.<br/><br/><blockquote class="uncited"><div>Not that I consider myself to be a practicing utilitarian, but I think the 'greatest happiness' principle is better ; it's the felt amount of happiness and suffering that matters (in my belief) and not the number of people who experience happiness or pain. That might be splitting hairs but I think it makes a difference. Also, democracy may be what works but I don't favor it in principle. I don't think moral equality (everyone having the same moral status and their interests being given equal consideration) necessarily implies political equality.</div></blockquote><br/><br/>I kind of assumed that the "Greatest Good for the Greatest Number" and the "Greatest Happiness Principle" were basically equivalent.  The "Greatest Good" means to maximize the overall amount of happiness.  The "Greatest Number" part just is more of an admission that we may have to compromise and not everyone will be happier off, so to speak.<br/><br/>To me, democracy is a compromise, because consensus-based government is has been historically unfeasible.  I do think though that political equality makes sense because in practice, giving people political equality allows them to best represent their preferences and allows us to more easily treat them as morally equal.  Political power is something that significantly affects people's positive liberty and thus their capacity to achieve things that will make them happy.  Equalizing power to some extent is, in my humble opinion, an important step in maximizing utility, because of the diminishing marginal utility of power, and the tendency of those with more power than others to abuse that power to the harm of others.<br/> <br/><blockquote class="uncited"><div>I don't think utilitarians should care directly about 'fairness'. If there's any truth to Jonathon Haidt's claims about political psychology (I'm not convinced that there is) than hedonistic utilitarianism can be considered liberalism without the concern for fairness (he argues that liberal morality involves harm/care and fairness whereas conservative morality involves those 2 principles as well as in-group loyalty, respect to authority and purity/sanctity -I think this is based on disgust based gut responses, like sexually promiscuous women being 'dirty' and libertarian morality revolves around autonomy - he also claims libertarians have , on average, the lowest empathy).</div></blockquote><br/><br/>I actually think that fairness is an inherent assumption of utilitarianism.  Why should we care about the happiness of others and maximize the utility of everyone rather than just ourselves (i.e. ethical egoism)?  Why should we treat each person as one and only one in the hedonic moral calculus?  Because it is the fair and just thing to do.  When we look outside of ourselves and see the big picture, we recognize that our interests are equally important, that it is only fair to consider everyone equally.  And practically speaking, most people have a strong genetically endowed desire for fairness.  So doing what's fair is very often also utility maximizing because it satisfies most people's natural inclinations.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9019">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9021">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9021">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-04T17:11:00</p>
<div class="content"><div class="postrev" data-snap="1">Ubuntu, I'm also curious why you think a global communist society would be the ideal utilitarian society.  Is it just because if everyone were utilitarian effective altruists, that you believe a global communist society would work best?<br/><br/>And, you mention that you're not a practicing utilitarian.  I'm curious what you do practice in terms of your ethical views.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9021">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9022">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9022">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-04T17:47:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>I'm of the opinion that Utilitarians shouldn't necessarily commit to a particular political ideology except for pragmatic reasons.</div></blockquote><br/><br/>I agree that utilitarians shouldn't commit themselves to promoting one particular political system in practice but fundamental political ideals are interconnected with fundamental moral ideals. Someone who favors capitalism because they believe it has the best overall consequences in practice but would regard communism as ideal arguably has a very different political ideology than someone who favors capitalism because they believe in natural property rights or view coerced redistrubution of wealth as unjust regardless of whether or not it has the best overall consequences. I don't think you can separate politics from morality. Because utilitarians believe everyone's interests deserve equal consideration, they have to ideally favor a system where resources are allocated on the basis of benefit without regard to merit or luck.<br/><br/><br/> <blockquote class="uncited"><div>I like liberalism because it has worked very well historically. Most of the ideas, like democracy, individuals rights, and the welfare state have become so successful that very few people argue about whether or not to implement them. </div></blockquote><br/><br/>I also think that regulated capitalism, democracy and individual rights have worked well in practice (better than any other system, on a widespread level), although not without tragic failings.<br/><br/><blockquote class="uncited"><div>Communism on the other hand, I very much question because all historical experiments with it have generally been less successful.</div></blockquote><br/><br/>Communism has worked among small enclaves comprised of like minded people, not to mention that hunter-gatherer societies were generally 'communist' and families share resources as a group. Any system can work if people are generally like minded and if a 100 people share the same attitude, a million or a billion could. <br/><br/><blockquote class="uncited"><div> And I don't just mean the "communist" states like the Soviet Union but actual implementations like the Israeli Kibbutz. I think the problem with Communism, like Libertarianism, is that it tries to glorify one aspect of human nature, and suppress all the others. Whereas Libertarianism glorifies self-interest, Communism glorifies altruism. They're both Utopian ideologies that have yet to live up to their claims. In practice, a reasonable society should allow all aspects of human nature to benefit everyone. Thus, a society that includes a free market can benefit from self-interest, and a society that also has public elements can benefit from altruism.</div></blockquote><br/><br/>I don't believe in a static human nature, we have an innate capacity for co-operative/altruistic and competitive/self-interested behavior. I think I wanted to say something else, if I did I forgot. 21st century human societies are radically different than human society 10 000 years ago but we still have the same 'nature' of our ancestors, we're still adapted-more or less- for life as hunter-gatherers.<br/><br/><blockquote class="uncited"><div>Pure global communism I just don't see working out. More than just the culture would have to change. You would probably have to fundamentally change human nature.</div></blockquote><br/><br/>I'm strongly in favor of genetic engineering (although it might be best if humans just stop reproducing entirely).<br/><br/><blockquote class="uncited"><div>I kind of assumed that the "Greatest Good for the Greatest Number" and the "Greatest Happiness Principle" were basically equivalent. The "Greatest Good" means to maximize the overall amount of happiness. The "Greatest Number" part just is more of an admission that we may have to compromise and not everyone will be happier off, so to speak.</div></blockquote><br/><br/>Maybe I'm nitpicking but I think there's an important difference. I would favor increasing 100 points of happiness for one person over maximizing a single point of happiness for 50 people each even though the latter would result in a greater number of happier people. The compromise utilitarians may have to accept isn't based on the number of people who are affected by their decisions, the 100 points of happiness of the single individual is the greater good.<br/><br/><blockquote class="uncited"><div>To me, democracy is a compromise, because consensus-based government is has been historically unfeasible. I do think though that political equality makes sense because in practice, giving people political equality allows them to best represent their preferences and allows us to more easily treat them as morally equal. Political power is something that significantly affects people's positive liberty and thus their capacity to achieve things that will make them happy. Equalizing power to some extent is, in my humble opinion, an important step in maximizing utility, because of the diminishing marginal utility of power, and the tendency of those with more power than others to abuse that power to the harm of others.</div></blockquote><br/><br/>Democracy seems to me to be a perfect expression of preference-utilitarianism but I don't necessarily believe people's preferences are morally important - in themselves. I think democracy works in practice at least partly because it helps to prevent a concentration of power among people who shouldn't have it and because people might be negatively affected by not being including in the decision making process of the group but I don't think having power-in itself- is beneficial or in someone's interests. There's a political inequality between parents and their children but this can be justified because children, being less rational, are better off having compassionate and rational adults making some decisions on their behalf, this doesn't have to conflict with viewing them as moral and social equals.<br/><br/><br/><blockquote class="uncited"><div>I actually think that fairness is an inherent assumption of utilitarianism. Why should we care about the happiness of others and maximize the utility of everyone rather than just ourselves (i.e. ethical egoism)? Why should we treat each person as one and only one in the hedonic moral calculus? Because it is the fair and just thing to do. When we look outside of ourselves and see the big picture, we recognize that our interests are equally important, that it is only fair to consider everyone equally. And practically speaking, most people have a strong genetically endowed desire for fairness. So doing what's fair is very often also utility maximizing because it satisfies most people's natural inclinations.</div></blockquote><br/><br/>I think that fairness is in the eye of the beholder.  What one person thinks of as fair is radically different than what another person thinks of as fair or just (and they might be two very different concepts), your point of view and your personal stake in a situation has a lot to do with it. It's a very arbitrary concept. I admit that people probably have different ideas in mind when they use the word. 'Fairness' usually overlaps with egalitarianism but I think the two are distinct. There are better examples to make my point but progressive taxation is completely fair to some people and completely unfair to others. It might seem obviously fair to you if you sympathize with the poor but it is unequal treatment and arguing for it on the basis of fairness when you could justify it from a basic concern for welfare and equal consideration ( diminishing marginal utility of money justifies wealth redistribution) is unnecessary. Let's say that you have two men who commit a brutal crime, a utilitarian lawyer (who somehow knows that neither men will re-offend if not sentenced to jail and others would not be persuaded to commit the same crime with the expectation of getting off if they do) wants to keep both men out of prison but he can only get one off, this is unfair since they both committed the same crime but a utilitarian would rather one stay out of prison if not both. Or imagine a utilitarian judge or whatever who somehow knew that a guilty man he sent to jail would suffer far, far more than an innocent man would (this would rarely ever be the case in real life since a guilty man could rationalize that he "deserved" it or at least knowing that he could have avoided it might give him some sense of agency over the situation), all other factors considered, the utilitarian should rather the innocent man go to jail than the guilty man since utilitarianism has no direct concern for 'fairness', only equal consideration. Utilitarians care about fairness only to the extent that they want to accommodate the moral inclinations of non-utilitarians who might take offense to their contrary attitudes.<br/><br/>At the risk of sounding cynical people care about fairness when they view themselves or people they identify with as the disadvantaged and not necessarily because they're consciously self-oriented but because it doesn't occur to them to look at the scenario from someone else's point of view. Fairness doesn't really have a tangible, non-conceptual and non-intuitive basis, our real, concrete experience of happiness and pain justifies caring about it impartially.<br/><br/>When you say that everyone's interests are equally important, how do you justify this from a preference utilitarian point of view (if you are a preference utilitarian, or how would any preference utilitarians do so if you're not). Why should I care about the preferences of other people, the very nature of our preferences are fundamentally different and often inherently conflicting. My experience of happiness, on the other hand, is the exact same as George Bush's basis experience of pleasure so it's irrational for me not to care about George's happiness just as it would be irrational for me to regard the water in my bathtub as more valuable than the water in my next door neighbour's pool for no other reason than it being located in my bathtub, water is chemically the same regardless of where it's located. When you say that it's the fair and just thing to care about the interests of other people, what are you basing this on? (I don't know if you consider yourself to be a hedonistic utilitarian, I guess this applies either way).</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9022">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9024">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9024">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-04T19:39:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>I agree that utilitarians shouldn't commit themselves to promoting one particular political system in practice but fundamental political ideals are interconnected with fundamental moral ideals. Someone who favors capitalism because they believe it has the best overall consequences in practice but would regard communism as ideal arguably has a very different political ideology than someone who favors capitalism because they believe in natural property rights or view coerced redistrubution of wealth as unjust regardless of whether or not it has the best overall consequences. I don't think you can separate politics from morality. Because utilitarians believe everyone's interests deserve equal consideration, they have to ideally favor a system where resources are allocated on the basis of benefit without regard to merit or luck.</div></blockquote><br/><br/>I don't know that such a system would necessarily look like communism though.  It could arguably look more like <a class="postlink" href="http://en.wikipedia.org/wiki/Distributism">distributism</a> or <a class="postlink" href="http://en.wikipedia.org/wiki/Mutualism_(economic_theory)">mutualism</a>.  Communism assumes that the common ownership of property will necessarily lead to best consequences, and I'm not convinced that it will.<br/><br/><blockquote class="uncited"><div>I'm strongly in favor of genetic engineering (although it might be best if humans just stop reproducing entirely).</div></blockquote><br/><br/>I'm actually strongly in favour of creating a race of altruistic sentient machines that would desire to benefit and serve all sentient life and enact a Utilitarian society.<br/><br/><blockquote class="uncited"><div>Maybe I'm nitpicking but I think there's an important difference. I would favor increasing 100 points of happiness for one person over maximizing a single point of happiness for 50 people each even though the latter would result in a greater number of happier people. The compromise utilitarians may have to accept isn't based on the number of people who are affected by their decisions, the 100 points of happiness of the single individual is the greater good.</div></blockquote><br/><br/>Fair enough.<br/><br/><blockquote class="uncited"><div>Democracy seems to me to be a perfect expression of preference-utilitarianism but I don't necessarily believe people's preferences are morally important - in themselves. I think democracy works in practice at least partly because it helps to prevent a concentration of power among people who shouldn't have it and because people might be negatively affected by not being including in the decision making process of the group but I don't think having power-in itself- is beneficial or in someone's interests. There's a political inequality between parents and their children but this can be justified because children, being less rational, are better off having compassionate and rational adults making some decisions on their behalf, this doesn't have to conflict with viewing them as moral and social equals.</div></blockquote><br/><br/>Well, the assumption I make is that usually, among reasonably intelligent adult citizens, their preferences will generally coincide with what makes them happiest.  Similarly, it seems to me that having enough power to accomplish one's goals generally correlates well with maximizing someone's happiness, given that Self-Determination Theory in psychology suggests that most people are motivated by desires for Competence, Autonomy, and Relatedness, and that fulfilling these desires leads reliably to positive emotional states (pleasure).<br/><br/><blockquote class="uncited"><div>I think that fairness is in the eye of the beholder. What one person thinks of as fair is radically different than what another person thinks of as fair or just (and they might be two very different concepts), your point of view and your personal stake in a situation has a lot to do with it. It's a very arbitrary concept. I admit that people probably have different ideas in mind when they use the word. 'Fairness' usually overlaps with egalitarianism but I think the two are distinct. There are better examples to make my point but progressive taxation is completely fair to some people and completely unfair to others. It might seem obviously fair to you if you sympathize with the poor but it is unequal treatment and arguing for it on the basis of fairness when you could justify it from a basic concern for welfare and equal consideration ( diminishing marginal utility of money justifies wealth redistribution) is unnecessary. Let's say that you have two men who commit a brutal crime, a utilitarian lawyer (who somehow knows that neither men will re-offend if not sentenced to jail and others would not be persuaded to commit the same crime with the expectation of getting off if they do) wants to keep both men out of prison but he can only get one off, this is unfair since they both committed the same crime but a utilitarian would rather one stay out of prison if not both. Or imagine a utilitarian judge or whatever who somehow knew that a guilty man he sent to jail would suffer far, far more than an innocent man would (this would rarely ever be the case in real life since a guilty man could rationalize that he "deserved" it or at least knowing that he could have avoided it might give him some sense of agency over the situation), all other factors considered, the utilitarian should rather the innocent man go to jail than the guilty man since utilitarianism has no direct concern for 'fairness', only equal consideration. Utilitarians care about fairness only to the extent that they want to accommodate the moral inclinations of non-utilitarians who might take offense to their contrary attitudes.</div></blockquote><br/><br/>I actually agree with Eliezer Yudkowsky on <a class="postlink" href="http://lesswrong.com/lw/t2/is_fairness_arbitrary/">whether or not fairness is arbitrary</a>.<br/><br/>To me, fairness is one of the basic foundations of Utilitarianism.  Without it, it becomes exceedingly difficult to argue in favour of Utilitarianism over Ethical Egoism.  Why should I maximize utility generally, rather than just maximize my own utility?  Utilitarianism is fundamentally about being fair to others by giving them equal moral worth and standing.  Thus, being truly, objectively fair means maximizing the utility of everyone.  That we sometimes decide to give one person more utility than another, is because we appreciate that sometimes maximizing total utility involves giving unequal distributions.  But nevertheless, because we factor everyone into the equation of our moral calculus, we are intrinsically trying to be fair.<br/><br/>I would argue that things only seem unfair to some people and fair to others because they all have imperfect knowledge of the truth.  If you were able to have perfect knowledge, you would be able to conclude what was truly fair.  There is some kind of fundamentally just arrangement, and I believe with my limited knowledge that the just arrangement is utility maximizing.<br/><br/><blockquote class="uncited"><div>At the risk of sounding cynical people care about fairness when they view themselves or people they identify with as the disadvantaged and not necessarily because they're consciously self-oriented but because it doesn't occur to them to look at the scenario from someone else's point of view. Fairness doesn't really have a tangible, non-conceptual and non-intuitive basis, our real, concrete experience of happiness and pain justifies caring about it impartially.<br/><br/>When you say that everyone's interests are equally important, how do you justify this from a preference utilitarian point of view (if you are a preference utilitarian, or how would any preference utilitarians do so if you're not). Why should I care about the preferences of other people, the very nature of our preferences are fundamentally different and often inherently conflicting. My experience of happiness, on the other hand, is the exact same as George Bush's basis experience of pleasure so it's irrational for me not to care about George's happiness just as it would be irrational for me to regard the water in my bathtub as more valuable than the water in my next door neighbour's pool for no other reason than it being located in my bathtub, water is chemically the same regardless of where it's located. When you say that it's the fair and just thing to care about the interests of other people, what are you basing this on? (I don't know if you consider yourself to be a hedonistic utilitarian, I guess this applies either way).</div></blockquote><br/><br/>I'm not a preference utilitarian.  I like to call myself a Eudaimonic Utilitarian, but if I have to choose between preference and hedonistic utilitarianism, I currently lean towards choosing hedonistic utilitarianism.<br/><br/>When I say that it is the fair and just thing to care about the interests of other people, I'm basing it on the reality that people's interests and preferences generally coincide with things that if fulfilled will lead them to the emotional goal state of happiness.  I consider this state to be intrinsically valuable, and all other "values" to be instrumental values towards the creation of this state.   However, it can be argued that only my own happiness is intrinsically valuable to me.  The happiness of others, while likely to elicit empathy, and happiness in me as well, is not necessarily so.  For instance, if I don't know about someone else's happiness, empathetic happiness doesn't factor.  In order to be able to argue that the happiness of others is intrinsically valuable, I must choose to look outside my own parochial self, and establish my values from a universal perspective.  From such an objective point of view, there is no real reason why my happiness should be any more or less important than anyone else's.  Instead, it is fair or just to consider all happiness to be intrinsically valuable, because it is valuable to the subject that feels it.  Justice and fairness are fundamentally about being unbiased and objective and showing no preferences.<br/><br/>Think of it this way.  Imagine for a moment that we develop a superintelligent computer that has perfect knowledge and perfect rationality.  However, this computer has no built in utility function.  It has no emotions or desires, feels no pain or pleasure, and has no initial values or preferences.  Nevertheless, it can know that other entities exist which do have these things.  Given that the machine has no preferences or values, what should it do?  I believe that such a being would eventually conclude that it should accept the intrinsic values of others as being morally important and imperatively demanding.  And that it should not show any bias towards any one entity over another, but should be fair to them as a default position, as an application of the probabilistic <a class="postlink" href="http://en.wikipedia.org/wiki/Principle_of_indifference">Principle of Indifference</a> and the <a class="postlink" href="http://en.wikipedia.org/wiki/Principle_of_maximum_entropy">Principle of Maximum Entropy</a>.  Thus it will come to develop a utility function that maximizes the positive emotional and objective states of all sentient beings (their Eudaimonia).</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9024">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9034">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9034">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-06T17:02:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>Ubuntu, I'm also curious why you think a global communist society would be the ideal utilitarian society. Is it just because if everyone were utilitarian effective altruists, that you believe a global communist society would work best?<br/><br/>And, you mention that you're not a practicing utilitarian. I'm curious what you do practice in terms of your ethical views.</div></blockquote><br/><br/>If everyone were a perfectly consistent utilitarian (and I admit, no one will ever be a <span style="font-style: italic">perfectly</span> consistent utilitarian) they would give no special consideration to their own well-being, they would care about their interests (or the interests of a select few individuals they're emotionally attached to - I do think that they would still be partial in terms of their personal emotional attachments and there's nothing wrong with that) no more or less than they would care about anyone else's so they would be naturally inclined to share resources freely in a gift economy. Capitalism is driven by self-interest and competition, utilitarianism is predicated on a concern for the world as a whole and universal empathy (utilitarians care about their own happiness because they care about happiness and not because it is <span style="font-style: italic">their </span>happiness which is in direct conflict with the self-interest that pushes capitalism and sympathizing universally with the happiness of all beings is in direct conflict with an economy based on competition for resources ; you don't compete with someone when you want them to 'win' as much as you want yourself to). As I understand it - a communist economy is one in which resources are distributed on the basis of benefit and means of production are owned communally, or at least 'owned' in the sense of being controlled by a state that operates with the interests of the community as a whole in mind (I know that might be a very basic understanding of communism but is that not correct?). The reason why attempting to establish a global communist economy would not work is because most people are not utilitarians. Again, obviously I would favor a hyper-capitalist society with a very high ratio of happiness-suffering over a communist society with more suffering and less happiness but only in the same way I would favor a world of happy egotists over one of depressed egalitarians/altruists. All other factors accounted for, a world of utilitarians would necessarily be better than a world of egotists.<br/><br/><br/><br/><br/><br/><br/><br/><blockquote class="uncited"><div>I don't know that such a system would necessarily look like communism though.  It could arguably look more like <a class="postlink" href="http://en.wikipedia.org/wiki/Distributism">distributism</a> or <a class="postlink" href="http://en.wikipedia.org/wiki/Mutualism_(economic_theory)">mutualism</a>.  Communism assumes that the common ownership of property will necessarily lead to best consequences, and I'm not convinced that it will.</div></blockquote><br/><br/>If we're on the same page about what 'communism' entails I can't possibly understand how it wouldn't (not in practice, which I've already conceded, but in a world where everyone, or at least most moral agents, were utilitarians). When I use the term 'communism' I don't mean modern China but I don't necessarily mean the stateless society Marx had in mind as the end goal of state socialism either, and I don't necessarily favor communal ownership of property in the sense of the community controlling the economy democratically ; I'm allowing for a centrally planned economy (planned by a state with an explicitly hedonistic utilitarian agenda). Again, I'm not talking about what would lead to the best consequences in a world of predominately non-utilitarians.<br/><br/><br/><br/><blockquote class="uncited"><div>I'm actually strongly in favour of creating a race of altruistic sentient machines that would desire to benefit and serve all sentient life and enact a Utilitarian society.</div></blockquote><br/><br/>I personally don't believe that sentient A.I is possible but I wouldn't mind being proven wrong.<br/><br/><br/><blockquote class="uncited"><div>Well, the assumption I make is that usually, among reasonably intelligent adult citizens, their preferences will generally coincide with what makes them happiest.</div></blockquote><br/><br/>I completely agree (as far as preferences regarding their own life are concerned) but I don't think that justifies a direct concern for their preferences per se. Hedonistic utilitarians should consider both the preferences and the autonomy of other people because people are negatively affected when their autonomy is violated and the felt frustration of their desires is distressing but I see the justification for respecting the preferences and autonomy of other people being that it's instrumental to their happiness and not because their preferences or autonomy are inherently worth respecting.<br/><br/><br/><blockquote class="uncited"><div>  Similarly, it seems to me that having enough power to accomplish one's goals generally correlates well with maximizing someone's happiness, given that Self-Determination Theory in psychology suggests that most people are motivated by desires for Competence, Autonomy, and Relatedness, and that fulfilling these desires leads reliably to positive emotional states (pleasure).</div></blockquote><br/><br/>I don't disagree.<br/><br/><br/><br/><br/><blockquote class="uncited"><div>To me, fairness is one of the basic foundations of Utilitarianism.  Without it, it becomes exceedingly difficult to argue in favour of Utilitarianism over Ethical Egoism.  Why should I maximize utility generally, rather than just maximize my own utility?  Utilitarianism is fundamentally about being fair to others by giving them equal moral worth and standing.  Thus, being truly, objectively fair means maximizing the utility of everyone.  That we sometimes decide to give one person more utility than another, is because we appreciate that sometimes maximizing total utility involves giving unequal distributions.  But nevertheless, because we factor everyone into the equation of our moral calculus, we are intrinsically trying to be fair.</div></blockquote><br/><br/>To me, the basic foundation to utilitarianism is 'utility' (or good). The reason why you should maximize the good of the world generally is because good itself is worth maximizing. Utilitarians are egalitarians because they're equally concerned with everyone's good and this overlaps with fairness (what I have in mind when I use the term) but diverges from it as well. I don't think I disagree with your concept of fairness, it's just not in sync with the general impression that I have about what most people consider to be fair. To me, 'justice' has connotations of rights and how to respond to people who violate those rights and 'fairness' involves undeserved advantages and how to equalize advantages between competing parties ; even when no one is actually better off because of it and no wrong has actually been done by the more advantaged party, maybe that isn't what most people have in mind about 'fairness' but , in my observation, it seems people tend to care about fairness only when they view themselves (accurately or not) as being disadvantaged compared to someone else. People care more about their suffering than they do about the suffering of others (even the kindest people, if for no other reason than their at the moment suffering being more vivid and real to them) but everyone seems to be on the same page that poking someone's eye out is an unkind thing to do, even if it's 'deserved', but people radically disagree on what is fair or unfair - that alone doesn't show that fairness is arbitrary, though.<br/><br/><blockquote class="uncited"><div>I would argue that things only seem unfair to some people and fair to others because they all have imperfect knowledge of the truth.  If you were able to have perfect knowledge, you would be able to conclude what was truly fair.  There is some kind of fundamentally just arrangement, and I believe with my limited knowledge that the just arrangement is utility maximizing.</div></blockquote><br/><br/>So what exactly is your definition of fairness?<br/><br/>And should people maximize the well-being of others because their well-being is worth maximizing or because it is just to do so, it seems like two different reasons. In my view, happiness is the one inherent good, not happiness and justice. Kant would have opposed hurting an innocent person (or at least an autonomous and rational innocent person - for direct reasons) because their suffering is undeserved but my problem is with the experience itself and not the injustice of it being undeserved.<br/><br/><br/><br/><blockquote class="uncited"><div>When I say that it is the fair and just thing to care about the interests of other people, I'm basing it on the reality that people's interests and preferences generally coincide with things that if fulfilled will lead them to the emotional goal state of happiness.</div></blockquote><br/><br/>If 'just' and 'fair' means morally good or warranted then I couldn't disagree but with the rights based understanding of 'justice' that I have, justice and happiness seem to be two different values. You wouldn't say that not going out of your way to help someone ; even if you should, was an <span style="font-style: italic"> injustice</span>, would you?<br/><br/><br/> <blockquote class="uncited"><div> However, it can be argued that only my own happiness is intrinsically valuable to me.</div></blockquote><br/><br/>And I would reject that argument as I would the idea that your happiness only exists for you ; it's a part of the world and exists simpliciter. The water in my bathtub is wet in itself, not for my tub. That's what it means to say that water is 'intrinsically' wet.<br/><br/><blockquote class="uncited"><div>  The happiness of others, while likely to elicit empathy, and happiness in me as well, is not necessarily so.  For instance, if I don't know about someone else's happiness, empathetic happiness doesn't factor.</div></blockquote> <br/><br/>But the fact that you aren't aware of the existence of another person's happiness doesn't make it any less real. It either exists or it doesn't.<br/><br/><blockquote class="uncited"><div> In order to be able to argue that the happiness of others is intrinsically valuable, I must choose to look outside my own parochial self, and establish my values from a universal perspective.  From such an objective point of view, there is no real reason why my happiness should be any more or less important than anyone else's.</div></blockquote><br/><br/>I agree although this doesn't apply to preference utilitarianism because my preferences aren't necessarily commensurable with your preferences, my happiness is commensurable with your happiness because it's the same thing.<br/><br/><blockquote class="uncited"><div>  Instead, it is fair or just to consider all happiness to be intrinsically valuable, because it is valuable to the subject that feels it.</div></blockquote><br/><br/>It can only be 'fair' or 'just' to regard all happiness as intrinsically valuable if all happiness really is intrinsically valuable. If George's happiness is only valuable to him then only George has a reason to care about his happiness. You could say that George's happiness is good for him but justice, which requires giving George's interests equal consideration, is good simpliciter but you would be rejecting hedonism (or Eudaimonism).<br/><br/><blockquote class="uncited"><div>  Justice and fairness are fundamentally about being unbiased and objective and showing no preferences.</div></blockquote><br/><br/>I would call this impartiality. <br/><br/><blockquote class="uncited"><div>Think of it this way.  Imagine for a moment that we develop a superintelligent computer that has perfect knowledge and perfect rationality.  However, this computer has no built in utility function.  It has no emotions or desires, feels no pain or pleasure, and has no initial values or preferences.  Nevertheless, it can know that other entities exist which do have these things.  Given that the machine has no preferences or values, what should it do?  I believe that such a being would eventually conclude that it should accept the intrinsic values of others as being morally important and imperatively demanding.</div></blockquote><br/><br/>I can't imagine how it could possibly do this without a personal self-reference as to why their emotions mattered ; what it's like to want things or being able to identify with these preferences or values emotionally. Without ever having experienced emotion or wanted anything , it couldn't relate to us, the concepts of preference/value/emotion would have as much meaning to it as color to someone who was born blind.<br/><br/><blockquote class="uncited"><div>  And that it should not show any bias towards any one entity over another, but should be fair to them as a default position, as an application of the probabilistic <a class="postlink" href="http://en.wikipedia.org/wiki/Principle_of_indifference">Principle of Indifference</a> and the <a class="postlink" href="http://en.wikipedia.org/wiki/Principle_of_maximum_entropy">Principle of Maximum Entropy</a>.  Thus it will come to develop a utility function that maximizes the positive emotional and objective states of all sentient beings (their Eudaimonia).</div></blockquote><br/><br/>I don't see how this being could possibly care about anything without emotions. Not that I think caring is necessarily just an immediate emotional response and not a rational decision but it has to be rooted ultimately in emotion.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9034">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9035">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9035">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/59.html">DanielLC</a></strong> on 2014-02-06T20:32:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>I personally don't believe that sentient A.I is possible but I wouldn't mind being proven wrong.</div></blockquote><br/><br/>It might be a good idea to move this to a new thread, but:<br/><br/>We know intelligence is possible because it exists. Are you saying that doing the same thing artificially will somehow produce different results, or just that designing AI is inhumanly difficult?</div><div class="diff hidden"></div></div>
<div class="signature">Consequentialism: The belief that doing the right thing makes the world a better place.</div>
</div>
<dl class="postprofile" id="profile9035">
<dt>
<a href="../user/59.html"></a><br/>
<a href="../user/59.html">DanielLC</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 703</dd>
<dd><strong>Joined:</strong> Fri Oct 10, 2008 4:29 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9036">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9036">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-06T23:45:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>If everyone were a perfectly consistent utilitarian (and I admit, no one will ever be a perfectly consistent utilitarian) they would give no special consideration to their own well-being, they would care about their interests (or the interests of a select few individuals they're emotionally attached to - I do think that they would still be partial in terms of their personal emotional attachments and there's nothing wrong with that) no more or less than they would care about anyone else's so they would be naturally inclined to share resources freely in a gift economy. Capitalism is driven by self-interest and competition, utilitarianism is predicated on a concern for the world as a whole and universal empathy (utilitarians care about their own happiness because they care about happiness and not because it is their happiness which is in direct conflict with the self-interest that pushes capitalism and sympathizing universally with the happiness of all beings is in direct conflict with an economy based on competition for resources ; you don't compete with someone when you want them to 'win' as much as you want yourself to). As I understand it - a communist economy is one in which resources are distributed on the basis of benefit and means of production are owned communally, or at least 'owned' in the sense of being controlled by a state that operates with the interests of the community as a whole in mind (I know that might be a very basic understanding of communism but is that not correct?). The reason why attempting to establish a global communist economy would not work is because most people are not utilitarians. Again, obviously I would favor a hyper-capitalist society with a very high ratio of happiness-suffering over a communist society with more suffering and less happiness but only in the same way I would favor a world of happy egotists over one of depressed egalitarians/altruists. All other factors accounted for, a world of utilitarians would necessarily be better than a world of egotists.<br/><br/>If we're on the same page about what 'communism' entails I can't possibly understand how it wouldn't (not in practice, which I've already conceded, but in a world where everyone, or at least most moral agents, were utilitarians). When I use the term 'communism' I don't mean modern China but I don't necessarily mean the stateless society Marx had in mind as the end goal of state socialism either, and I don't necessarily favor communal ownership of property in the sense of the community controlling the economy democratically ; I'm allowing for a centrally planned economy (planned by a state with an explicitly hedonistic utilitarian agenda). Again, I'm not talking about what would lead to the best consequences in a world of predominately non-utilitarians.</div></blockquote><br/><br/>If you put it that way, I suppose some form of anarcho-communism, like what Ursula LeGuin proposed in "The Dispossessed" (which by the way is a very good book) would be ideal.  The way I see it, if everyone was perfectly altruistic, then there would be no need for a state apparatus to force people to be Utilitarian.   People could voluntarily give of themselves and the only state-like elements in such a society might be technocratic experts who would be consulted to coordinate this giving to maximize benefit.  But it would not be a state in the sense that the means of production would need to be owned by it, nor would they have to monopolize the use of force.  Arguably in such a society, no one would own anything, but things would be voluntarily shared according to Utilitarian principles.<br/><br/>The reason why I think that anarcho-communism is better than state communism is simply because I view a bottom-up approach to happiness maximization as more effective than top-down.  People usually know what makes them happy better than some distant bureaucrats in the capital.  If everyone is genuinely Utilitarian, then individuals close to each other can easily identify needs and benefits.  If they are unable to bring the most benefit locally, they can always communicate with others outside the local community and spread information to the global community this way.  Conversely, a top-down approach is limited by the computing power of the bureaucrats and technocrats in charge.  Taking advantage of the local processing power of everyone in parallel, is much more efficient than trying to coordinate things from a central processing organ.  This is the reason why the human brain, made up of billions of neurons working in parallel, is able to perform so well even though each individual neuron is much slower than the average CPU of a currently existing digital computer.<br/><br/>It's also the reason why markets tend to work better than central planning.  The economic calculation problem is something I consider a serious concern with any sort of socialist or state communist system.<br/><br/>Also, arguably Occam's razor would favour the society that was simpler and less complicated.  States necessarily add a layer of complexity to the system, and doing away with the state apparatus would probably be a more efficient allocation of resources as well.  Perhaps some useful elements of the state might still exist, such as an all-volunteer army that would exist solely to protect us from alien attack.  But for the most part, if everyone is altruistic enough, there is really no need to force people to do anything, as they'll act voluntarily for the greatest good.<br/><br/><blockquote class="uncited"><div>I personally don't believe that sentient A.I is possible but I wouldn't mind being proven wrong.</div></blockquote><br/><br/>I'm working on it.  My master's thesis is on Neural Networks and Object Recognition. <img alt=":D" src="../images/smilies/icon_e_biggrin.gif"/><br/><br/>I think that A.I. that is based on neural networks could eventually lead to sentient A.I., simply because it's the same structure that human and animal intelligence is based on.  If you create an artificial brain with all the cognitive characteristics of a fully functional human brain, I don't see how they would be in any functional way different.<br/><br/><blockquote class="uncited"><div>I completely agree (as far as preferences regarding their own life are concerned) but I don't think that justifies a direct concern for their preferences per se. Hedonistic utilitarians should consider both the preferences and the autonomy of other people because people are negatively affected when their autonomy is violated and the felt frustration of their desires is distressing but I see the justification for respecting the preferences and autonomy of other people being that it's instrumental to their happiness and not because their preferences or autonomy are inherently worth respecting.</div></blockquote><br/><br/>I agree completely.<br/><br/><blockquote class="uncited"><div>To me, the basic foundation to utilitarianism is 'utility' (or good). The reason why you should maximize the good of the world generally is because good itself is worth maximizing. Utilitarians are egalitarians because they're equally concerned with everyone's good and this overlaps with fairness (what I have in mind when I use the term) but diverges from it as well. I don't think I disagree with your concept of fairness, it's just not in sync with the general impression that I have about what most people consider to be fair. To me, 'justice' has connotations of rights and how to respond to people who violate those rights and 'fairness' involves undeserved advantages and how to equalize advantages between competing parties ; even when no one is actually better off because of it and no wrong has actually been done by the more advantaged party, maybe that isn't what most people have in mind about 'fairness' but , in my observation, it seems people tend to care about fairness only when they view themselves (accurately or not) as being disadvantaged compared to someone else. People care more about their suffering than they do about the suffering of others (even the kindest people, if for no other reason than their at the moment suffering being more vivid and real to them) but everyone seems to be on the same page that poking someone's eye out is an unkind thing to do, even if it's 'deserved', but people radically disagree on what is fair or unfair - that alone doesn't show that fairness is arbitrary, though.<br/><br/>So what exactly is your definition of fairness?</div></blockquote><br/><br/>My definition of fairness is whatever an impartial observer taking a universal perspective and having all the relevant information would believe is the correct way of acting towards subjects.<br/><br/><blockquote class="uncited"><div>And should people maximize the well-being of others because their well-being is worth maximizing or because it is just to do so, it seems like two different reasons. In my view, happiness is the one inherent good, not happiness and justice. Kant would have opposed hurting an innocent person (or at least an autonomous and rational innocent person - for direct reasons) because their suffering is undeserved but my problem is with the experience itself and not the injustice of it being undeserved.</div></blockquote><br/><br/>Both?  I think justice is the concept of doing what is right, of letting people get what they honestly deserve from the fair perspective.  And I think that people deserve to be happy.  The reason for this is that people are not free to deny happiness or suffering.  Even if you try to ignore it, you still feel it.  And given that how they feel is one of the few things that we can know with absolute certainty, it is also one of the few things we can make an absolute moral statement about.  It is true by the very nature of happiness and suffering that happiness is good, and suffering is bad, all other things being equal.  The right thing to do then, is to maximize the happiness of everyone.  Generally, because of the principle of diminishing marginal utility, this conforms to maximizing happiness period.  I consider the ideal, the "perfect morality" then, to be to maximize everyone's happiness without exception.  The "greatest number" notion is a compromise, admitting that in most practical circumstances it is not possible to make everyone happy.  Justice is not by itself "good".  Rather it is "right".  And I believe that doing what is right, means maximizing the good.  The two are strongly correlated enough that in practice they are basically the same thing, but they are distinct notions in philosophy.<br/><br/><blockquote class="uncited"><div>If 'just' and 'fair' means morally good or warranted then I couldn't disagree but with the rights based understanding of 'justice' that I have, justice and happiness seem to be two different values. You wouldn't say that not going out of your way to help someone ; even if you should, was an injustice, would you?</div></blockquote><br/><br/>I actually would argue it is unjust, that you aren't doing the right thing.<br/><br/><blockquote class="uncited"><div>And I would reject that argument as I would the idea that your happiness only exists for you ; it's a part of the world and exists simpliciter. The water in my bathtub is wet in itself, not for my tub. That's what it means to say that water is 'intrinsically' wet.</div></blockquote><br/><br/>Interesting.  I would say that Ethical Egoism is actually a perfectly rational if not necessarily correct moral theory.  An ethical egoist doesn't value happiness intrinsically.  Rather, they only value their own specific happiness and say that only happiness they can feel is good.  Given that value, they can rationally act accordingly.<br/><br/><blockquote class="uncited"><div>But the fact that you aren't aware of the existence of another person's happiness doesn't make it any less real. It either exists or it doesn't.</div></blockquote><br/><br/>True.<br/><br/><blockquote class="uncited"><div>It can only be 'fair' or 'just' to regard all happiness as intrinsically valuable if all happiness really is intrinsically valuable. If George's happiness is only valuable to him then only George has a reason to care about his happiness. You could say that George's happiness is good for him but justice, which requires giving George's interests equal consideration, is good simpliciter but you would be rejecting hedonism (or Eudaimonism).</div></blockquote><br/><br/>The Ethical Egoist generally makes no effort to argue the fairness or justice of his/her position.  I'm not defending that position, but rather simply stating that the value that we give to happiness is subject-oriented.  That is to say, we value it not because there is some object called "happiness" out in the physical world, but that "happiness" is necessarily a subjective state that exists within the subject, and which is intrinsically valuable to it.<br/><br/><blockquote class="uncited"><div>I can't imagine how it could possibly do this without a personal self-reference as to why their emotions mattered ; what it's like to want things or being able to identify with these preferences or values emotionally. Without ever having experienced emotion or wanted anything , it couldn't relate to us, the concepts of preference/value/emotion would have as much meaning to it as color to someone who was born blind.</div></blockquote><br/><br/>Well, the essential part of this argument is that it has perfect knowledge of things like what emotions, preferences, or values would feel like if it had them.  Perhaps this is incoherent, so let's modify the thought experiment slightly.  Assume that the superintelligent computer is sentient, which is to say, it knows that emotions, preferences and values feel like because it has the capacity to feel them.<br/><br/><blockquote class="uncited"><div>I don't see how this being could possibly care about anything without emotions. Not that I think caring is necessarily just an immediate emotional response and not a rational decision but it has to be rooted ultimately in emotion.</div></blockquote><br/><br/>We'll modify the thought experiment further then, and say that it does have one driving emotion or value, and that is to do what is moral.  It feels happiness when it does what it thinks is the right thing, and sadness if it fails to do so.  Thus it would be motivated to figure out what is moral and do it.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9036">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9037">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9037">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-07T02:30:00</p>
<div class="content"><div class="postrev" data-snap="1">Actually, if I think about it some more, ANY system of government would run reasonably well if everyone were perfect Utilitarians.  I mean, even a Monarchy would be fairly benevolent and enlightened, as the monarch would govern benevolently and with the consensus approval of all his or her subjects.  Anarcho-Capitalism would even be fine because everyone would probably start charities and create a "market" gift-economy anyway.<br/><br/>So I actually wonder if it even really matters how the society is formally organized.  If everyone is a perfect altruistic utilitarian, laws are redundant because people will generally do the right thing voluntarily, and that probably includes ignoring the laws that aren't utility maximizing (and this assumes that judges and law enforcement will look the other way when they do).  In practice every type of society will eventually become a kind of consensus-based society that takes the best aspects of every type of government and economic organization and uses them where they are most useful.<br/><br/>Eventually I see such a society evolving into a kind of Utilitarian Society that you can't really classify as any particular system.  It will probably resemble Anarcho-Communism in some ways, but if some state apparatus actually turns out to be useful, they won't be tied to that ideology.  For instance, I mentioned having an all-volunteer army for protection against outside threats.  There might similarly be a kind of executive leadership who in practice executes the decisions of the consensus in situations where you need central authority in analogy to the central executive function in the brain.  These may appear to be state-like, so I don't know that such a society would be strictly Anarcho-Communist anymore.  I would prefer to call it a Consensus-based Utilitarian Utopia.  XD<br/><br/>The most natural structure I can see of how this society would be "governed", would be that everyone would voluntarily attend a local council where they would arrive at a consensus.  If they can do everything themselves, then there's no need to move further, but if they need help, they can then send a representative to the next level council, and so on until you reached the central global council, who would decide what the executive should do.  There might be some things like interplanetary diplomacy that you would want a "leader" to represent you for, and this is what the central executive would be useful for.  Again, everything would become in practice voluntary.  Laws, if they still exist, would be like heuristics.<br/><br/>Things like property might actually still exist if there was usefulness to the concept.  Like, property would no longer be an absolute right but simply, "what you are responsible for".  There might still be a market for people who like markets, but it would run alongside the gift-economy.<br/><br/>So, I think, Communism and in even, Anarcho-Communism, is still too ideologically rigid to be the Utilitarian Utopia.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9037">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9038">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9038">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-07T17:36:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote><div><cite>DanielLC wrote:</cite><br/>It might be a good idea to move this to a new thread, but:<br/><br/>We know intelligence is possible because it exists. Are you saying that doing the same thing artificially will somehow produce different results, or just that designing AI is inhumanly difficult?</div></blockquote><br/><br/>I don't believe that subjective experience develops out of thin air at some arbitrary point in the development of a fetal nervous system, I believe that it's intrinsic to the basic building blocks of matter. I don't think that it can be created artificially by manipulating physical systems and that's why I don't think sentient A.I will ever exist. I'd be happy to be 'proven' wrong because I've always loved the idea of sentient A.I.<br/><br/><blockquote class="uncited"><div>If you put it that way, I suppose some form of anarcho-communism, like what Ursula LeGuin proposed in "The Dispossessed" (which by the way is a very good book) would be ideal. The way I see it, if everyone was perfectly altruistic, then there would be no need for a state apparatus to force people to be Utilitarian. People could voluntarily give of themselves and the only state-like elements in such a society might be technocratic experts who would be consulted to coordinate this giving to maximize benefit. But it would not be a state in the sense that the means of production would need to be owned by it, nor would they have to monopolize the use of force. Arguably in such a society, no one would own anything, but things would be voluntarily shared according to Utilitarian principles.</div></blockquote><br/><br/>I think that an anarchist-communist society would be ideal and is preferable to state communism but the utilitarians in my ideal society would be willing to initiate coercion and force so they couldn't really be 'anarchists' in the same way that they couldn't be 'pacifists'. Definitely, a society without coercion and force would be better but it might be a good idea to have a party that is prepared to initiate force if it becomes necessary in future and it might still be necessary if most of the people were altruistic utilitarians but a minority were not ; and even like-minded people with the best intentions can have different ideas about how best to improve society.<br/><br/><blockquote class="uncited"><div>It's also the reason why markets tend to work better than central planning. </div></blockquote><br/><br/>I think that any kind of free market competition, even in a socialist society without capitalist 'exploitation', is in direct conflict with the basic premise of hedonistic utilitarianism (for the utilitarians themselves to favor this self-interested competition ; not necessarily to accept it pragmatically because other people aren't utilitarians). Markets don't always work better than central planning (doesn't regulated capitalism with social welfare benefits like public health care and public education works better than laissez faire capitalism? ) and when they do it has a lot to do with cultural and political values held by most people (like the incentive provided by self-interest) and not something intrinsic to the free market itself.<br/><br/><blockquote class="uncited"><div>such as an all-volunteer army that would exist solely to protect us from alien attack.</div></blockquote><br/><br/>I don't think that will ever be a practical concern, I don't think we'll ever come across sentient alien life (regardless of whether or not they exist). If we do, utilitarians should care no less about the alien invaders than about other humans.<br/><br/><br/><blockquote class="uncited"><div>I think that A.I. that is based on neural networks could eventually lead to sentient A.I., simply because it's the same structure that human and animal intelligence is based on. If you create an artificial brain with all the cognitive characteristics of a fully functional human brain, I don't see how they would be in any functional way different.</div></blockquote><br/><br/>I would have agreed with you before I became a pan-psychist but I don't think that consciousness is something caused by physical activity in the brain. I believe the very concept of a qualitatively new kind of reality (first person subjective experience) emerging from inter-subjectively observable physical processes is incoherent. Even weak emergence of entirely new traits and characteristics is logically impossible, in my opinion.<br/><br/><blockquote class="uncited"><div>My definition of fairness is whatever an impartial observer taking a universal perspective and having all the relevant information would believe is the correct way of acting towards subjects.<br/></div></blockquote><br/><br/>Then maybe the issue is just semantics because that's not what comes to mind when I hear the word 'fairness'.<br/><br/><blockquote class="uncited"><div>Both? I think justice is the concept of doing what is right, of letting people get what they honestly deserve from the fair perspective. And I think that people deserve to be happy.</div></blockquote><br/><br/>Again, I think of something different when I hear the word 'justice'. I wouldn't disagree that people (without exception) deserve happiness but, arguably, maximizing happiness because it's deserved-even when the deservingness of the beneficiary is intrinsic to their status as an emotional being- and maximizing happiness because happiness itself is good are two different justifications for maximizing happiness. Or maybe the distinction only makes sense when happiness is considered to be undeserved in some circumstances.<br/><br/><blockquote class="uncited"><div>The reason for this is that people are not free to deny happiness or suffering. Even if you try to ignore it, you still feel it. And given that how they <span style="font-weight: bold">(you mean we?)</span> feel is one of the few things that we can know with absolute certainty, it is also one of the few things we can make an absolute moral statement about. It is true by the very nature of happiness and suffering that happiness is good, and suffering is bad,</div></blockquote><br/><br/>I agree.<br/><br/><blockquote class="uncited"><div> all other things being equal.</div></blockquote><br/><br/>I think that happiness is good unconditionally, regardless of circumstance.<br/><br/><blockquote class="uncited"><div> The right thing to do then, is to maximize the happiness of everyone. Generally, because of the principle of diminishing marginal utility, this conforms to maximizing happiness period.</div></blockquote><br/><br/>How does diminishing marginal utility justify an impartial concern for everyone's happiness? I understand how it justifies economic redistribution from a point of view that is already concerned with everyone's happiness.<br/><br/><blockquote class="uncited"><div> The "greatest number" notion is a compromise, admitting that in most practical circumstances it is not possible to make everyone happy.</div></blockquote><br/><br/>The compromise for me has nothing to do with the number of people who experience happiness or pain.<br/><br/><blockquote class="uncited"><div> Justice is not by itself "good". Rather it is "right". And I believe that doing what is right, means maximizing the good. The two are strongly correlated enough that in practice they are basically the same thing,</div></blockquote><br/><br/>If justice has to do with rights and desert then I don't think they are the same thing. <br/><br/><blockquote class="uncited"><div>I actually would argue it is unjust, that you aren't doing the right thing.</div></blockquote><br/><br/>I would just say that it was morally wrong.<br/><br/><blockquote class="uncited"><div>Interesting. I would say that Ethical Egoism is actually a perfectly rational if not necessarily correct moral theory. An ethical egoist doesn't value happiness intrinsically. Rather, they only value their own specific happiness and say that only happiness they can feel is good. Given that value, they can rationally act accordingly.</div></blockquote><br/><br/>I think that it is irrational for them to do this because there is no qualitative difference between their happiness and anyone else's. If a sadist-masochist saw nothing wrong with his own suffering and was just as willing to harm himself as he was to harm others, I wouldn't consider him to be irrational.<br/><br/><blockquote class="uncited"><div>The Ethical Egoist generally makes no effort to argue the fairness or justice of his/her position. I'm not defending that position, but rather simply stating that the value that we give to happiness is subject-oriented. That is to say, we value it not because there is some object called "happiness" out in the physical world, but that "happiness" is necessarily a subjective state that exists within the subject, and which is intrinsically valuable to it.</div></blockquote><br/><br/>I would argue against the idea that we 'value' happiness (that we give it it's value), we experience the value of happiness regardless of whatever rational judgement we make about it. Happiness may not exist 'out there' in the <span style="font-style: italic">physical</span> world but it does exist in objective reality. Any statement that you make about my subjective experience is true or false objectively because my experience is objectively real. It's only 'subjective' in that I'm the only one who has access to it.<br/><br/><br/><blockquote class="uncited"><div>Well, the essential part of this argument is that it has perfect knowledge of things like what emotions, preferences, or values would feel like if it had them</div></blockquote><br/><br/>I don't understand how it could have that knowledge without having experienced emotion. Even an implanted false memory of an emotion would be a real simulated experience of it.<br/><br/><blockquote class="uncited"><div>Anarcho-Capitalism would even be fine because everyone would probably start charities and create a "market" gift-economy anyway.</div></blockquote><br/><br/>In a utilitarian anarcho-capitalist society, utilitarian business owners would discourage customers from doing business with them if another company or business needed the money more , or they'd be willing to adjust their prices even if it would result in a net loss to them and an advantage to the customer. If a utilitarian gives no special consideration to his or her own welfare then they have no interest in competing with others whose welfare they are equally concerned with. I'm talking about a utilitarian society, not utilitarians in a non-utilitarian society who have to work within a non-utilitarian friendly system to provide private charities, share privately earned resources etc.<br/><br/><blockquote class="uncited"><div>So I actually wonder if it even really matters how the society is formally organized. If everyone is a perfect altruistic utilitarian, laws are redundant because people will generally do the right thing voluntarily, and that probably includes ignoring the laws that aren't utility maximizing (and this assumes that judges and law enforcement will look the other way when they do).</div></blockquote><br/><br/>I agree that laws would more or less be unnecessary in a society where everyone were a perfect utilitarian. I say more or less because even well-intentioned people can exercise poor judgment.<br/><br/><blockquote class="uncited"><div> It will probably resemble Anarcho-Communism in some ways, but if some state apparatus actually turns out to be useful, they won't be tied to that ideology.</div></blockquote><br/><br/>The problem that I have with this is that you seem to believe that you can separate moral ideology from political ideology. Your political ideology (which encompasses more than just what political system you support in practice but also the basic moral principles you use to justify supporting that system) is part of your general moral ideology. Everyone who supports an anarchist-communist society, or at least thinks that it would be ideal, is not a utilitarian but all consistent utilitarians have to think that an 'anarchist'-communist society would be ideal, even if they don't believe that attempting to establish one is practical.<br/><br/><blockquote class="uncited"><div>There might still be a market for people who like markets, but it would run alongside the gift-economy.</div></blockquote><br/><br/>There might still be self-interested competition for self-interested people who are OK - in principle- with competition , but it would run alongside the gift economy.<br/><br/><blockquote class="uncited"><div>So, I think, Communism and in even, Anarcho-Communism, is still too ideologically rigid to be the Utilitarian Utopia.</div></blockquote><br/><br/>I would understand your position if you were just arguing that communism is impractical, that's not my issue. My issue is with your not recognizing an inherent connection between hedonistic utilitarianism and communism, the former is predicated on the same basic ideal found in the latter ; equal consideration of interests = to each according to their need. Maybe hedonistic utilitarians should not promote hedonistic utilitarianism (explicitly, definitely they should promote some general idea of universal compassion even if things other then happiness are considered to be good or people aren't expected to give precisely equal consideration to strangers and family members), maybe they should promote Buddhism or some kind of 'liberalized', animal friendly version of Christianity without the concept of a hell or one dimensional devil but hedonistic utilitarians can only tolerate economic systems other than communism to the extent that they can tolerate ethical views other than hedonistic utilitarianism.<br/><br/>I went back and specified hedonistic utilitarianism because I was iffy about this applying to preference utilitarianism. I think democracy is the ideal system for preference utilitarianism, but not H.U, and democracy wouldn't necessarily take us to communism. A pref. utilitarian would argue for equal consideration of 'interests' but the specific preferences of different people aren't necessarily commensurable in any way, happiness is.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9038">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9039">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9039">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-07T20:20:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>I don't believe that subjective experience develops out of thin air at some arbitrary point in the development of a fetal nervous system, I believe that it's intrinsic to the basic building blocks of matter. I don't think that it can be created artificially by manipulating physical systems and that's why I don't think sentient A.I will ever exist. I'd be happy to be 'proven' wrong because I've always loved the idea of sentient A.I.<br/><br/>...<br/><br/>I would have agreed with you before I became a pan-psychist but I don't think that consciousness is something caused by physical activity in the brain. I believe the very concept of a qualitatively new kind of reality (first person subjective experience) emerging from inter-subjectively observable physical processes is incoherent. Even weak emergence of entirely new traits and characteristics is logically impossible, in my opinion.</div></blockquote><br/><br/>I disagree, mainly because I don't see how a normal rock could have any level of sentience.  Comets that fall into stars don't care that they are being destroyed.  All subjects are objects, but not all objects are subjects.  Subjects represent a subset of objects.  Subjective experience, in my view, arises from the internal mental states of a mind.  A mind is essentially like the software running on the hardware of a brain.  We cannot really point to the software in the physical world, but it nevertheless objectively exists, and somewhat resembles physical information.  Sentience in my view, emerges naturally from the integration of information, as suggested by <a class="postlink" href="http://en.wikipedia.org/wiki/Integrated_information_theory">Tononi's Integrated Information Theory</a> (IIT).  Objects in which there is no integration of information, like say, in a rock, are not sentient.  This is where IIT differs from Panpsychism.<br/><br/><blockquote class="uncited"><div>I think that an anarchist-communist society would be ideal and is preferable to state communism but the utilitarians in my ideal society would be willing to initiate coercion and force so they couldn't really be 'anarchists' in the same way that they couldn't be 'pacifists'. Definitely, a society without coercion and force would be better but it might be a good idea to have a party that is prepared to initiate force if it becomes necessary in future and it might still be necessary if most of the people were altruistic utilitarians but a minority were not ; and even like-minded people with the best intentions can have different ideas about how best to improve society.</div></blockquote><br/><br/>In general I would think that the differences in ideas would amount to differences in knowledge and rationality.  If everyone were really perfect utilitarians, then their values would essentially be the same, and the only area of disagreement would be over the how to implement those values, not why.  In such a situation, giving people relevant knowledge through communication, would go a long way to end disagreements.  It's kind of like how people who are in the same political party tend to agree with each other a lot, except take that to the extreme.<br/><br/><blockquote class="uncited"><div>I think that any kind of free market competition, even in a socialist society without capitalist 'exploitation', is in direct conflict with the basic premise of hedonistic utilitarianism (for the utilitarians themselves to favor this self-interested competition ; not necessarily to accept it pragmatically because other people aren't utilitarians). Markets don't always work better than central planning (doesn't regulated capitalism with social welfare benefits like public health care and public education works better than laissez faire capitalism? ) and when they do it has a lot to do with cultural and political values held by most people (like the incentive provided by self-interest) and not something intrinsic to the free market itself.</div></blockquote><br/><br/>I don't think that in a truly Utilitarian society, the free market would function like it does in capitalism.  "Competition" would be strictly a friendly sort of "well let's test to see who can make the best products with their different methods" kind of affair, and money might exist solely because of the usefulness of price signals.  For instance, in such a society, maybe everyone would be granted a basic income of "social credits" or unlimited access to no-interest loans.  The whole point of having money then, would be to help producers figure out what was in demand so they could better supply it.<br/><br/><blockquote class="uncited"><div>I don't think that will ever be a practical concern, I don't think we'll ever come across sentient alien life (regardless of whether or not they exist). If we do, utilitarians should care no less about the alien invaders than about other humans.</div></blockquote><br/><br/>Of course we'll care about the invaders.  The ideal Utilitarian army would shoot to disable with hypothetical temporary paralysis guns (phasors set to stun?) rather than shoot to kill.  The point is that a Utilitarian Society might have to protect itself from non-Utilitarian societies and states.<br/><br/><blockquote class="uncited"><div>How does diminishing marginal utility justify an impartial concern for everyone's happiness? I understand how it justifies economic redistribution from a point of view that is already concerned with everyone's happiness.</div></blockquote><br/><br/>It doesn't actually.  It only specifics that in practice we'll end up being functionally more egalitarian than not.  I probably shouldn't have included it in my argument.<br/><br/><blockquote class="uncited"><div>If justice has to do with rights and desert then I don't think they are the same thing. </div></blockquote><br/><br/>Justice has to do with what is right (or moral), not "rights".  And desert is how we justify the good.  This really only matters as an argument to people who see what is right and what is good as being different.<br/><br/><blockquote class="uncited"><div>I think that it is irrational for them to do this because there is no qualitative difference between their happiness and anyone else's. If a sadist-masochist saw nothing wrong with his own suffering and was just as willing to harm himself as he was to harm others, I wouldn't consider him to be irrational.</div></blockquote><br/><br/>Rationality is doing what achieves one's goals or values.  Rational does not mean the same thing as moral.<br/><br/><blockquote class="uncited"><div>I would argue against the idea that we 'value' happiness (that we give it it's value), we experience the value of happiness regardless of whatever rational judgement we make about it. Happiness may not exist 'out there' in the physical world but it does exist in objective reality. Any statement that you make about my subjective experience is true or false objectively because my experience is objectively real. It's only 'subjective' in that I'm the only one who has access to it.</div></blockquote><br/><br/>I actually agree with this.  I think we're basically saying the same thing differently.<br/><br/><blockquote class="uncited"><div>I don't understand how it could have that knowledge without having experienced emotion. Even an implanted false memory of an emotion would be a real simulated experience of it.</div></blockquote><br/><br/>Thus, why I said it may be incoherent and modified the argument.<br/><br/><blockquote class="uncited"><div>In a utilitarian anarcho-capitalist society, utilitarian business owners would discourage customers from doing business with them if another company or business needed the money more , or they'd be willing to adjust their prices even if it would result in a net loss to them and an advantage to the customer. If a utilitarian gives no special consideration to his or her own welfare then they have no interest in competing with others whose welfare they are equally concerned with. I'm talking about a utilitarian society, not utilitarians in a non-utilitarian society who have to work within a non-utilitarian friendly system to provide private charities, share privately earned resources etc.</div></blockquote><br/><br/>Again, a truly Utilitarian market would not be the same as the market as we usually conceive of it.  Competition would be solely for the benefit of finding out who was better at producing things, and money would be just to send price signals and convey information about supply and demand.  These things are useful enough that I think we wouldn't need to abandon them.  We would simply have an understanding that they were subordinate to the general welfare and structure them accordingly, i.e. with everyone being given access to as much social credit money as the economy allows.  It would, I conjecture, look very different from capitalism as we understand it today.<br/><br/><blockquote class="uncited"><div>I agree that laws would more or less be unnecessary in a society where everyone were a perfect utilitarian. I say more or less because even well-intentioned people can exercise poor judgment.</div></blockquote><br/><br/>But even so, their motives would be good, so it would be very hard to prosecute them.  There arguably wouldn't be any crimes of malice, but only accidents and mistakes of people with good intentions and unfortunate ignorance.<br/><br/><blockquote class="uncited"><div>The problem that I have with this is that you seem to believe that you can separate moral ideology from political ideology. Your political ideology (which encompasses more than just what political system you support in practice but also the basic moral principles you use to justify supporting that system) is part of your general moral ideology. Everyone who supports an anarchist-communist society, or at least thinks that it would be ideal, is not a utilitarian but all consistent utilitarians have to think that an 'anarchist'-communist society would be ideal, even if they don't believe that attempting to establish one is practical.<br/><br/>I would understand your position if you were just arguing that communism is impractical, that's not my issue. My issue is with your not recognizing an inherent connection between hedonistic utilitarianism and communism, the former is predicated on the same basic ideal found in the latter ; equal consideration of interests = to each according to their need. Maybe hedonistic utilitarians should not promote hedonistic utilitarianism (explicitly, definitely they should promote some general idea of universal compassion even if things other then happiness are considered to be good or people aren't expected to give precisely equal consideration to strangers and family members), maybe they should promote Buddhism or some kind of 'liberalized', animal friendly version of Christianity without the concept of a hell or one dimensional devil but hedonistic utilitarians can only tolerate economic systems other than communism to the extent that they can tolerate ethical views other than hedonistic utilitarianism.<br/><br/>I went back and specified hedonistic utilitarianism because I was iffy about this applying to preference utilitarianism. I think democracy is the ideal system for preference utilitarianism, but not H.U, and democracy wouldn't necessarily take us to communism. A pref. utilitarian would argue for equal consideration of 'interests' but the specific preferences of different people aren't necessarily commensurable in any way, happiness is.</div></blockquote><br/><br/>My own thinking is that Utilitarian moral principles don't necessarily support any society that has absolute principles like "money is bad" or "property is theft".  Utilitarianism is concerned with consequences, and so would support the society that has the best consequences regardless of what it looks like from an ideological perspective.  Communism is not just concerned with "equal consideration of interests = to each according to their need".  Communism also has an inherent ideological bias that says "property is evil, and power should be equalized".  Communism is founded on a kind of deontological schema which doesn't square with Utilitarianism's inherently consequentialist outlook.  The truth is, we don't actually know that Communism would be utility maximizing, even if everyone were perfect Utilitarians, and even if Communism does seem to share some principles with Utilitarianism.<br/><br/>To me that Communism seems to share a very similar moral outlook as Utilitarianism is enough to perhaps consider it as a possible form of society, and to make me sympathetic to it, but it doesn't convince me that I must support it as the ideal.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9039">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9050">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9050">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-10T17:27:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>I disagree, mainly because I don't see how a normal rock could have any level of sentience.  Comets that fall into stars don't care that they are being destroyed.  All subjects are objects, but not all objects are subjects.  Subjects represent a subset of objects.</div></blockquote><br/><br/>I don't believe that all physical objects have a unified consciousness, only that they're made up of 'things' that do. I think that the elementary particles, atoms and molecules that comprise a rock are sentient but not the rock qua rock.<br/><br/><br/><br/><blockquote class="uncited"><div>In general I would think that the differences in ideas would amount to differences in knowledge and rationality.  If everyone were really perfect utilitarians, then their values would essentially be the same, and the only area of disagreement would be over the how to implement those values, not why.  In such a situation, giving people relevant knowledge through communication, would go a long way to end disagreements.  It's kind of like how people who are in the same political party tend to agree with each other a lot, except take that to the extreme.</div></blockquote><br/><br/>I'm sure it would but people would still have important disagreements. I remember the Dalai Lama saying something like this ; that even in a world where everyone was more compassionate there would still be serious disagreements. I don't disagree with your point, though. <br/><br/><br/><br/><blockquote class="uncited"><div>I don't think that in a truly Utilitarian society, the free market would function like it does in capitalism.  "Competition" would be strictly a friendly sort of "well let's test to see who can make the best products with their different methods" kind of affair, and money might exist solely because of the usefulness of price signals.  For instance, in such a society, maybe everyone would be granted a basic income of "social credits" or unlimited access to no-interest loans.  The whole point of having money then, would be to help producers figure out what was in demand so they could better supply it.</div></blockquote><br/><br/>That wouldn't be a free market economy as I understand it. Even in the same company people might compete with their ideas but (even if there's a competition for certain positions in the company) it's a form of co-operation  because the objective is to make the company successful. The kind of free market 'competition' in a utilitarian society that could exist wouldn't be motivated by a desire for personal profit, it would be to produce the highest quality goods and services for the community and it wouldn't result in resources being distributed on the basis of merit as opposed to need.<br/><br/><br/><br/><blockquote class="uncited"><div>It doesn't actually.  It only specifics that in practice we'll end up being functionally more egalitarian than not.  I probably shouldn't have included it in my argument.</div></blockquote><br/><br/>How does diminishing marginal utility not justify economic redistribution? I mean I can understand some purely hypothetical and impractical scenarios when a millionaire would benefit more from an additional million dollars than 10 low income people would from being given $100 000 each but I don't think that a person can even theoretically not become desensitized to a specific source of pleasure over time, it's only a question of how sensitive they are.<br/><br/><br/><blockquote class="uncited"><div>Justice has to do with what is right (or moral), not "rights".</div></blockquote><br/><br/>Most of the definitions I've come across involve the concept of rights and desert that it is determined by innocence or guilt and not just one's status as a person but I don't care about the word. If 'justice' is just doing what's morally right then there's no issue but everyone else who uses the word may not have in mind what you do. <br/><br/><br/><blockquote class="uncited"><div>  And desert is how we justify the good.</div></blockquote><br/><br/>Doesn't the good justify the good?<br/><br/>"Compassion isn't given because it's deserved, Buffy, it's given because it's needed" - Rupert Giles.<br/><br/><blockquote class="uncited"><div>  This really only matters as an argument to people who see what is right and what is good as being different.</div></blockquote><br/><br/>The ethics of justice that many people advocate regards giving people their due (beneficial and harmful) as good in itself.<br/><br/><br/><blockquote class="uncited"><div>Rationality is doing what achieves one's goals or values.  Rational does not mean the same thing as moral.</div></blockquote><br/><br/>Then his position is inconsistent.<br/><br/><br/><br/><blockquote class="uncited"><div>Again, a truly Utilitarian market would not be the same as the market as we usually conceive of it.  Competition would be solely for the benefit of finding out who was better at producing things, and money would be just to send price signals and convey information about supply and demand.  These things are useful enough that I think we wouldn't need to abandon them.  We would simply have an understanding that they were subordinate to the general welfare and structure them accordingly, i.e. with everyone being given access to as much social credit money as the economy allows.  It would, I conjecture, look very different from capitalism as we understand it today.</div></blockquote><br/><br/>If that's the case then this 'free market competition' is compatible with communism. But it's not the free market competition I'm talking about.<br/><br/><br/><blockquote class="uncited"><div>But even so, their motives would be good, so it would be very hard to prosecute them.  There arguably wouldn't be any crimes of malice, but only accidents and mistakes of people with good intentions and unfortunate ignorance.</div></blockquote><br/><br/>I agree.<br/><br/><br/><br/><blockquote class="uncited"><div>My own thinking is that Utilitarian moral principles don't necessarily support any society that has absolute principles like "money is bad" or "property is theft". Utilitarianism is concerned with consequences, and so would support the society that has the best consequences regardless of what it looks like from an ideological perspective. </div></blockquote><br/><br/>You're still separating the political from the moral. Utilitarianism is a moral ideology. It's predicated on an absolute principle ( X is the only ultimate good and maximizing it should be the sole objective of all decisions ; everyone's X should be given equal consideration because X is all that matters) and political principles can be judged as consistent or inconsistent with this moral idea, even if actual political systems should not supported or rejected for that reason. <span style="font-style: italic">The argument as to which kind of a society has the best consequences is a separate argument from which kind of a society is consistent with the basic premise of utilitarianism...</span> Like I said, my issue is not with whether or not you think communism works but whether or not it's consistent with the basis premise of utilitarianism. <span style="font-style: italic">If</span> we should promote utilitarianism <span style="font-style: italic">then</span> this involves promoting communism.. <br/><br/><blockquote class="uncited"><div> Communism is not just concerned with "equal consideration of interests = to each according to their need".  Communism also has an inherent ideological bias that says "property is evil, and power should be equalized".</div></blockquote> <br/><br/>I think that you're confusing communism with Marxism. Marxism views the capitalist exploitation of the working class as an injustice - not because their well-being is given less consideration but because capitalists have no right to exploit their labor for personal profit (which is one example of fairness being in the eye of the beholder, i.m.o), Marx never had a purely utilitarian concern with maximizing the balance of happiness over suffering (he once said something along the lines of 'the last capitalist that we will do business with is the one from whom we purchase the rope to hang him with' - 'justice' often involves this kind of callous retributivist attitude against perceived wrong doers).<br/><br/><blockquote class="uncited"><div>Communism is founded on a kind of deontological schema which doesn't square with Utilitarianism's inherently consequentialist outlook.</div></blockquote><br/><br/><br/>No, not communism. <span style="font-style: italic">Marxism</span>. You can give a utilitarian or non-utilitarian argument for some kind of communist system.<br/><br/><blockquote class="uncited"><div>The truth is, we don't actually know that Communism would be utility maximizing, even if everyone were perfect Utilitarians, and even if Communism does seem to share some principles with Utilitarianism. To me that Communism seems to share a very similar moral outlook as Utilitarianism is enough to perhaps consider it as a possible form of society, and to make me sympathetic to it, but it doesn't convince me that I must support it as the ideal.</div></blockquote><br/><br/>In a society where everyone was a perfect utilitarian, they would distribute resources among themselves on the basis of benefit alone with no regard to merit, luck or natural property rights -this would be a communist economy. I do not understand how you cannot see that. <br/><br/>1)The sole objective of hedonistic utilitarianism is to maximize the ratio of happiness-suffering in the universe<br/><br/>2)It logically follows that the ideal economic system, according to hedonistic utilitarianism, would be one in which resources are distributed on the basis of benefit alone. <br/><br/>Why?<br/><br/>3)Because benefit (happiness) is the only morally relevant criterion for determining which economic system is ideal. <br/><br/>Perfect utilitarians would be motivated to maximize the general happiness and not just (or even primarily) their own, if someone else would benefit more from something that a perfect utilitarian owned then (s)he would give it away. Nobody would have an excess of any goods that could produce a greater amount of happiness if shared and no one would have a preference for themselves to benefit from something rather than someone else if the expected benefit for each was equal.<br/><br/><br/>How can you<span style="font-style: italic"> possibly</span> deny that the ideal utilitarian economy would be one in which resources were distributed solely on the basis of benefit and if you agree that - because happiness is the only thing that hedonistic utilitarians regard as morally relevant- a utilitarian economy would be one in which resources would be distributed on the basis of benefit alone then how would this not be a communist economy??</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9050">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9052">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9052">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-10T21:19:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>I don't believe that all physical objects have a unified consciousness, only that they're made up of 'things' that do. I think that the elementary particles, atoms and molecules that comprise a rock are sentient but not the rock qua rock.</div></blockquote><br/><br/>Why or how would elementary particles, atoms, and molecules be sentient, but not the rock?<br/><br/><blockquote class="uncited"><div>I'm sure it would but people would still have important disagreements. I remember the Dalai Lama saying something like this ; that even in a world where everyone was more compassionate there would still be serious disagreements. I don't disagree with your point, though. </div></blockquote><br/><br/>Yeah, I've thought about it some more, and I admit that there would be disagreements over the how and what.  We would just have taken out the disagreement over why.<br/><br/><blockquote class="uncited"><div>That wouldn't be a free market economy as I understand it. Even in the same company people might compete with their ideas but (even if there's a competition for certain positions in the company) it's a form of co-operation because the objective is to make the company successful. The kind of free market 'competition' in a utilitarian society that could exist wouldn't be motivated by a desire for personal profit, it would be to produce the highest quality goods and services for the community and it wouldn't result in resources being distributed on the basis of merit as opposed to need.</div></blockquote><br/><br/>True, it doesn't fit the usual definition of a "free market economy" as economics understands it.<br/><br/><blockquote class="uncited"><div>How does diminishing marginal utility not justify economic redistribution? I mean I can understand some purely hypothetical and impractical scenarios when a millionaire would benefit more from an additional million dollars than 10 low income people would from being given $100 000 each but I don't think that a person can even theoretically not become desensitized to a specific source of pleasure over time, it's only a question of how sensitive they are.</div></blockquote><br/><br/>I didn't mean that it doesn't justify economic redistribution in practice.  I meant only that it doesn't "justify an impartial concern for everyone's happiness".  Which is to say I was agreeing with you.<br/><br/><blockquote class="uncited"><div>Doesn't the good justify the good?<br/><br/>"Compassion isn't given because it's deserved, Buffy, it's given because it's needed" - Rupert Giles.</div></blockquote><br/><br/>I'll admit I smiled when you quoted Giles. <img alt=":)" src="../images/smilies/icon_e_smile.gif"/><br/><br/>Some would argue that the good justifying the good is circular reasoning, that you have to have an outside justification for the good.  I thus apply the notion of the "right" to justify the good.  If you're willing to believe that the good is just intrinsically justified, then there's no real reason to appeal to the right.  I'm honestly somewhat undecided on whether the good justifies itself.<br/><br/><blockquote class="uncited"><div>The ethics of justice that many people advocate regards giving people their due (beneficial and harmful) as good in itself.</div></blockquote><br/><br/>And I argue that people by virtue of their nature are due benefit over harm, and so the ethics of justice actually supports Utilitarianism.<br/><br/><blockquote class="uncited"><div>Then his position is inconsistent.</div></blockquote><br/><br/>Only if he values morality.  Some people don't.<br/><br/><blockquote class="uncited"><div>You're still separating the political from the moral. Utilitarianism is a moral ideology. It's predicated on an absolute principle ( X is the only ultimate good and maximizing it should be the sole objective of all decisions ; everyone's X should be given equal consideration because X is all that matters) and political principles can be judged as consistent or inconsistent with this moral idea, even if actual political systems should not supported or rejected for that reason. The argument as to which kind of a society has the best consequences is a separate argument from which kind of a society is consistent with the basic premise of utilitarianism... Like I said, my issue is not with whether or not you think communism works but whether or not it's consistent with the basis premise of utilitarianism. If we should promote utilitarianism then this involves promoting communism..<br/><br/>I think that you're confusing communism with Marxism. Marxism views the capitalist exploitation of the working class as an injustice - not because their well-being is given less consideration but because capitalists have no right to exploit their labor for personal profit (which is one example of fairness being in the eye of the beholder, i.m.o), Marx never had a purely utilitarian concern with maximizing the balance of happiness over suffering (he once said something along the lines of 'the last capitalist that we will do business with is the one from whom we purchase the rope to hang him with' - 'justice' often involves this kind of callous retributivist attitude against perceived wrong doers).<br/><br/>No, not communism. Marxism. You can give a utilitarian or non-utilitarian argument for some kind of communist system.</div></blockquote><br/><br/>Marxism was for the longest time the dominant stream of communist thought, so please excuse me for assuming that you meant Marxist communism.<br/><br/><blockquote class="uncited"><div>In a society where everyone was a perfect utilitarian, they would distribute resources among themselves on the basis of benefit alone with no regard to merit, luck or natural property rights -this would be a communist economy. I do not understand how you cannot see that. <br/><br/>1)The sole objective of hedonistic utilitarianism is to maximize the ratio of happiness-suffering in the universe<br/><br/>2)It logically follows that the ideal economic system, according to hedonistic utilitarianism, would be one in which resources are distributed on the basis of benefit alone. <br/><br/>Why?<br/><br/>3)Because benefit (happiness) is the only morally relevant criterion for determining which economic system is ideal. <br/><br/>Perfect utilitarians would be motivated to maximize the general happiness and not just (or even primarily) their own, if someone else would benefit more from something that a perfect utilitarian owned then (s)he would give it away. Nobody would have an excess of any goods that could produce a greater amount of happiness if shared and no one would have a preference for themselves to benefit from something rather than someone else if the expected benefit for each was equal.<br/><br/><br/>How can you possibly deny that the ideal utilitarian economy would be one in which resources were distributed solely on the basis of benefit and if you agree that - because happiness is the only thing that hedonistic utilitarians regard as morally relevant- a utilitarian economy would be one in which resources would be distributed on the basis of benefit alone then how would this not be a communist economy??</div></blockquote><br/><br/>If you define communism as simply an economy where "resources are distributed solely on the basis of benefit", then yes, an ideal Utilitarian economy would match this.  However, communism is more than that.  To my knowledge, all forms of communism make certain assumptions and moral assertions, that private property should be disallowed, that all resources should be held communally somehow, and so on.  These may be good heuristics to follow in a society of Utilitarians, but they should be treated as just that, heuristics rather than ideological requirements.<br/><br/>There may well be exceptions where some notion of property can allow people to be more responsible with objects because there is a clear delineation of who is responsible for what.  Again, the usefulness of property, money, and other economic devices could mean that conceivably a Utilitarian ideal economy would not need to be strictly communist.  It would not by any means be what we describe as capitalism either.  It may strongly resemble a gift economy.<br/><br/>Here's one example of how a Utilitarian society would differ from Communism.  In a pure communist society such as an Israeli Kibbutz, children would be raised collectively rather than by their parents.  This is an ideological choice that Kibbutz members felt was warranted by their ideology.  This practice had significant problems, because of things like the Westermarck effect, where children who are raised together do not find each other sexually attractive in later life.<br/><br/>A Utilitarian society would therefore have to decide based on the benefits whether or not children should be raised communally.  In the same way, a Utilitarian society should determine its economics based on actual benefits, rather than ideological reasons.  This is not the same as saying that Communism wouldn't work in practice.  I'm saying that even if Communism worked perfectly in a society of perfect Utilitarians, we would still be adopting it because of its positive consequences, rather than because it was ideologically correct.<br/><br/>Communism and Utilitarianism are distinct ideological frameworks.  If you are truly being Utilitarian, you would adopt the Utilitarian framework, not the Communist framework.  The communist economy may be compatible with the Utilitarian framework, but you cannot hold both frameworks as absolute simultaneously.  In the end, if you want to be consistent, you have to consider one ideology to be the correct one, and all others, to be correct only to the extent that they fit the correct ideology.<br/><br/>This is one thing that I don't think you realize.  Communism, even non-Marxist communism, is an ideology.  It prescribes certain things and makes statements that have a moral character to them.  Utilitarianism is a moral ideology.  It is almost totalitarian in the sense that it prescribes that everything you do should follow the principle of Greatest Happiness.  I assert therefore, that Utilitarianism is incompatible with ideological Communism, as it is with any other totalitarian ideology.<br/><br/>I am a liberal only in the sense that I find liberalism a useful set of ideas, but underlying it all is a Utilitarian justification.  Liberalism is my politics, but Utilitarianism is my philosophy.<br/><br/>Similarly, if all people were perfect Utilitarians, I would probably espouse anarcho-communist politics, but the underlying philosophical justification would not be Communism, but Utilitarianism.<br/><br/>I think the confusion we're having is that communism is both a kind of social order, and an ideology.  You see communism as a social order that closely matches what Utilitarianism wants, I see communism as a competing ideology.  I will concede that the social order of anarcho-communism is probably what a world of pure utilitarians would want to create, that it is closest to the basic premises and principles of Utilitarianism of any of the possible systems that we have thought of so far.  However, I do not think that the match is necessarily perfect, and I caution you not to confuse the useful social order of communism with the political, social, economic, and moral ideology that communism is capable of being.<br/><br/>And for that reason, I don't think that if we should promote Utilitarianism, that this involves promoting communism.  Because if you try to do so, people will almost certainly confuse you with promoting ideological communism, even if you are just promoting social order communism as an eventual ideal after everyone has become Utilitarian.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9052">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9061">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9061">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-12T18:09:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote class="uncited"><div>Why or how would elementary particles, atoms, and molecules be sentient, but not the rock?</div></blockquote><br/><br/>Rocks don't appear to behave with agency, they show no spontaneity and only react to stimuli. <br/><br/><blockquote class="uncited"><div>Some would argue that the good justifying the good is circular reasoning, that you have to have an outside justification for the good.  I thus apply the notion of the "right" to justify the good.  If you're willing to believe that the good is just intrinsically justified, then there's no real reason to appeal to the right.  I'm honestly somewhat undecided on whether the good justifies itself.</div></blockquote><br/><br/>I could give circular reasoning as to why the good is the good but to say that something is 'good' is to say that it is favorable, desirable, agreeable, preferable etc. To say that we should maximize happiness for any reason other than happiness being good is to deny that happiness is intrinsically good. An ultimate external justification for X (Y) would mean that Y was inherently good and not X, wouldn't it?<br/><br/>In my view, wanting others to experience happiness is not itself intrinsically good, it's <span style="font-style: italic">warranted</span> because happiness is intrinsically good. I don't think I can imagine a conceivable universe where a rational moral agent wouldn't necessarily be more likely to maximize happiness if doing so ; which involves giving everyone's happiness equal consideration , wasn't the explicit goal of all their decisions (also, for a self-aware and rational being, I think that feeling connected to all beings and wishing them happiness and freedom from suffering is the key to stable, long-term happiness that isn't dependent on external circumstances, far more than any other attitude).<br/><br/><br/><blockquote class="uncited"><div>And I argue that people by virtue of their nature are due benefit over harm, and so the ethics of justice actually supports Utilitarianism.</div></blockquote><br/><br/>I wouldn't disagree that all beings deserve happiness because happiness being worth maximizing implies to me that the experiencers of happiness are worthy of happiness since you can't have an experience without an experiencer (maybe this is just an interpretation) but arguing that we should maximize happiness because it's due (and giving people their due is good) is different than arguing that we should maximize happiness because happiness is good. I don't think that the universe owes anyone happiness but the existence of happiness is better than suffering (as well as no experience which is itself better than suffering).<br/><br/><br/><blockquote class="uncited"><div>Only if he values morality.  Some people don't.</div></blockquote><br/><br/>Or I could argue that some people don't value egalitarianism/impartiality, meaning they have a morality of egocentrism. Morality is just a question of what are good decisions to make (this can be in terms of what kind of character we should develop as well as how we should behave) and why. Then again, maybe he does think,intellectually, that other people's interests deserve consideration but he just doesn't care emotionally.<br/><br/><blockquote class="uncited"><div>Marxism was for the longest time the dominant stream of communist thought, so please excuse me for assuming that you meant Marxist communism.</div></blockquote><br/><br/>I definitely do not, I don't think Marxism is compatible with utilitarianism.<br/><br/><br/><blockquote class="uncited"><div>If you define communism as simply an economy where "resources are distributed solely on the basis of benefit", then yes, an ideal Utilitarian economy would match this.  However, communism is more than that.</div></blockquote><br/><br/>My understanding was that 'communism' refers to an economic system that can be justified based on different political/moral principles or assumptions.<br/><br/><blockquote class="uncited"><div>  To my knowledge, all forms of communism make certain assumptions and moral assertions, that private property should be disallowed, that all resources should be held communally somehow, and so on.  These may be good heuristics to follow in a society of Utilitarians, but they should be treated as just that, heuristics rather than ideological requirements.</div></blockquote><br/><br/>An ideological requirement for hedonistic utilitarians is that everyone's happiness should be given equal and unconditional consideration which would necessarily lead to favoring (ideally) an economic system where resources would be distributed purely on the basis of benefit (and means of production being controlled for the benefit of the community as a whole if not controlled by the community as a whole) - maybe I'm wrong to call this 'communism'. My only argument is that a hedonistic utilitarian economy would be one in which resources were distributed on the basis of benefit, whether utilitarians should promote a utilitarian economy or not is another matter.<br/><br/><blockquote class="uncited"><div>There may well be exceptions where some notion of property can allow people to be more responsible with objects because there is a clear delineation of who is responsible for what.  Again, the usefulness of property, money, and other economic devices could mean that conceivably a Utilitarian ideal economy would not need to be strictly communist.  It would not by any means be what we describe as capitalism either.  It may strongly resemble a gift economy.</div></blockquote><br/><br/>If the state isn't distributing goods and services on the basis of expected benefit and centrally planning the economy with the interests of the community in mind then a hedonistic utilitarian economy wouldn't just resemble a gift economy, it would be a gift economy.<br/><br/><blockquote class="uncited"><div>Here's one example of how a Utilitarian society would differ from Communism.  In a pure communist society such as an Israeli Kibbutz, children would be raised collectively rather than by their parents.  This is an ideological choice that Kibbutz members felt was warranted by their ideology.  This practice had significant problems, because of things like the Westermarck effect, where children who are raised together do not find each other sexually attractive in later life.</div></blockquote><br/><br/>I've read a little about the Israeli Kibbutz system but I don't know a lot about it. There were some advantages, weren't they? I think there are also good arguments to be made for communal rearing of children (not necessarily the Kibbutz style system, even just some kind of 'it takes a village to raise a child' mentality). For one, it should be noted that in a utilitarian economy (whether it was stateless gift economy or centrally planned) families would no longer acquire and share resources as a distinct group, the entire community would. This is one of the key distinguishing characteristics of the family in agricultural societies. Maybe the community as a whole would think of themselves as an extended family.<br/><br/><a class="postlink" href="http://www.livestrong.com/article/559901-the-effects-of-raising-children-communally/">http://www.livestrong.com/article/55990 ... ommunally/</a><br/><br/>-There are some benefits to communal child rearing but I agree that you can give a utilitarian argument against it. With the Westermark effect specifically, children could grow up to become romantically interested in people from other local communities.<br/><br/><br/><blockquote class="uncited"><div>In the same way, a Utilitarian society should determine its economics based on actual benefits, rather than ideological reasons.  This is not the same as saying that Communism wouldn't work in practice.  I'm saying that even if Communism worked perfectly in a society of perfect Utilitarians, we would still be adopting it because of its positive consequences, rather than because it was ideologically correct.</div></blockquote><br/><br/>Here's where we still disagree and I don't understand your position. There is no possible way that a utilitarian economy would not be 'communist' if we define communism simply as an economic system where resources are distributed solely the basis of benefit. It's not a question of whether or not it would have the best consequences (and once you account for all other factors - what other system besides one that distributes resources according to *benefit* could have better consequences?), <span style="font-style: italic">if</span> every member of this society was a hedonistic utilitarian then they would share resources among themselves according to benefit.<br/><br/>Hedonistic utilitarians should not want to promote hedonistic utilitarianism for it's own sake, they should want to maximize happiness and minimize suffering for it's own sake (it may be that promoting H.U is necessarily the best way to do this but just adhering to the ideology itself has no inherent value). The utilitarians in a utilitarian economy would not be deontological communists in the exact same way that they wouldn't be committed to promoting H.U for it's own sake but <span style="font-style: italic">you're saying that a society of perfectly consistent hedonistic utilitarians might not develop a gift economy where resources are distributed on the basis of benefit alone makes no sense whatsoever because you're flat out admitting that these utilitarians would care about something other than (the general) happiness</span>.. <br/><br/>For the record, if I identify with state communism over an 'anarchist' gift economy it's only because, in principle I'm O.K with a party that is prepared to initiate force and centrally plan the economy through coercion but if everyone were perfectly moral and always would be then a stateless gift economy would be ideal, I'm not an anarchist because I'm not opposed necessarily to the initiation of force. 'Anarchism' I see as an ideology and not just a preference for a society without coercion and force, 'communism' is just an economic system.<br/><br/><blockquote class="uncited"><div>Communism and Utilitarianism are distinct ideological frameworks.</div></blockquote><br/><br/>Communism, as I've used the term, is just an economic system. The ideologies that favor it are 'collectivist' but there is no one communist ideology. <br/><br/><blockquote class="uncited"><div>  If you are truly being Utilitarian, you would adopt the Utilitarian framework, not the Communist framework.  The communist economy may be compatible with the Utilitarian framework, but you cannot hold both frameworks as absolute simultaneously.  In the end, if you want to be consistent, you have to consider one ideology to be the correct one, and all others, to be correct only to the extent that they fit the correct ideology.</div></blockquote><br/><br/>I would agree if I regarded communism as an ideology. Or if communism is an ideology, I only favor it because it's consistent with the premise of utilitarianism. Utilitarians have to ideally favor a communist economy despite communists not necessarily being utilitarians.<br/><br/>And by the way, you can't see how this same reasoning would require the good to justify itself without some kind of external justification?<br/><br/><br/><br/><blockquote class="uncited"><div>This is one thing that I don't think you realize.  Communism, even non-Marxist communism, is an ideology.</div></blockquote><br/><br/>Clearly, I'm not talking about the 'communism' that you are. But even if we settled this, we still disagree about what a utilitarian economy would <span style="font-style: italic">necessarily have</span> to look like, never mind whether or not utilitarians should promote a utilitarian economy.<br/><br/><blockquote class="uncited"><div>  It prescribes certain things and makes statements that have a moral character to them.</div></blockquote><br/><br/>When I've used the term 'communism', have I ever given you the impression that I meant anything other than an *economy* where resources are distributed according to benefit ( meaning according to who is made<span style="text-decoration: underline"> happiest</span> by those resources..). I do not believe that 'property is theft' or that capitalism is exploitation. I'm not a Marxist.<br/><br/><blockquote class="uncited"><div>  Utilitarianism is a moral ideology.  It is almost totalitarian in the sense that it prescribes that everything you do should follow the principle of Greatest Happiness.  I assert therefore, that Utilitarianism is incompatible with ideological Communism, as it is with any other totalitarian ideology. </div></blockquote><br/><br/>So utilitarianism, which is almost totalitarian, is incompatible with ideological communism because it is totalitarian? 'Totalitarianism' refers to a political system where the state has complete authority and control over a society.<br/><br/>So what specifically do you think 'ideological' communists advocate and for what reason? Kropotkin, Marx and Bakunin had very different ideas. <br/><br/><blockquote class="uncited"><div>I am a liberal only in the sense that I find liberalism a useful set of ideas, but underlying it all is a Utilitarian justification.  Liberalism is my politics, but Utilitarianism is my philosophy.</div></blockquote><br/><br/>'Liberalism' may not be an explicit and unified ideology but the differences between liberals and conservatives are not just differences regarding how best to implement shared ideological values, they are fundamental ideological differences. <br/><br/><blockquote class="uncited"><div>Similarly, if all people were perfect Utilitarians, I would probably espouse anarcho-communist politics, but the underlying philosophical justification would not be Communism, but Utilitarianism.</div></blockquote><br/><br/>I would argue that utilitarianism is incompatible with anarchism in the same way you think that utilitarianism is incompatible with communism. <br/><br/><blockquote class="uncited"><div>I think the confusion we're having is that communism is both a kind of social order, and an ideology.  You see communism as a social order that closely matches what Utilitarianism wants, I see communism as a competing ideology.  I will concede that the social order of anarcho-communism is probably what a world of pure utilitarians would want to create, that it is closest to the basic premises and principles of Utilitarianism of any of the possible systems that we have thought of so far.  However, I do not think that the match is necessarily perfect, and I caution you not to confuse the useful social order of communism with the political, social, economic, and moral ideology that communism is capable of being.</div></blockquote><br/><br/>Communism, as I've used the term, is not an ideology. It is an economic system. Your argument would make sense if you substituted 'communism' with 'anarchism' or 'pacifism' because these are fundamentally deontological positions. Anarchists (ie. consistent libertarians) oppose the initiation of force - not because of the suffering it causes - but because people have a right to autonomy. Pacifists oppose violence in all circumstances - again, not because of the suffering violence causes - but because the act of inflicting physical pain is bad even if it's necessary to prevent more pain than it causes. Still, a utilitarian would ideally favor a society without the initiation of force or any violence at all. There is no such conflict between utilitarianism and the communism I've outlined because my 'communism' is an economic system, not a deontological position stating that you should never allow private property or free market competition because these things are intrinsically bad.<br/><br/>That's not what really blows me away, though. I can understand your thinking that 'communism' comes with ideological baggage that isn't in sync with utilitarian ethics. What I don't understand (and this truly blows me the fuck away!), is not how utilitarianism doesn't necessarily lead us to a favor an economy where resources are distributed according to benefit in practice but that a society of perfect utilitarians would not necessarily distribute resources among themselves according to benefit. So if John is a perfect utilitarian and he knows that his next door neighbor or anyone else would benefit more from a good that he owns than he would, he would not necessarily share his belonging despite the fact that doing so would result in a greater amount of happiness. Or if some hospital has a limited amount of medicine that one person badly needs and another would only mildly benefit from, the medicine would not be given to the person who needs it more. Merit, luck or things other than HAPPINESS would determine how a society of perfect hedonistic utilitarians would distribute resources...<br/><br/><blockquote class="uncited"><div>And for that reason, I don't think that if we should promote Utilitarianism, that this involves promoting communism.  Because if you try to do so, people will almost certainly confuse you with promoting ideological communism, even if you are just promoting social order communism as an eventual ideal after everyone has become Utilitarian.</div></blockquote><br/><br/>If I were interested in promoting communism (the economic system) I would try to make it as explicitly clear as possible that I favored a communist economy only because I believe everyone's well-being should be given equal and unconditional consideration and thus that resources should be dispensed on the basis of how much happiness they cause (or how much suffering they alleviate).</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9061">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9062">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9062">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-12T19:34:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>Rocks don't appear to behave with agency, they show no spontaneity and only react to stimuli. </div></blockquote><br/><br/>So agency is a necessary component of sentience?  What if a person suffered brain damage that caused full body paralysis, but left the person fully aware and able to feel things?  Would this person no longer be sentient?<br/><br/>How exactly do atoms behave with agency?  Is it because they appear to move around of their own volition?  Asteroids move around in orbits in a similar way that electrons move around in orbits around an atomic nucleus.  Do asteroids (rocks in space) have agency and are therefore sentient?<br/><br/><blockquote class="uncited"><div>And by the way, you can't see how this same reasoning would require the good to justify itself without some kind of external justification?</div></blockquote><br/><br/>I still think that it's possible to assert, "why should I be good?"  Good is only self-justifying if you value good intrinsically.  But it is possible to take a neutral position with no values, or with values different from just valuing good.<br/><br/><blockquote class="uncited"><div>So what specifically do you think 'ideological' communists advocate and for what reason? Kropotkin, Marx and Bakunin had very different ideas.</div></blockquote><br/><br/>They nevertheless shared common prescriptions of the abolition of private property and money, and the eventual goal of a stateless society.  They also shared as fundamental values, equality and freedom.<br/><br/><blockquote class="uncited"><div>'Liberalism' may not be an explicit and unified ideology but the differences between liberals and conservatives are not just differences regarding how best to implement shared ideological values, they are fundamental ideological differences. </div></blockquote><br/><br/>Actually, liberalism can be described as a unified ideology that values "liberty" both in its positive and negative forms, as its fundamental value.  True about the fundamental ideological differences between liberals and conservatives.<br/><br/><blockquote class="uncited"><div>I would argue that utilitarianism is incompatible with anarchism in the same way you think that utilitarianism is incompatible with communism. </div></blockquote><br/><br/>And I would agree.  Utilitarianism -is- incompatible with ideological anarchism.<br/><br/><blockquote class="uncited"><div>The utilitarians in a utilitarian economy would not be deontological communists in the exact same way that they wouldn't be committed to promoting H.U for it's own sake but you're saying that a society of perfectly consistent hedonistic utilitarians might not develop a gift economy where resources are distributed on the basis of benefit alone makes no sense whatsoever because you're flat out admitting that these utilitarians would care about something other than (the general) happiness.. <br/><br/>Communism, as I've used the term, is not an ideology. It is an economic system. Your argument would make sense if you substituted 'communism' with 'anarchism' or 'pacifism' because these are fundamentally deontological positions. Anarchists (ie. consistent libertarians) oppose the initiation of force - not because of the suffering it causes - but because people have a right to autonomy. Pacifists oppose violence in all circumstances - again, not because of the suffering violence causes - but because the act of inflicting physical pain is bad even if it's necessary to prevent more pain than it causes. Still, a utilitarian would ideally favor a society without the initiation of force or any violence at all. There is no such conflict between utilitarianism and the communism I've outlined because my 'communism' is an economic system, not a deontological position stating that you should never allow private property or free market competition because these things are intrinsically bad.<br/><br/>That's not what really blows me away, though. I can understand your thinking that 'communism' comes with ideological baggage that isn't in sync with utilitarian ethics. What I don't understand (and this truly blows me the fuck away!), is not how utilitarianism doesn't necessarily lead us to a favor an economy where resources are distributed according to benefit in practice but that a society of perfect utilitarians would not necessarily distribute resources among themselves according to benefit. So if John is a perfect utilitarian and he knows that his next door neighbor or anyone else would benefit more from a good that he owns than he would, he would not necessarily share his belonging despite the fact that doing so would result in a greater amount of happiness. Or if some hospital has a limited amount of medicine that one person badly needs and another would only mildly benefit from, the medicine would not be given to the person who needs it more. Merit, luck or things other than HAPPINESS would determine how a society of perfect hedonistic utilitarians would distribute resources...</div></blockquote><br/><br/>Actually, I agree -completely- with you that a society of perfect hedonistic utilitarians would distribute resources based on the benefit, or the effect on happiness rather than anything else.  I just think it's possible to do that while still having things that resemble property or money.  I think these things can still exist in a gift economy, though they would function quite differently than the way they do now.  Like everything else, people would share property or money to those whom it would be the most benefit to.<br/><br/>I think the difference here is you don't think the ideal of distribution according to benefit is compatible with non-communist economic arrangements, while I think the ideal of distribution according to benefit is compatible with non-communist economic arrangements.  A communist economy is not necessarily the same as a gift economy, but both could satisfy the ideal of distribution according to benefit in a society of perfect Utilitarians.<br/><br/>And for that matter, you've already expressed that there are two different communist economic options, the anarcho-communist (gift) economy, and the state-communist (centrally planned) economy.  Strictly speaking communism itself isn't an economy but a set of ideals for the economy to aspire to.  The main known economies are: market, planned, and gift.  Of these, the planned and gift economies are believed to be compatible with communism.<br/><br/>A pure centrally planned economy is definitely not a gift economy.  You seem to prefer the centrally planned economy, but I think both are compatible with a society of perfect Utilitarians.  In practice, I think the gift economy will run better though, and why I would prefer it for a society of perfect Utilitarians.  Though it may be possible that a mixed gift/centrally planned economy will actually perform best, if you could get the best of both worlds without the limitations of either.<br/><br/>To clarify, I'm not saying that a "communist economy" is incompatible with Utilitarianism, only the communist ideology.  But just because it is compatible, does not mean it is the only arrangement that is compatible and that Utilitarianism therefore demands it.  I'm open to the possibility that other economic arrangements, perhaps ones that we haven't even thought of yet, might also be compatible with the ideals of Utilitarianism in a society of perfect Utilitarians.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9062">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9066">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9066">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-13T17:32:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>So agency is a necessary component of sentience?</div></blockquote><br/><br/>No but a rock's lack of behavior doesn't give me reason to believe that it probably is sentient.<br/><br/><br/><blockquote class="uncited"><div>How exactly do atoms behave with agency? Is it because they appear to move around of their own volition? Asteroids move around in orbits in a similar way that electrons move around in orbits around an atomic nucleus. Do asteroids (rocks in space) have agency and are therefore sentient?</div></blockquote><br/><br/>The behavior of asteroids is not unpredictable ( they don't move around spontaneously the way ants seem to, they just react to the gravitational pull of other objects), the behavior of elementary quantum particles is. The concept of private subjective experience arising from observable physical actions in the brain is completely inconceivable. The idea of a whole having fundamentally new properties that aren't possessed by the individual parts it is comprised of is incoherent because a whole is nothing more than the sum (whole) of the parts it is comprised of. What appears to be a new emergent property is just a specific arrangement of already existing properties. I would recommend a book called Radical Nature : The Soul of Matter by Christian de Quincey, he can give a much better argument for pan-psychism than I can.<br/><br/><br/><blockquote class="uncited"><div>I still think that it's possible to assert, "why should I be good?" Good is only self-justifying if you value good intrinsically. But it is possible to take a neutral position with no values, or with values different from just valuing good.</div></blockquote><br/><br/>If somebody doesn't care about being or doing what's moral then it's not likely that anything you say or do will change their mind but the only justification for caring about the good (whether it's persuasive or not) is that the good is worth caring about. That's what makes it "the good". Nobody can value what they -at least on a purely emotional if not intellectual level-regard as bad. 'Good' is interchangeable with 'valuable' and 'bad' with 'dis-valuable'. The neutral position is sitting still and doing nothing because nothing matters, there are no functioning nihilists.<br/><br/><blockquote class="uncited"><div>They nevertheless shared common prescriptions of the abolition of private property and money, and the eventual goal of a stateless society. They also shared as fundamental values, equality and freedom.</div></blockquote><br/><br/>Buddhists believe that part of enlightenment is recognizing the unity of the world and loving all beings (Buddhist 'love' is compassion rather than just affection or emotional attachment and I'm probably over simplifying or maybe even misrepresenting the many Buddhist schools but you get the general idea), Jainists also believe in causing no harm and being kind to others, Christians believe in loving your enemies and charity etc. These are all very different religions that share some core values that are consistent with utilitarianism. These four world views will come to the same conclusion on many different issues, if not entirely for the same reasons.<br/><br/>Hedonistic utilitarians do not oppose free market competition, private property or inequality of wealth or power for it's own sake but they do believe in giving equal and unconditional consideration to the happiness of all beings which means that an economy run by perfect hedonistic utilitarians would allocate resources on the basis of who would be expected to experience the most happiness or have the greatest reduction in suffering as a result of consuming those resources. If there is one piece of (vegan) cake left and I somehow know that John will experience 10 points of pleasure if given the last piece, Mary will experience 15 points of pleasure if given the last piece and Andrew will experience 5 points of pleasure if given the last piece, I will give the last piece to Mary because she is the one who will benefit most from eating it ; that's distributing a resource on the basis of benefit and that's what a utilitarian economy would look like. To divide the cake based on anything other than the amount of happiness it will produce is to reject hedonistic utilitarianism. In a free market competition (capitalist or socialist), resources are distributed on the basis of luck or earned through competition and self-interest ; they are not distributed solely on the basis of what division is expected to maximize the most happiness *generally* which is why an H.U economy would be a communist/gift economy even if proponents of a communist/gift economy are not necessarily utilitarians, just as the rationale a Christian might give against torturing someone is not entirely the same as one a Buddhist might give despite arriving at the same conclusion.<br/><br/>The ideal Gandhian society probably wouldn't look very different than the ideal hedonistic utilitarian society despite being very different world views.<br/><br/><blockquote class="uncited"><div>Actually, liberalism can be described as a unified ideology that values "liberty" both in its positive and negative forms, as its fundamental value. True about the fundamental ideological differences between liberals and conservatives.</div></blockquote><br/><br/>I think that liberalism is more of a vague 'tendency' than an explicit ideology. Utilitarianism and libertarianism are explicit ideologies. There is no explicit connection between being pro-choice when it comes to abortion and against the death penalty or for affirmative action and social welfare programs. Not all liberals are pro-choice, some conservatives oppose the death penalty, not everyone who is pro-choice or against the death penalty holds these positions for the same reasons. 'Positive freedom' is such a broad concept that is open to interpretation and can justify or oppose different positions depending on who you ask, on some issues I'm sure conservatives support 'positive freedoms' that liberals don't. <br/><br/><br/><br/><blockquote class="uncited"><div>I think the difference here is you don't think the ideal of distribution according to benefit is compatible with non-communist economic arrangements, while I think the ideal of distribution according to benefit is compatible with non-communist economic arrangements. A communist economy is not necessarily the same as a gift economy, but both could satisfy the ideal of distribution according to benefit in a society of perfect Utilitarians.</div></blockquote><br/><br/>I agree that a communist economy is not necessarily the same as a gift economy, a communist economy can be centrally planned. If we're dealing with a population that is entirely or mostly comprised of utilitarians (and if only the majority are comprised of utilitarians, I'm assuming that planning the economy through government coercion is a necessary evil and the interests of the minority are still being given equal consideration) then there are two options - a centrally planned economy where resources are distributed on the basis of benefit or a stateless gift economy where the people voluntarily distribute resources among themselves on the basis of benefit. If I remember correctly, you were arguing that a utilitarian economy would not necessarily be one in which resources were distributed on the basis of benefit since I was already open to the possibility of either a centrally planned or 'anarchist' economy and said so.<br/><br/><blockquote class="uncited"><div>And for that matter, you've already expressed that there are two different communist economic options, the anarcho-communist (gift) economy, and the state-communist (centrally planned) economy. Strictly speaking communism itself isn't an economy but a set of ideals for the economy to aspire to. The main known economies are: market, planned, and gift. Of these, the planned and gift economies are believed to be compatible with communism.</div></blockquote><br/><br/>If that's what 'communism' means then there's no word to describe someone who favors a particular economic system but without the Marxist baggage that you're associating the word with. <br/><br/>Market economy is not compatible with utilitarianism because it's based on self-interested competition for resources. What you described as a 'free market competition' that could be compatible with utilitarianism was not, it just wasn't centrally planned. Figuring out who can produce the highest quality goods and services through a process of trial and error and not to gain an advantage over the other is nowhere near a free market competition as virtually everyone uses the term. Division of resources according to merit through competition and not benefit is not compatible with utilitarianism so of those three possible economies you mentioned we have two options, not three.<br/><br/><blockquote class="uncited"><div>A pure centrally planned economy is definitely not a gift economy. You seem to prefer the centrally planned economy, but I think both are compatible with a society of perfect Utilitarians.</div></blockquote><br/><br/>I do not prefer a centrally planned economy. I actually said that I preferred a gift economy (who wouldn't, honestly?). I only wanted to make clear that my ideal society wouldn't really be "anarchist" not because it would have coercion but because the utilitarians in this society would be willing to initiate coercion, so it wouldn't be an 'anarchist' society in the sense that everyone held autonomy as an intrinsic value. My ideal society would be completely non-violent but I wouldn't necessarily criticize someone for reluctantly using violence in some circumstances.  I agree that both are compatible with a society of perfect utilitarians (no, government coercion would be completely unnecessary if everyone were a perfect utilitarian) but you weren't just saying that utilitarianism was compatible with either a gift economy or a planned economy, the impression I got was that you were open to the possibility of a utilitarian society not necessarily allocating resources on the basis of benefit alone.<br/><br/>You said that a society of utilitarians would favor the economic system that was most beneficial and not just because it was 'ideologically correct', I conceded this point a long time ago in admitting that utilitarianism could justify promoting views other than utilitarianism, but how could a society of utilitarians not allocate resources according to benefit? Once you account for the fact that we live in a world where most people are not utilitarians and this is why communism would fail if revolutionary communists in 2014 were to attempt to establish a communist economy by force,  how could a system which distributes resources according to benefit alone possibly not be the most beneficial? You might has well have been arguing that utilitarians shouldn't promote utilitarianism for it's own sake and I would have agreed, my only point was that in a utilitarian economy resources would be allocated on the basis of benefit.<br/><br/><br/><blockquote class="uncited"><div> In practice, I think the gift economy will run better though, and why I would prefer it for a society of perfect Utilitarians. Though it may be possible that a mixed gift/centrally planned economy will actually perform best, if you could get the best of both worlds without the limitations of either.</div></blockquote><br/><br/>I'm fine with that but either way, resources are distributed according to need.<br/><br/><blockquote class="uncited"><div>To clarify, I'm not saying that a "communist economy" is incompatible with Utilitarianism, only the communist ideology.</div></blockquote><br/><br/>I never thought that you were but there is no one communist ideology. People favor capitalism for different reasons.  An ideology is what we use to justify the economic system we favor.Utilitarianism necessarily has to favor an economic system which allocates resources according to benefit alone - I've called this 'communism' ; with this definition, ALL consistent utilitarians have to ideally favor communism and promote it to the extent that they promote utilitarianism, even if all communists are not necessarily utilitarians.<br/><br/><blockquote class="uncited"><div> But just because it is compatible, does not mean it is the only arrangement that is compatible and that Utilitarianism therefore demands it.</div></blockquote><br/><br/>Allocation of resources according to benefit is absolutely the only economic arrangement that is compatible with utilitarianism. <br/><br/><blockquote class="uncited"><div> I'm open to the possibility that other economic arrangements, perhaps ones that we haven't even thought of yet, might also be compatible with the ideals of Utilitarianism in a society of perfect Utilitarians.</div></blockquote><br/><br/>The issue that I have is not with how resources are distributed (that's political, not economic), utilitarianism can accommodate a wide range of systems in this regard, the issue that I have is on what basis. Allocation of resources based on anything other than benefit is non-utilitarian. <br/><br/>Anarchism is a political ideology. Politics deals with group decision making. Political ideologies are moral ideologies. Communism is not a political system, it is an economic arrangement. This is why you can have anarchist-communism but you can also have state communism.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9066">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9068">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9068">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-13T19:19:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>The behavior of asteroids is not unpredictable ( they don't move around spontaneously the way ants seem to, they just react to the gravitational pull of other objects), the behavior of elementary quantum particles is. The concept of private subjective experience arising from observable physical actions in the brain is completely inconceivable. The idea of a whole having fundamentally new properties that aren't possessed by the individual parts it is comprised of is incoherent because a whole is nothing more than the sum (whole) of the parts it is comprised of. What appears to be a new emergent property is just a specific arrangement of already existing properties. I would recommend a book called Radical Nature : The Soul of Matter by Christian de Quincey, he can give a much better argument for pan-psychism than I can.</div></blockquote><br/><br/>I think you're misunderstanding quantum uncertainty.  Strictly speaking elementary quantum particles are predictable because you can construct a probability wave function that explains how a particle will behave.  While the exact future position of the particle is not certain, we can theoretically calculate the probabilities by which to expect a particle to be be in a certain future position with.  Thus, particles do not move about at random, but according to a statistically measurable probability distribution.<br/><br/>Think of it this way.  A photon does not zig-zag about at random.  In a vacuum, it moves in a wavy straight line unless some force like gravity acts upon it (or alternatively, spacetime curves).  We can thus, predict with a fair degree of accuracy not only where a photon came from, but also, where it's going.<br/><br/>Strictly speaking, not only particles, but all objects, including both rocks and humans have these probability distributions.  We actually move along a probabilistic "worldline" that is determined by the prior arrangements of matter, energy, and information.<br/><br/>If the whole is nothing more than the sum of its parts, then how do you explain the positive externalities that are generated from living in a society?  By themselves, individuals living alone would have to make their own food, clothing and shelter.  Acting together in a society however allows for division of labour.  Some people can specialize as farmers, others as tailors, and yet others as construction workers, scientists, artists, etc.  By doing so, the quality of each good or service is significantly improved compared to if you just made and did everything yourself.<br/><br/>Similarly, try having fifty people work separately at making a movie.  The 50 movies would probably be awful.  On the other hand, if the 50 people work together as a studio, they can make a single, very high quality movie.<br/><br/>A car is another example.  Individually, the elements of a car are just parts.  By themselves, they don't move.  It's only when the car is assembled that this new functionality or property of being able to move at high speeds, given certain inputs from the driver, arises.<br/><br/>I personally separate agency into two sub-properties:  Sentience and Actorhood.<br/><br/>The paralyzed man is an example of a sentient without agency or actorhood.  A boulder rolling down a slope towards you is an example of an actor that is not sentient and not an agent.<br/><br/>Sentience requires inputs.  You can't think if you have nothing to think about.  It also requires some kind of internal state in which information is processed and inputs are discriminated.  It does not require outputs.<br/><br/>Actorhood requires outputs.  It requires some kind of action.  A program that blindly tells a robotic arm to move in such and such ways to assemble something, is an actor.<br/><br/>Agency combines the two together.<br/><br/><blockquote class="uncited"><div>If I remember correctly, you were arguing that a utilitarian economy would not necessarily be one in which resources were distributed on the basis of benefit... the impression I got was that you were open to the possibility of a utilitarian society not necessarily allocating resources on the basis of benefit alone.</div></blockquote><br/><br/>Uh no.  I do agree with you that resources would be distributed on the basis of benefit in a perfect utilitarian economy.<br/><br/><blockquote class="uncited"><div>Utilitarianism necessarily has to favor an economic system which allocates resources according to benefit alone - I've called this 'communism' ; with this definition, ALL consistent utilitarians have to ideally favor communism and promote it to the extent that they promote utilitarianism, even if all communists are not necessarily utilitarians.</div></blockquote><br/><br/>I ideally favour your definition of communism specifically for a society of perfect altruists.  I don't favour it for regular humans.  For this reason, I don't think that to be consistent, I have to promote communism to the same extent as I would promote Utilitarianism.  I promote Utilitarianism even for regular humans.  I don't promote communism for regular humans.<br/><br/><blockquote class="uncited"><div>Allocation of resources according to benefit is absolutely the only economic arrangement that is compatible with utilitarianism.</div></blockquote><br/><br/>I am assuming that there could be other economic arrangements that satisfy "allocation of resources according to benefit ".<br/><br/><blockquote class="uncited"><div>The issue that I have is not with how resources are distributed (that's political, not economic), utilitarianism can accommodate a wide range of systems in this regard, the issue that I have is on what basis. Allocation of resources based on anything other than benefit is non-utilitarian. <br/><br/>Anarchism is a political ideology. Politics deals with group decision making. Political ideologies are moral ideologies. Communism is not a political system, it is an economic arrangement. This is why you can have anarchist-communism but you can also have state communism.</div></blockquote><br/><br/>An economic arrangement is something that explains how resources are distributed.  You're confusing the notion of economy, which is the coordination system by which resources are distributed, with economic ideology, which is the set of reasons for distributing resources according to certain conditions.  Your communism is an economic ideology, not an economic arrangement.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9068">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9071">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9071">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-14T18:52:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>I think you're misunderstanding quantum uncertainty. Strictly speaking elementary quantum particles are predictable because you can construct a probability wave function that explains how a particle will behave. While the exact future position of the particle is not certain, we can theoretically calculate the probabilities by which to expect a particle to be be in a certain future position with. Thus, particles do not move about at random, but according to a statistically measurable probability distribution.<br/><br/><br/>Think of it this way. A photon does not zig-zag about at random. In a vacuum, it moves in a wavy straight line unless some force like gravity acts upon it (or alternatively, spacetime curves). We can thus, predict with a fair degree of accuracy not only where a photon came from, but also, where it's going.<br/><br/>Strictly speaking, not only particles, but all objects, including both rocks and humans have these probability distributions. We actually move along a probabilistic "worldline" that is determined by the prior arrangements of matter, energy, and information.</div></blockquote><br/><br/>What I understand is that the predictions we make about the quantum world are a matter of probability, we can't predict it's behavior with the same near certainty I can assume that a rock I throw out of a window will fall to the ground because it's subject to the law of gravity (no recorded case I'm aware of has ever shown otherwise). The behavior of elementary quantum particles appears to be spontaneous, even if not completely unpredictable, the rock's behavior doesn't. And all of this is besides the fact that, whether it's just the indivisible components of a thing that are sentient or all macroscopic sized objects, consciousness from no consciousness is inconceivable. In fact, you can still adopt the pan-psychist point of view while still maintaining determinism.<br/><br/><blockquote class="uncited"><div>If the whole is nothing more than the sum of its parts, then how do you explain the positive externalities that are generated from living in a society? By themselves, individuals living alone would have to make their own food, clothing and shelter. Acting together in a society however allows for division of labour. Some people can specialize as farmers, others as tailors, and yet others as construction workers, scientists, artists, etc. By doing so, the quality of each good or service is significantly improved compared to if you just made and did everything yourself.<br/><br/>Similarly, try having fifty people work separately at making a movie. The 50 movies would probably be awful. On the other hand, if the 50 people work together as a studio, they can make a single, very high quality movie.<br/><br/>A car is another example. Individually, the elements of a car are just parts. By themselves, they don't move. It's only when the car is assembled that this new functionality or property of being able to move at high speeds, given certain inputs from the driver, arises.</div></blockquote><br/><br/>I don't understand how any of this shows that fundamentally new properties can emerge from arranging particles in a certain way (the first two examples seem completely off topic). As for the car example,  the car doesn't have fundamentally novel traits that aren't possessed by any of it's parts.<br/><br/><a class="postlink" href="https://searchformagic.wordpress.com/2006/09/27/logical-fallacy-of-division/">https://searchformagic.wordpress.com/20 ... -division/</a><br/><br/><blockquote class="uncited"><div>I personally separate agency into two sub-properties: Sentience and Actorhood.<br/><br/>The paralyzed man is an example of a sentient without agency or actorhood. A boulder rolling down a slope towards you is an example of an actor that is not sentient and not an agent.</div></blockquote><br/><br/>The boulder rolling down a hill is reacting to external stimuli, it's not acting spontaneously.<br/><br/><blockquote class="uncited"><div>Sentience requires inputs. You can't think if you have nothing to think about. It also requires some kind of internal state in which information is processed and inputs are discriminated. It does not require outputs.<br/><br/>Actorhood requires outputs. It requires some kind of action. A program that blindly tells a robotic arm to move in such and such ways to assemble something, is an actor.<br/><br/>Agency combines the two together.</div></blockquote><br/><br/>With respect, is there a point to this? Seriously?<br/><br/><br/><br/><br/><br/><blockquote class="uncited"><div>Uh no. I do agree with you that resources would be distributed on the basis of benefit in a perfect utilitarian economy.</div></blockquote><br/><br/>I'm calling an economy in which resources are distributed according to benefit a 'communist' economy. I have been from the beginning and as baffled as I am by your insistence that the word 'communism' must refer to some kind of deontological political ideology and not just supporting, for whatever reasons, an economy where resources are distributed according to benefit, words don't matter.<br/><br/>I don't care whether these resources are distributed through central planning or voluntarily by the individuals of this society, not because I don't think that a society without coercion is ideally preferable but because a willingness to control the economy through coercion isn't inconsistent with hedonistic utilitarianism. Factoring anything other than happiness/suffering into consideration regarding on what basis resources are distributed is.<br/><br/><br/><br/><blockquote class="uncited"><div>I ideally favour your definition of communism specifically for a society of perfect altruists. I don't favour it for regular humans.</div></blockquote><br/><br/>Fair enough (not that I don't take issue with your assumption that something close to a communist/gift economy on a widespread level is compatible with 'human nature' but that's another issue).<br/><br/><blockquote class="uncited"><div> For this reason, I don't think that to be consistent, I have to promote communism to the same extent as I would promote Utilitarianism.</div></blockquote><br/><br/>You are wrong (if you mean what I mean by 'communism'). I'm not saying you should try to persuade people to be <span style="font-style: italic">perfect</span> utilitarians but a society of more or less practicing utilitarians would have a more or less communist economy.<br/><br/><blockquote class="uncited"><div> I promote Utilitarianism even for regular humans. I don't promote communism for regular humans.</div></blockquote><br/><br/>This is inconsistent. It is completely inconsistent. <br/><br/>Perfectly consistent utilitarians care equally about the happiness of all beings. If someone cared equally about the happiness and suffering of all beings, they would share resources with others to the extent that they believed others would benefit from those resources more than they would. A utilitarian society may not have a pure communist economy but only because these utilitarians weren't perfect utilitarians. What you're saying is that you favor promoting utilitarianism- that is, the idea that everyone's emotional well-being (if you're promoting H.U) should be given equal consideration and the single objective of all decisions should be to maximize the balance of happiness over suffering generally- <span style="font-weight: bold">but</span> you don't see this requiring that people share or distribute resources according only to the benefit that it produces ; it's consistent to promote a version of utilitarianism in which adherents can use merit or luck as a direct justification for a certain division of resources or that resources that are only mildly beneficial to the wealthy can justifiably be reserved for them despite being hugely beneficial for less fortunate people. I can understand your not promoting communism for 'regular humans' but this means that you aren't promoting utilitarianism.<br/><br/><br/><br/><br/><blockquote class="uncited"><div>I am assuming that there could be other economic arrangements that satisfy "allocation of resources according to benefit "</div></blockquote><br/><br/>Then I would include those systems under 'communism'.<br/><br/><br/><br/><blockquote class="uncited"><div>An economic arrangement is something that explains how resources are distributed<span style="font-weight: bold"> (replace 'arrangement' with 'system' maybe)</span>. You're confusing the notion of economy, which is the coordination system by which resources are distributed, with economic ideology, which is the set of reasons for distributing resources according to certain conditions. Your communism is an economic ideology, not an economic arrangement.</div></blockquote><br/><br/>O.K but utilitarianism is a moral ideology that has political, social and economic implications. All moral ideologies have political, social and economic implications. It's not that I agree with two distinct ideologies - communism and utilitarianism - it's that utilitarianism ideally favors allocating resources according to who is made happiest/whose suffering is most reduced as a result of having those resources. It's not that I agree with both utilitarianism and the anti-rape view- two fundamentally unrelated if somewhat similar positions, it's that utilitarianism has to factor into consideration the suffering of rape victims so (assuming that there aren't rapists, especially rapists who would identify with the suffering of their victims and enjoy raping them despite that, who actually feel an amount of pleasure from raping someone that eclipses all of the direct and indirect life long suffering the rape victim would feel as a result of being raped), to the extent that I want to promote utilitarianism, I have to promote 'anti-rapism'. Other anti-rapists may oppose rape for reasons different than mine, they may oppose for it's own sake the infringement of autonomy or even the non-experienced frustration of someone's preference for others not to have sex with their body without their consent whereas I'm explicitly concerned with the felt harm that being raped causes but I'm not juggling two incompatible views, one leads to the other.<br/><br/>If your problem is just with the word 'communism', whatever. Come up with a broad term that I can use to describe a number of economic systems that involve allocation of resources according to benefit alone. I think I had something else to say but anarchism, for example, is a political (and thus moral) ideology that offers a 'why' for prohibiting certain behavior, even if different anarchists have different 'whys' justifying their anarchism and several 'whys' that they might use to justify any other decision or judgment they make aren't consistent with the 'why' they offer for anarchism. Just saying that you advocate distribution of resources according to benefit alone offers no 'why', utilitarianism is one 'why' for this kind of an economy just as it's only one 'why' for being anti-rape.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9071">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9072">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9072">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-14T19:49:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>What I understand is that the predictions we make about the quantum world are a matter of probability, we can't predict it's behavior with the same near certainty I can assume that a rock I throw out of a window will fall to the ground because it's subject to the law of gravity (no recorded case I'm aware of has ever shown otherwise). The behavior of elementary quantum particles appears to be spontaneous, even if not completely unpredictable, the rock's behavior doesn't. And all of this is besides the fact that, whether it's just the indivisible components of a thing that are sentient or all macroscopic sized objects, consciousness from no consciousness is inconceivable. In fact, you can still adopt the pan-psychist point of view while still maintaining determinism.</div></blockquote><br/><br/>It's not spontaneous though.  Spontaneous would mean completely unpredictable.  The only reason we can't predict them perfectly is due to the fact that the particles are also waves and therefore the exact position of the particle isn't knowable.<br/><br/><blockquote class="uncited"><div>I don't understand how any of this shows that fundamentally new properties can emerge from arranging particles in a certain way (the first two examples seem completely off topic). As for the car example, the car doesn't have fundamentally novel traits that aren't possessed by any of it's parts.</div></blockquote><br/><br/>Then you're not seeing the new properties and behaviours that arise from the examples I just made.  The first two example simply show how the sum can be greater than its parts.  In other words, synergy occurs.  The car is made of individual parts that if broken down enough, by themselves they cannot create forces, but the combined system is able to create forces that cause movement.<br/><br/>Another very simple example is water.  Hydrogen and Oxygen are both gases.  However, when combined together they form a liquid, which is a new property of matter that emerges and wasn't present in the individual atoms.<br/><br/><blockquote class="uncited"><div>The boulder rolling down a hill is reacting to external stimuli, it's not acting spontaneously.</div></blockquote><br/><br/>How do you know that it's not acting spontaneously.  I never said why the boulder was rolling down the hill, you just assumed it was because of gravity and external forces.  In the same way, we can never be "sure" that elementary particles aren't moving spontaneously, but our observations of how predictable they are strongly suggest that they are controlled by external fundamental forces such as electromagnetism, gravity, and the strong and weak nuclear forces.<br/><br/><blockquote class="uncited"><div>With respect, is there a point to this? Seriously?</div></blockquote><br/><br/>Yes.  The point is that sentience or consciousness are not something you can assume just because something appears to move about spontaneously.  Thus, even if it were true that elementary particles moved spontaneously, it wouldn't follow that they were conscious or sentient, because it is possible to appear to move spontaneously as a pure non-sentient actor.<br/><br/><blockquote class="uncited"><div>This is inconsistent. It is completely inconsistent. <br/><br/>Perfectly consistent utilitarians care equally about the happiness of all beings. If someone cared equally about the happiness and suffering of all beings, they would share resources with others to the extent that they believed others would benefit from those resources more than they would. A utilitarian society may not have a pure communist economy but only because these utilitarians weren't perfect utilitarians. What you're saying is that you favor promoting utilitarianism- that is, the idea that everyone's emotional well-being (if you're promoting H.U) should be given equal consideration and the single objective of all decisions should be to maximize the balance of happiness over suffering generally- but you don't see this requiring that people share or distribute resources according only to the benefit that it produces ; it's consistent to promote a version of utilitarianism in which adherents can use merit or luck as a direct justification for a certain division of resources or that resources that are only mildly beneficial to the wealthy can justifiably be reserved for them despite being hugely beneficial for less fortunate people. I can understand your not promoting communism for 'regular humans' but this means that you aren't promoting utilitarianism.</div></blockquote><br/><br/>On the contrary, it is consistent because I can promote Utilitarianism as being good even if only a few humans in the society are perfect Utilitarians.  I cannot promote communism until all humans in the society are perfect Utilitarians.<br/><br/>I believe that having more Utilitarians would be good regardless if what percentage of the population they were.  However, communism only works if everyone already is a perfect Utilitarian.  Otherwise you run into the problem of free riders and the tragedy of the commons.  Thus, for a society with some mixture of perfect utilitarians and normal self-interested humans, I would advocate for something different than communism.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9072">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9079">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9079">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-17T16:44:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>It's not spontaneous though. Spontaneous would mean completely unpredictable. The only reason we can't predict them perfectly is due to the fact that the particles are also waves and therefore the exact position of the particle isn't knowable.</div></blockquote><br/><br/>As a determinist I would have given a similar argument, that the behavior of quantum particles being somewhat predictable implies that they are causally determined and that our knowledge is just incomplete but this isn't the general consensus among physicists, most of them reject the traditional Newtonian view of a perfectly determined universe and insist that quantum particles behave independently.<br/><br/><blockquote class="uncited"><div>Then you're not seeing the new properties and behaviours that arise from the examples I just made. The first two example simply show how the sum can be greater than its parts.</div></blockquote><br/><br/>The very concept of a sum being greater than the sum of it's parts is logically incoherent. A sum is the sum of it's parts.<br/><br/><blockquote class="uncited"><div> In other words, synergy occurs. The car is made of individual parts that if broken down enough, by themselves they cannot create forces, but the combined system is able to create forces that cause movement.<br/><br/>Another very simple example is water. Hydrogen and Oxygen are both gases. However, when combined together they form a liquid, which is a new property of matter that emerges and wasn't present in the individual atoms.</div></blockquote><br/><br/>Yes, but nothing new is being created. It's just being rearranged.<br/><br/><blockquote class="uncited"><div>How do you know that it's not acting spontaneously.</div></blockquote><br/><br/>I don't but, based on our consistent observation of the world, we have no reason to believe that boulders or rocks behave spontaneously.<br/><br/><blockquote class="uncited"><div> I never said why the boulder was rolling down the hill, you just assumed it was because of gravity and external forces <span style="font-weight: bold">(and the reason why I've assumed this is because there is no known case of a boulder exhibiting what appears to be spontaneous behavior)</span>. In the same way, we can never be "sure" that elementary particles aren't moving spontaneously, but our observations of how predictable they are strongly suggest that they are controlled by external fundamental forces such as electromagnetism, gravity, and the strong and weak nuclear forces.</div></blockquote><br/><br/>I have never claimed that we can know anything beyond our own conscious experience or the law of non-contradiction (the only apriori knowledge that I think we can have is ruling out propositions that are internally self-contradicting in the same way we would rule out propositions that contradict our direct experience, a statement can't be simultaneously true and false in the same respect).<br/><br/><blockquote class="uncited"><div>The point is that sentience or consciousness are not something you can assume just because something appears to move about spontaneously.</div></blockquote><br/><br/>I can't assume to know that something is sentient because it appears to move about spontaneously, I can regard someone or something being sentient or insentient as probable or improbable.<br/><br/><blockquote class="uncited"><div> Thus, even if it were true that elementary particles moved spontaneously, it wouldn't follow that they were conscious or sentient, because it is possible to appear to move spontaneously as a pure non-sentient actor.</div></blockquote><br/><br/>I never claimed that pan-psychism was true because quantum particles appear to behave spontaneously. My primary argument is the incoherence of emergence. Pointing out that quantum particles appear to behave spontaneously was just my explaining why I believe that they are sentient and inanimate objects like rocks, trees and my laptop are not.<br/><br/><blockquote class="uncited"><div>On the contrary, it is consistent because I can promote Utilitarianism as being good even if only a few humans in the society are perfect Utilitarians. I cannot promote communism until all humans in the society are perfect Utilitarians.</div></blockquote><br/><br/>I'm not criticizing you for not promoting communism. What I disagree with is your claim that promoting utilitarianism does not involve promoting a communist economy. Because hedonistic utilitarians care (ultimately) about happiness/suffering alone, a hedonistic utilitarian is someone who cares equally about the happiness and suffering of all persons and such a being would share resources with others to the extent that they believed others would benefit more from those resources than they would (I hope you're not getting tired of me saying that but it's true). A perfect(ly consistent) utilitarian isn't a fundamentally different kind of thing than an imperfect utilitarian, a perfect utilitarian is just a utilitarian, in regards to their intentions and decisions and in terms of their attitudes and judgments, all of the time. I don't think you should even attempt to persuade people to be perfect utilitarians but, again, a society of more or less practicing utilitarians would develop a <span style="font-style: italic">more or less</span> communist economy. A society of people who develop an economy that doesn't distribute resources according to benefit alone is a society of people who don't care exclusively about the general happiness simpliciter, hedonistic utilitarians care about everyone's happiness/suffering and only happiness/suffering.<br/><br/>I interpreted 'promoting utilitarianism' as trying to persuade people to become utilitarians or to adopt utilitarian sentiments. Maybe we're not on the same page about what that means? If you mean that you want to promote as many people to become utilitarians, or even just more 'utilitarian' in their judgments (the word 'utilitarian' has such negative connotations), with the practical realization that most people will never adopt utilitarianism, then I think I understand what you mean. But if you're talking about promoting an actual utilitarian society and not just increasing the number of utilitarians in a predominately non-utilitarian world then this necessarily involves promoting a communist/gift economy.<br/><br/><blockquote class="uncited"><div>I believe that having more Utilitarians would be good regardless if what percentage of the population they were. <br/>However, communism only works if everyone already is a perfect Utilitarian. Otherwise you run into the problem of free riders and the tragedy of the commons. Thus, for a society with some mixture of perfect utilitarians and normal self-interested humans, I would advocate for something different than communism.</div></blockquote><br/><br/>I don't disagree with this. I'm not saying that you're wrong to advocate a system other than communism. I do think you're wrong to not regard a communist economy (an economy in which resources are distributed according to benefit alone) as ideal and consistent with the basic egalitarian principle of utilitarianism.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9079">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9080">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9080">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-17T18:11:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>As a determinist I would have given a similar argument, that the behavior of quantum particles being somewhat predictable implies that they are causally determined and that our knowledge is just incomplete but this isn't the general consensus among physicists, most of them reject the traditional Newtonian view of a perfectly determined universe and insist that quantum particles behave independently.</div></blockquote><br/><br/>As far as I know, quantum physics isn't incompatible with determinism.  It's not the same as a Newtonian view that everything is perfectly predictable, but the implications are still that the universe is deterministic in the sense that cause and effect predominate and allow us to determine the probabilities of certain events.  The probabilities are still effectively determined, even if that's as accurate as we can get.<br/><br/><blockquote class="uncited"><div>The very concept of a sum being greater than the sum of it's parts is logically incoherent. A sum is the sum of it's parts.</div></blockquote><br/><br/>It's a figure of speech to mean that new properties and behaviours can arise that weren't present in the individual parts.<br/><br/><blockquote class="uncited"><div>Yes, but nothing new is being created. It's just being rearranged.</div></blockquote><br/><br/>Of course, strictly speaking nothing is being created.  The Law of Conservation of Energy holds in all cases.  What is being "created" rather is simply new "properties" and "behaviours".  These are not strictly speaking new objects, but rather new functions and associations that are made from existing objects.<br/><br/><blockquote class="uncited"><div>I never claimed that pan-psychism was true because quantum particles appear to behave spontaneously. My primary argument is the incoherence of emergence. Pointing out that quantum particles appear to behave spontaneously was just my explaining why I believe that they are sentient and inanimate objects like rocks, trees and my laptop are not.</div></blockquote><br/><br/>I think you're misunderstanding what emergence means.  It doesn't mean that completely new objects or additional matter or energy are created.  It simply means that new properties or behaviours of existing entities can "emerge" from combining existing objects/matter/energy in certain ways.  These properties or behaviours are patterns or systems.  In this sense, when consciousness "emerges" from a bunch of neurons, it's not a new object that exists in some kind of dualistic other realm.  Rather, consciousness is just the software that runs on the neural hardware.  It's a pattern that generates behaviours, but it isn't separate from the neurons.  If you destroy the neurons, you destroy the consciousness.  Note that when you destroy the neurons, you aren't destroying the matter, but just converting it into a different form.  The consciousness however, is lost because it isn't matter or energy, but a property of the matter/energy/information that only existed because of the particular configuration that the matter/energy/information was in.<br/><br/>Water is again, a good example.  Water has some interesting properties that Hydrogen and Oxygen do not have.  For instance, when you freeze water, it expands, which is the opposite of what Hydrogen and Oxygen would do.  It is also a universal solvent, etc. etc.<br/><br/><blockquote class="uncited"><div>I interpreted 'promoting utilitarianism' as trying to persuade people to become utilitarians or to adopt utilitarian sentiments. Maybe we're not on the same page about what that means? If you mean that you want to promote as many people to become utilitarians, or even just more 'utilitarian' in their judgments (the word 'utilitarian' has such negative connotations), with the practical realization that most people will never adopt utilitarianism, then I think I understand what you mean. But if you're talking about promoting an actual utilitarian society and not just increasing the number of utilitarians in a predominately non-utilitarian world then this necessarily involves promoting a communist/gift economy.</div></blockquote><br/><br/>Yes, I do actually mean the former when I mean "promoting utilitarianism".  I think that having even just one more altruist in the world would be a good thing.  And I agree that "utilitarian" has some unfortunate negative connotations.  I've actually had some people confuse me as being some kind of ethical egoist, because to them "utilitarian" means what's most expedient.  That's actually why among most people, I usually try to clarify by mentioning something about "the greatest good", or "maximizing happiness".<br/><br/><blockquote class="uncited"><div>I don't disagree with this. I'm not saying that you're wrong to advocate a system other than communism. I do think you're wrong to not regard a communist economy (an economy in which resources are distributed according to benefit alone) as ideal and consistent with the basic egalitarian principle of utilitarianism.</div></blockquote><br/><br/>If we define a communist economy the way you define it, then yes, it would, to the best of my limited knowledge, be ideal given that all the people are altruists and that these ideal conditions are set.  I accepted this a long time ago in our debate.  What I don't accept is this view that because we support it in ideal conditions, that we should also support it in all conditions, as if communism were unconditionally good.<br/><br/>I actually happen to think that the only thing that is unconditionally good is maximizing happiness.  Everything else, even promoting Utilitarianism, is at most conditionally good.  Promoting Utilitarianism is good on the condition that people are intelligent and rational enough to be able to predict consequences with reasonable accuracy and thus actually do the most good.  If people are mentally impoverished and prone to making huge errors in reasoning, I might actually be more inclined towards promoting some kind of simpler, deontological system that they can easily understand and which tends to maximize happiness.  Whatever actually works in maximizing happiness, is what I would promote.<br/><br/>Similarly, whatever economic system actually works in maximizing happiness, is what I would promote.  This is, to me, the most consistent way of being Utilitarian.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9080">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9119">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9119">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-23T22:14:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>I think you're misunderstanding what emergence means. It doesn't mean that completely new objects or additional matter or energy are created.</div></blockquote><br/><br/><blockquote class="uncited"><div> What is being "created" rather is simply new "properties"</div></blockquote><br/><br/><br/>And that's what I meant by 'emergence', not the creation of entirely new matter-energy.<br/><br/><blockquote class="uncited"><div>In this sense, when consciousness "emerges" from a bunch of neurons, it's not a new object that exists in some kind of dualistic other realm</div></blockquote><br/><br/>It's completely inconceivable how a fundamentally new <span style="font-style: italic">kind</span> of reality can arise from inter-subjectively observable physical interactions, especially when those same neural events could theoretically occur without neurons suddenly gaining an entirely new and 'invisible' property completely unrelated to any property that has ever existed before-subjective experience- as a result of interacting with other neurons in a certain way (of course emergent property dualists can argue that consciousness is epiphenomenal so that I'm not saying that proves anything). There's no reason why this should happen. Emergence doesn't explain anything. It's just an assertion that isn't even theoretically testable. It's a philosophical assumption and not something that has ever been supported by scientific evidence. This point can only be made in so many ways, and other people can make the argument better than I can. I honestly would not be surprised if the pan-psychist view eventually becomes the dominant position in the scientific community, even though it might take a while. Would you consider yourself to be a materialist or an emergent property dualist?<br/><br/><blockquote class="uncited"><div>What I don't accept is this view that because we support it in ideal conditions, that we should also support it in all conditions, as if communism were unconditionally good.</div></blockquote><br/><br/>I don't disagree with this. My only point was that a society of utilitarians would develop a communist economy because distributing resources according to benefit would necessarily have to be regarded as ideal from the point of view of someone who cared equally about everyone's well-being, even if it wasn't practically desirable for whatever reasons.I still think that utilitarians should promote a utilitarian society and - by extension- a communist economy ; if this is ever accomplished it would be very gradual and require a serious cultural reformation (and also genetic engineering, hopefully); but that wasn't my point and I don't think a utilitarian is being inconsistent in assuming that most people will never become utilitarians and a communist economy will never be practical.<br/><br/><blockquote class="uncited"><div>I actually happen to think that the only thing that is unconditionally good is maximizing happiness. Everything else, even promoting Utilitarianism, is at most conditionally good. </div></blockquote><br/><br/><blockquote class="uncited"><div> Promoting Utilitarianism is good on the condition that people are intelligent and rational enough to be able to predict consequences with reasonable accuracy and thus actually do the most good. If people are mentally impoverished and prone to making huge errors in reasoning, I might actually be more inclined towards promoting some kind of simpler, deontological system that they can easily understand and which tends to maximize happiness. Whatever actually works in maximizing happiness, is what I would promote.</div></blockquote><br/><br/><br/><br/>Regardless of how intelligent or rational someone is, I don't think there's a conceivable universe in which a person wouldn't necessarily be more likely to maximize happiness if doing so wasn't their explicit intention. Why would deontology work better than a set of general rules that can be abandoned in specific circumstances when it appears to the agent in question that breaking the rule will have better consequences than following it? Cognitive empathy and imagination have as much to do with being able to accurately infer which decisions are more likely to maximize happiness and minimize suffering as intelligence and a capacity for rational decision making do. Hedonistic utilitarianism and the meta-ethical position that justifies it is 'simple' and 'easily understood', instead of 'never do this' or 'always do that' -regardless of circumstance- any moral agent can live by the principle of caring about the happiness and suffering of others the way that they care about their own well-being and as hard as this may be, intelligence has nothing to do with it. The complication and uncertainty comes in to play when it comes to determining exactly which decisions are likely to maximize the ratio of happiness-suffering, especially on a wide scale level, but again, a perfectly logical, high IQ computer with no emotional experience will have a harder time predicting how their decisions will affect other people than a 6 year old would. Utilitarianism doesn't just apply to economics and political decisions that affect a large group of people, utilitarianism is adopting and loving sheltered cats and dogs, cooking meals for homeless people, dressing up as Santa Clause for sick children, being a pen pale to prisoners, volunteering at hospitals, leaving strangers kind notes, befriending or sticking up for bullied school children etc. It kind of turns me off that ethics is considered this completely impersonal, abstract academic topic that doesn't really relate to day to day life. Why does utilitarianism only come up with the trolley problem or justifying war or forced organ donation or some horrible, often impractical event we'll never have to worry about, what about mundane issues like giving someone at a bus stop a ride to where they're going or mowing someone's lawn?<br/><br/>There may be some personality types that are more likely to be drawn to hedonistic utilitarianism or philosophical hedonism than others but our basic experience of happiness and pain is something that all sentient beings can relate to, regardless of IQ, personality, sex, ethnicity, species, political orientation/philosophy etc. It's universal. If I ever thought promoting a view other than utilitarianism was justified it would be because some of the conclusions that utilitarianism justifies are too counter-intuitive and difficult to swallow but I don't see what rationality or intelligence would have to do with it. Because of the universality of happiness and suffering, I think most -if not all- of our anti-utilitarian intuitions can be conquered and put it into context (ie. what if I were a family member of one of the  passengers who would be saved if one person was sacrificed to stop the train or would I rather experience a great amount of pain at once or a milder, but non-trivial- amount of pain every day for the rest of my life etc.). I might have elaborated if I wasn't running out of time.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9119">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9123">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9123">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-24T20:27:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>It's completely inconceivable how a fundamentally new kind of reality can arise from inter-subjectively observable physical interactions, especially when those same neural events could theoretically occur without neurons suddenly gaining an entirely new and 'invisible' property completely unrelated to any property that has ever existed before-subjective experience- as a result of interacting with other neurons in a certain way (of course emergent property dualists can argue that consciousness is epiphenomenal so that I'm not saying that proves anything). There's no reason why this should happen. Emergence doesn't explain anything. It's just an assertion that isn't even theoretically testable. It's a philosophical assumption and not something that has ever been supported by scientific evidence. This point can only be made in so many ways, and other people can make the argument better than I can. I honestly would not be surprised if the pan-psychist view eventually becomes the dominant position in the scientific community, even though it might take a while. Would you consider yourself to be a materialist or an emergent property dualist?</div></blockquote><br/><br/>I consider myself a materialist, where materialism means (<a class="postlink" href="http://en.wikipedia.org/wiki/Materialism">according to Wikipedia</a>):<br/><br/><blockquote class="uncited"><div>In philosophy, the theory of materialism holds that all things are composed of material, and that all emergent phenomena (including consciousness) are the result of material properties and interactions. In other words, the theory claims that our reality consists entirely of physical matter that is the sole cause of every possible occurrence, including human thought, feeling, and action.</div></blockquote><br/><br/>I'm also, thanks to my background in Cognitive Science, a reductionist, which with regards to emergence means (<a class="postlink" href="http://en.wikipedia.org/wiki/Reductionism">again from Wikipedia)</a>:<br/><br/><blockquote class="uncited"><div>Reductionism does not preclude the existence of what might be called emergent phenomena, but it does imply the ability to understand those phenomena completely in terms of the processes from which they are composed. This reductionist understanding is very different from that usually implied by the term 'emergence', which typically intends that what emerges is more than the sum of the processes from which it emerges.</div></blockquote><br/><br/>So I apologize for confusing you with the figure of speech, "more than the sum of its parts".  Technically, I shouldn't have used that to explain emergence, because it comes with a lot of baggage that is different from what a reductionist means by emergent phenomena.<br/><br/>If you haven't already, you really should read <a class="postlink" href="http://en.wikipedia.org/wiki/Emergence">the Wikipedia article on Emergence</a>.  The scientific concept of emergent phenomena is, contrary to what you seem to believe, not very controversial in the scientific community.  I'm actually quite surprised that there are people out there that find it so objectionable, but I'm willing to consider it some kind of misunderstanding of what scientists mean when they say emergence.<br/><br/>We don't mean that there's some magical new reality that's created.  Emergent properties and phenomena exist within the physical reality.  They're very much like software running on hardware.  If you break the hardware, the software stops working too.  Most Cognitive Scientists are functionalists.  We view the mind as a kind of software running on the hardware of the brain.  To the extent that software is an emergent phenomena, so is consciousness.  But we're not "emergent property dualists".  I'm pretty sure that's not actually a thing (or if it is, it's not common among the predominant Cognitive Science views).<br/><br/><blockquote class="uncited"><div>I don't disagree with this. My only point was that a society of utilitarians would develop a communist economy because distributing resources according to benefit would necessarily have to be regarded as ideal from the point of view of someone who cared equally about everyone's well-being, even if it wasn't practically desirable for whatever reasons.I still think that utilitarians should promote a utilitarian society and - by extension- a communist economy ; if this is ever accomplished it would be very gradual and require a serious cultural reformation (and also genetic engineering, hopefully); but that wasn't my point and I don't think a utilitarian is being inconsistent in assuming that most people will never become utilitarians and a communist economy will never be practical.</div></blockquote><br/><br/>Fair enough.<br/><br/><blockquote class="uncited"><div>Regardless of how intelligent or rational someone is, I don't think there's a conceivable universe in which a person wouldn't necessarily be more likely to maximize happiness if doing so wasn't their explicit intention. Why would deontology work better than a set of general rules that can be abandoned in specific circumstances when it appears to the agent in question that breaking the rule will have better consequences than following it? Cognitive empathy and imagination have as much to do with being able to accurately infer which decisions are more likely to maximize happiness and minimize suffering as intelligence and a capacity for rational decision making do. Hedonistic utilitarianism and the meta-ethical position that justifies it is 'simple' and 'easily understood', instead of 'never do this' or 'always do that' -regardless of circumstance- any moral agent can live by the principle of caring about the happiness and suffering of others the way that they care about their own well-being and as hard as this may be, intelligence has nothing to do with it. The complication and uncertainty comes in to play when it comes to determining exactly which decisions are likely to maximize the ratio of happiness-suffering, especially on a wide scale level, but again, a perfectly logical, high IQ computer with no emotional experience will have a harder time predicting how their decisions will affect other people than a 6 year old would. Utilitarianism doesn't just apply to economics and political decisions that affect a large group of people, utilitarianism is adopting and loving sheltered cats and dogs, cooking meals for homeless people, dressing up as Santa Clause for sick children, being a pen pale to prisoners, volunteering at hospitals, leaving strangers kind notes, befriending or sticking up for bullied school children etc. It kind of turns me off that ethics is considered this completely impersonal, abstract academic topic that doesn't really relate to day to day life. Why does utilitarianism only come up with the trolley problem or justifying war or forced organ donation or some horrible, often impractical event we'll never have to worry about, what about mundane issues like giving someone at a bus stop a ride to where they're going or mowing someone's lawn?</div></blockquote><br/><br/>I agree with you that utilitarianism can and does apply to all those examples that you made.  I do in my own life, try to be as utilitarian as I can manage, by doing simple things like holding doors for strangers, or giving up my seat on the bus for an elderly person, or just being considerate and caring about how other people feel (though I am by no means perfect at this).  I wasn't suggesting that utilitarianism was unworkable for most people, but just that it might be possible that for some people, some other ethical system might be useful as a means to getting them to behave morally.  For instance, I think the mixture of virtue ethics and deontology that Christianity uses (at least for the Christians who emphasize the New Testament), commands like "Love Thy Neighbour" and the Golden Rule, are often surprisingly effective at getting otherwise selfish people to behave morally and altruistically.<br/><br/>Interestingly, whenever I ask my friends whether they care more about rules or consequences, they almost always say consequences, so it's quite possible that a lot of people already use pseudo-utilitarian reasoning for a lot of their actions.  A lot more people would agree with the statement "I should do things for the greater good", than an explicit definition of Utilitarianism.<br/><br/>And I do agree that empathy plays a huge role in motivating most moral behaviour.  I would almost go so far as to argue that the core of any moral philosophy is centered around an empathetic emotional motivation.  We choose to be fair and care about everyone's happiness because we can imagine and feel other people's happiness ourselves, and so we can understand that they value their happiness just as much as we do.<br/><br/><blockquote class="uncited"><div>There may be some personality types that are more likely to be drawn to hedonistic utilitarianism or philosophical hedonism than others but our basic experience of happiness and pain is something that all sentient beings can relate to, regardless of IQ, personality, sex, ethnicity, species, political orientation/philosophy etc. It's universal. If I ever thought promoting a view other than utilitarianism was justified it would be because some of the conclusions that utilitarianism justifies are too counter-intuitive and difficult to swallow but I don't see what rationality or intelligence would have to do with it. Because of the universality of happiness and suffering, I think most -if not all- of our anti-utilitarian intuitions can be conquered and put it into context (ie. what if I were a family member of one of the passengers who would be saved if one person was sacrificed to stop the train or would I rather experience a great amount of pain at once or a milder, but non-trivial- amount of pain every day for the rest of my life etc.). I might have elaborated if I wasn't running out of time.</div></blockquote><br/><br/>I would think so too.  The problem is that there are people who have gotten so separated from their emotions or have absorbed memes about how suffering is good to achieve success, that they don't automatically see the relationships that might otherwise seem obvious to us who have really put the time into thinking about it.  Like, for instance, a lot of people straight up think killing is wrong as a rule.  To them, it makes perfect sense, and the idea that we should weigh the consequences seems cruel and inhumane.  There's a reason why "cost-benefit analysis" is often a dirty phrase.  The Ford Pinto example comes to mind.  Rationality and intelligence have to do with being able to see beyond the cultural memes and actually analyze one's beliefs with care.  It also means looking beyond the immediate emotional payoff towards the actual long term consequences and effects.  To that extent, I think that more rational and intelligent folk are more likely to be able to accept Utilitarianism, as well as be able to better perform the often complex moral calculus that is involved with actually making good moral decisions.  For instance, there are a lot of charities that may seem like a great idea to get involved with at first glance, but when you actually analyze their contributions, they may not be the most efficient use of your time as an altruist.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9123">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9132">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9132">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-25T17:52:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>So I apologize for confusing you with the figure of speech, "more than the sum of its parts". </div></blockquote><br/><br/>I understood what you meant I just disagree with it.<br/><br/><blockquote class="uncited"><div>The scientific concept of emergent phenomena is, contrary to what you seem to believe, not very controversial in the scientific community.</div></blockquote><br/><br/>I know that it isn't. Materialism is the dominant view among scientists but there are several physicists and biologists who would argue against a strong emergence of consciousness from non-conscious physical activity (actually, from a consistent materialist point of view, consciousness doesn't exist to begin with). <br/><br/><blockquote class="uncited"><div>We don't mean that there's some magical new reality that's created.</div></blockquote><br/><br/>You don't consciously think that, obviously, but this is what I believe your position implies. <br/><br/><blockquote class="uncited"><div>I'm actually quite surprised that there are people out there that find it so objectionable<br/></div></blockquote><br/><br/>And I'm genuinely surprised that someone who can sit down, go over and understand the argument against emergence (never mind strong emergence) of consciousness from no consciousness can still think that consciousness arising from physical activity is plausible which is why I wouldn't be surprised if pan-psychism eventually becomes the dominant view among scientists. Like I said, I haven't done the issue justice.<br/><br/><br/><blockquote class="uncited"><div> but I'm willing to consider it some kind of misunderstanding of what scientists mean when they say emergence.</div></blockquote><br/><br/>It isn't a misunderstanding of what scientists mean when they talk about emergence. Some people, including scientists, just disagree with you.<br/><br/><blockquote class="uncited"><div> But we're not "emergent property dualists". I'm pretty sure that's not actually a thing</div></blockquote><br/><br/>Materialists believe that physical phenomenon is all that exists which implies that consciousness is an illusion (which I believe is nonsensical because it would have to exist in order to appear as though it did, our consciousness is exactly the way that it appears to be even if our sensory perception of the external world doesn't correspond with the external world as it actually is). Emergent property dualists believe that the mental and physical are fundamentally different kinds of properties that brains have but the former emerges from the latter. My issue with emergent property dualism is logical and not empirical but materialism completely defies direct experience. Subjective experience is not the neural activity it corresponds with. A tree is not a rock. Nobody else can experience what I can experience even though they can view the neurological activity that corresponds with what I experience.<br/><br/><blockquote class="uncited"><div> I do in my own life, try to be as utilitarian as I can manage, by doing simple things like holding doors for strangers, or giving up my seat on the bus for an elderly person, or just being considerate and caring about how other people feel (though I am by no means perfect at this).</div></blockquote><br/><br/>Then I admire you for that because I don't consider myself to be a practicing utilitarian beyond being a vegan. I'm not really a kind or a cruel person (I love all non-human animals, though). I'd choose to abolish suffering and to make every (potential and actual) sentient being  experience as much happiness as one possibly could in a heart beat if I could but I don't do much for other people, I tend to mind my own business.<br/><br/><blockquote class="uncited"><div>For instance, I think the mixture of virtue ethics and deontology that Christianity uses (at least for the Christians who emphasize the New Testament), commands like "Love Thy Neighbour" and the Golden Rule, are often surprisingly effective at getting otherwise selfish people to behave morally and altruistically.</div></blockquote><br/><br/>There are aspects of Christianity and other ethical systems that I admire and find deeply endearing, partly because religion usually takes a more personal and 'emotional' approach to ethics than secular ethics seems to, but they're not without serious problems either.Christianity is speciesist, sexist and homophobic, for one (or three). A supposedly loving and merciful god sends people (humans and demons) to hell for rejecting his authority ; Christians would say that he has to do this because he is also a just god and that would be one example of happiness being sacrificed for a value it's completely incommensurable with (justice). Christians might not send people to hell because their god does but the concept of hell can be harmful to people (especially children). I could go on but you could probably guess which aspects of Christianity and other religions I have a problem with. Not only do I have a problem with happiness (and by extension - as a moral value - compassion) being sacrificed for incommensurable values like sanctity, preference fulfillment, knowledge, justice, objective list theory of values etc. but religions also devalue happiness by making a distinction between 'true/authentic' happiness and worldly pleasures. In my opinion, the pleasure people experience when high on MDMA and other drugs or having an orgasm is 'true' happiness and has the same intrinsic value that ecstatic, joyful and peaceful religious and spiritual experiences do. Sadistic pleasure (if it exists) has intrinsic value but the psychology that allows it is inherently criticisable and even sadists themselves would be happier, in the long run, if they were more compassionate.<br/><br/><blockquote class="uncited"><div>Interestingly, whenever I ask my friends whether they care more about rules or consequences, they almost always say consequences, so it's quite possible that a lot of people already use pseudo-utilitarian reasoning for a lot of their actions. A lot more people would agree with the statement "I should do things for the greater good", than an explicit definition of Utilitarianism.</div></blockquote><br/><br/>Virtually everyone, including utilitarians, has contradicting moral intuitions, though. Most people will have a utilitarian attitude on one issue and a deontologist position on another or 'value' happiness in one scenario and something else in another.  A world of consistent utilitarians would look very different than the world as it is but a world of consistent deontologists would probably look very different as well.<br/><br/><blockquote class="uncited"><div>And I do agree that empathy plays a huge role in motivating most moral behaviour. I would almost go so far as to argue that the core of any moral philosophy is centered around an empathetic emotional motivation.</div></blockquote><br/><br/>'Affective empathy/compassion/sympathy' as I understand it (identifying with and caring about the felt emotional well-being of others) is the sole basis for what I would consider to be good intentions (at least as far as decisions we make that we expect to affect other people are concerned).<br/><br/><blockquote class="uncited"><div> We choose to be fair and care about everyone's happiness because we can imagine and feel other people's happiness ourselves, and so we can understand that they value their happiness just as much as we do.</div></blockquote><br/><br/>I would argue that their happiness is -intrinsic to it's nature- valuable. I don't think we give value to our emotional states (we experience them as such) and I don't think we would have any reason to care about anyone else's suffering simply because they 'dis-value' it. You already know my issue with 'fairness'. In most cases, I might say imagination is more important than intelligence because imagination is the basis of empathy.<br/><br/><br/><blockquote class="uncited"><div>Rationality and intelligence have to do with being able to see beyond the cultural memes and actually analyze one's beliefs with care.</div></blockquote><br/><br/><blockquote class="uncited"><div>I think that more rational and intelligent folk are more likely to be able to accept Utilitarianism</div></blockquote><br/><br/>Intelligent people might place more emphasis on logical consistency but the value of happiness can't be logically deduced in any way. <br/><br/>In theory, I would expect people who are introverted/introspective, experience emotion more intensely (they might be sensation seeking and/or neurotic) and 'concrete' thinkers as opposed to 'abstract' thinkers ('abstract' in the sense of being oriented toward the conceptual, symbolic and ideas that aren't supported by what is directly experienced or perceived through the senses and not 'abstract' in the sense of being generalized) to be more likely to accept philosophical hedonism or hedonistic utilitarianism. The first because happiness is internally felt and they might be more 'hyper aware' of their emotional response to things and not just the external object of their emotion itself. The second for obvious and similar reasons. The third because happiness is something we directly experience and not an idea, concept or rational judgment, people who accept raw experience at face value might be more likely to, not just identify with H.U, but accept philosophical hedonism as a meta-ethical position. I don't know if there's anything to this, I could be way off.<br/><br/><br/><blockquote class="uncited"><div> It also means looking beyond the immediate emotional payoff towards the actual long term consequences and effects.</div></blockquote><br/><br/>I agree with this completely.<br/><br/><blockquote class="uncited"><div>as well as be able to better perform the often complex moral calculus that is involved with actually making good moral decisions. For instance, there are a lot of charities that may seem like a great idea to get involved with at first glance, but when you actually analyze their contributions, they may not be the most efficient use of your time as an altruist.</div></blockquote><br/><br/>I agree with this but how would promoting deontology for less intelligent people help in scenarios like this as opposed to more intelligent people simply advising less intelligent people on which decisions are more likely to have better consequences? And as far as predicting 'consequences' is concerned, we can measure economic production or the number of lives saved 'objectively' but to predict how other people will actually <span style="font-style: italic">feel </span>requires imagination and using our own past experience as a reference, not intelligence. Intelligence is something that someone can use to help them accomplish their goal but I'm not sure if intelligent people are more likely to care about maximizing happiness/minimizing suffering (generally) to begin with. Some research has actually shown a negative correlation between intelligence and empathy or agreeableness (libertarians, who apparently score the lowest on empathy, also score higher on IQ tests in comparison to both liberals and conservatives) and one study has shown that regions of the brain involved in logical reasoning and empathizing with others actually conflict. When people assume that humans are more emotionally 'developed' (whatever that means) than non-human animals, I actually wonder if less cognitively developed persons experience emotions more intensely because they feel more than they think.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9132">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9135">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9135">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-25T19:21:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>I understood what you meant I just disagree with it.</div></blockquote><br/><br/>I guess we'll just have to agree to disagree then.<br/><br/><blockquote class="uncited"><div>Materialists believe that physical phenomenon is all that exists which implies that consciousness is an illusion (which I believe is nonsensical because it would have to exist in order to appear as though it did, our consciousness is exactly the way that it appears to be even if our sensory perception of the external world doesn't correspond with the external world as it actually is). Emergent property dualists believe that the mental and physical are fundamentally different kinds of properties that brains have but the former emerges from the latter. My issue with emergent property dualism is logical and not empirical but materialism completely defies direct experience. Subjective experience is not the neural activity it corresponds with. A tree is not a rock. Nobody else can experience what I can experience even though they can view the neurological activity that corresponds with what I experience.</div></blockquote><br/><br/>I'm not sure that materialism actually implies that consciousness is an illusion.  Illusion is a very strong word.  Again, a better metaphor is that consciousness is like the software that runs on our biological hardware.  It's the algorithm that "emerges" from the neural activity and connections.<br/><br/>I think subjective experience is the neural activity though, because if you do something like damage the brain, or change the brain's chemistry with drugs, you can directly influence how the consciousness is felt.<br/><br/>I'm not sure what you mean by a tree is not a rock.  One is a living organism, while the other is not, but neither of them appear to be sentient.<br/><br/>And arguably, if we took all the neural connections and synthetically duplicated them exactly as they are, we could possibly create a copy of your mind that would be a separate entity that could experience exactly what you experience given the right activations.<br/><br/><blockquote class="uncited"><div>Then I admire you for that because I don't consider myself to be a practicing utilitarian beyond being a vegan. I'm not really a kind or a cruel person (I love all non-human animals, though). I'd choose to abolish suffering and to make every (potential and actual) sentient being experience as much happiness as one possibly could in a heart beat if I could but I don't do much for other people, I tend to mind my own business.</div></blockquote><br/><br/>Uh, thanks.  I'm definitely not a perfect utilitarian though.  I sometimes struggle just to do the simple things that my morality says I ought to.  That you're a practicing vegan means that you are to an extent, practicing your utilitarian values in at least one way.  So I think that at least is admirable as well.<br/><br/>I actually don't interfere much with other people unless I'm really confident that I can do good.  There's always the danger that in my ignorance, I could try to help someone, but actually end up making the situation worse.  So it's actually good to be careful about how you go about being compassionate.  That you even think about such things I think sets you apart from a lot of other people.<br/><br/><blockquote class="uncited"><div>There are aspects of Christianity and other ethical systems that I admire and find deeply endearing, partly because religion usually takes a more personal and 'emotional' approach to ethics than secular ethics seems to, but they're not without serious problems either.Christianity is speciesist, sexist and homophobic, for one (or three). A supposedly loving and merciful god sends people (humans and demons) to hell for rejecting his authority ; Christians would say that he has to do this because he is also a just god and that would be one example of happiness being sacrificed for a value it's completely incommensurable with (justice). Christians might not send people to hell because their god does but the concept of hell can be harmful to people (especially children). I could go on but you could probably guess which aspects of Christianity and other religions I have a problem with. Not only do I have a problem with happiness (and by extension - as a moral value - compassion) being sacrificed for incommensurable values like sanctity, preference fulfillment, knowledge, justice, objective list theory of values etc. but religions also devalue happiness by making a distinction between 'true/authentic' happiness and worldly pleasures. In my opinion, the pleasure people experience when high on MDMA and other drugs or having an orgasm is 'true' happiness and has the same intrinsic value that ecstatic, joyful and peaceful religious and spiritual experiences do. Sadistic pleasure (if it exists) has intrinsic value but the psychology that allows it is inherently criticisable and even sadists themselves would be happier, in the long run, if they were more compassionate.</div></blockquote><br/><br/>To the extent that I lean towards Christianity, I actually prefer the doctrine of Universalism, which argues that hell will be empty and that all people are ultimately going to be saved and go to heaven regardless of their beliefs upon death.  To me Universalism seems more consistent with a truly omnibenevolent God.  Admittedly, it is not the doctrine of the majority of churches though.<br/><br/>I'm currently on the fence about whether or not there is a "true/authentic" happiness like Eudaimonia, or if subjective happiness is by itself sufficient to justify all of morality.  Though I think that "justice" can be reconciled with happiness if you take the view that "justice" is just about being fair and that all sentient beings "deserve" to be happy.<br/><br/><blockquote class="uncited"><div>I would argue that their happiness is -intrinsic to it's nature- valuable. I don't think we give value to our emotional states (we experience them as such) and I don't think we would have any reason to care about anyone else's suffering simply because they 'dis-value' it. You already know my issue with 'fairness'. In most cases, I might say imagination is more important than intelligence because imagination is the basis of empathy.</div></blockquote><br/><br/>I think that intelligence is a prerequisite for imagination, that the ability to cognate and simulate situations in one's mind is part of what allows people to be so imaginative.  They are, at very least, well correlated.<br/><br/><blockquote class="uncited"><div>I agree with this but how would promoting deontology for less intelligent people help in scenarios like this as opposed to more intelligent people simply advising less intelligent people on which decisions are more likely to have better consequences? And as far as predicting 'consequences' is concerned, we can measure economic production or the number of lives saved 'objectively' but to predict how other people will actually feel requires imagination and using our own past experience as a reference, not intelligence. Intelligence is something that someone can use to help them accomplish their goal but I'm not sure if intelligent people are more likely to care about maximizing happiness/minimizing suffering (generally) to begin with. Some research has actually shown a negative correlation between intelligence and empathy or agreeableness (libertarians, who apparently score the lowest on empathy, also score higher on IQ tests in comparison to both liberals and conservatives) and one study has shown that regions of the brain involved in logical reasoning and empathizing with others actually conflict. When people assume that humans are more emotionally 'developed' (whatever that means) than non-human animals, I actually wonder if less cognitively developed persons experience emotions more intensely because they feel more than they think.</div></blockquote><br/><br/>Well, for the same reason two-level utilitarianism promotes using heuristics.  Less intelligent people have fewer cognitive cycles per unit of energy, and so, burdening them with challenging calculations may not be the most efficient use of their resources.  In moments where we lack the time, energy, and information to perform detailed moral calculations, it makes sense to rely on good, effective heuristics that can quickly be used to output what is probably the "correct moral response".<br/><br/>We can't always have more intelligent people advising the less intelligent ones, particularly since there is a tendency for less intelligent people to not listen to the more intelligent ones anyway.  In situations where the less intelligent person is unable to receive guidance on an immediately demanding circumstance, they need some kind of moral decision method.<br/><br/>As for intelligence and empathy conflicting, I'll admit that I've met a number of such libertarian types who are quite "smart", but not very "nice".  But I think that IQ only measures very specific forms of intelligence, the logical and abstract reasoning stuff, and that intelligence in a more general sense includes things like being good at imagining what it's like to be in someone else's situation.  Arguably that's why there's also separate tests for things like Emotional Intelligence.  A person's overall intelligence to me, includes how imaginative they are.<br/><br/>I don't know about whether less cognitively developed persons experience more intense emotions.  My own intuition is that objectively it is the same, but because they don't have the same basis for comparison, it might be seem relatively more intense.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9135">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9143">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9143">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-26T17:49:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>I'm not sure that materialism actually implies that consciousness is an illusion. Illusion is a very strong word.</div></blockquote><br/><br/>Eliminative materialists would disagree with you but I don't want to get into why I believe eliminative materialism is consistent materialism.<br/><br/><blockquote class="uncited"><div>Again, a better metaphor is that consciousness is like the software that runs on our biological hardware. It's the algorithm that "emerges" from the neural activity and connections.<br/><br/>I think subjective experience is the neural activity though</div></blockquote><br/><br/><blockquote class="uncited"><div>I'm not sure what you mean by a tree is not a rock.</div></blockquote><br/><br/>To say that private subjective experience is inter-subjectively observable neurological activity is to say that consciousness is something other than what it appears to be, it is an 'illusion'. What 'appears' to be my perception of color or my experience of pain is not what appears to be neurons firing and carrying out whatever algorithms that they do, they are clearly two separate things. To say that what 'appears' to be consciousness (and consciousness must be as it appears to, appearance itself is consciousness) is really neurological activity violates the law of identity.<br/><br/><blockquote class="uncited"><div>if you do something like damage the brain, or change the brain's chemistry with drugs, you can directly influence how the consciousness is felt.</div></blockquote><br/><br/>I'm not a Cartesian substance dualist. I wouldn't deny that the mental is fundamentally connected to the physical.<br/><br/><blockquote class="uncited"><div>I actually don't interfere much with other people unless I'm really confident that I can do good. There's always the danger that in my ignorance, I could try to help someone, but actually end up making the situation worse. So it's actually good to be careful about how you go about being compassionate. That you even think about such things I think sets you apart from a lot of other people.</div></blockquote><br/><br/>That sounds like a wise approach to take in some circumstances but by temperament I'm just not a very social person.<br/><br/><br/><blockquote class="uncited"><div>To the extent that I lean towards Christianity, I actually prefer the doctrine of Universalism, which argues that hell will be empty and that all people are ultimately going to be saved and go to heaven regardless of their beliefs upon death. To me Universalism seems more consistent with a truly omnibenevolent God. Admittedly, it is not the doctrine of the majority of churches though.</div></blockquote><br/><br/>That sounds interesting.<br/><br/><blockquote class="uncited"><div>I'm currently on the fence about whether or not there is a "true/authentic" happiness like Eudaimonia, or if subjective happiness is by itself sufficient to justify all of morality.</div></blockquote><br/><br/>I have a hard time understanding why some pleasurable states would have more inherent value than others by some objective standard other than how good they actually feel. I also think the idea of qualitatively higher and lower pleasurable states is incoherent. It might intuitively seem otherwise because the quantitative difference between a mild amount of happiness or distress and an extreme amount of happiness or suffering can be huge ; like the difference between a raindrop and the Pacific Ocean.<br/><br/><blockquote class="uncited"><div> Though I think that "justice" can be reconciled with happiness if you take the view that "justice" is just about being fair and that all sentient beings "deserve" to be happy.</div></blockquote><br/><br/>I wouldn't argue against the idea that all beings 'deserve' (are worthy of, not entitled to) happiness but I don't think we are due happiness. If we are, I still think happiness should be maximized because it's good and not because it's due. If by some objective standard a man like Hitler really was due suffering, I would still think that his suffering was intrinsically dis-valuable and should be minimized (if doing so wouldn't conflict with minimizing a greater amount of suffering or maximizing a greater amount of happiness). I think that we should be 'fair' if fairness is just giving people equal consideration but I don't believe in equalizing advantages between privileged and less fortunate people for it's own sake. I can't find the article online but there was a study done that showed that participants preferred to earn less if it meant that nobody earned more than they did. I can't imagine why someone would sacrifice improving their own situation just to prevent other people from being better off.<br/><br/><blockquote class="uncited"><div>I think that intelligence is a prerequisite for imagination, that the ability to cognate and simulate situations in one's mind is part of what allows people to be so imaginative. They are, at very least, well correlated.</div></blockquote><br/><br/>They may be correlated but I understand general intelligence to be the ability to reason and understand and imagination as being able to mentally simulate experience or perception. I doubt cognitively less developed animals have our capacity for imagination but I don't think either (intelligence or imagination) implies the other. Children seem to be more imaginative than adults. Also, by imagination I don't really mean creativity. <br/><br/><br/><blockquote class="uncited"><div>Well, for the same reason two-level utilitarianism promotes using heuristics. Less intelligent people have fewer cognitive cycles per unit of energy, and so, burdening them with challenging calculations may not be the most efficient use of their resources. In moments where we lack the time, energy, and information to perform detailed moral calculations, it makes sense to rely on good, effective heuristics that can quickly be used to output what is probably the "correct moral response".</div></blockquote><br/><br/>A deontologist isn't just someone who follows a convenient heuristic to avoid having to think and calculate what the likely consequences of a decision will be. A deontologist is someone who adheres to a moral rule forbidding a certain action or demanding another for it's own sake. Someone who follows a general rule that they expect to have the best consequences for that reason and not for the sake of following the rule itself is not a deontologist. Even a less intelligent person can realize, in at least some scenarios, how unlikely it is that following a normally wise rule will have the best consequences. A deontologist's commitment to rules is unconditional. Following a general rule in moments when we lack the time, energy or information to carry out detailed calculations is probably a good idea for everyone.<br/><br/><br/><blockquote class="uncited"><div>We can't always have more intelligent people advising the less intelligent ones, particularly since there is a tendency for less intelligent people to not listen to the more intelligent ones anyway. In situations where the less intelligent person is unable to receive guidance on an immediately demanding circumstance, they need some kind of moral decision method.</div></blockquote><br/><br/>Again, if someone assumes that cheating on one's partner, stealing money for needed food or medicine or telling a lie is wrong because it causes unnecessary suffering/unnecessarily minimizing happiness and not because the action itself  is unconditionally bad and would condone doing so in at least some hypothetical scenarios then they're not a deontologist. An intelligent deontologist (who happens to regard these actions as bad) would view these decisions as immoral even in scenarios when they are virtually guaranteed to have the 'best' (most beneficial) consequences (and the actors would justify making them under the assumption that they would not cause unnecessary suffering/unnecessarily minimize happiness so - if you're only concerned with happiness/suffering- you couldn't criticize their intentions or character). A deontologist follows the rule for the sake of the rule and not just on the assumption that it will have the 'best' (most beneficial) consequences.<br/><br/><blockquote class="uncited"><div>As for intelligence and empathy conflicting, I'll admit that I've met a number of such libertarian types who are quite "smart", but not very "nice". But I think that IQ only measures very specific forms of intelligence, the logical and abstract reasoning stuff, and that intelligence in a more general sense includes things like being good at imagining what it's like to be in someone else's situation. Arguably that's why there's also separate tests for things like Emotional Intelligence. A person's overall intelligence to me, includes how imaginative they are.</div></blockquote><br/><br/>It's debatable how valid the idea of emotional intelligence is. In my opinion, you're using the word 'intelligence' in such a broad way that makes it meaningless, at least as far as this conversation is concerned. Someone could be very imaginative and empathetic yet lack the intelligence needed to carry out detailed/complex moral calculations (calculations that are useful in predicting objectively measurable things like economic production, the number of lives saved etc. but not the private emotional experience of other people) . We can say that they are high in one kind of intelligence (imagination and empathy) but they're still lacking in the kind of intelligence that you think will make someone a more effective altruist or open to utilitarianism.<br/><br/><br/><blockquote class="uncited"><div>I don't know about whether less cognitively developed persons experience more intense emotions. My own intuition is that objectively it is the same, but because they don't have the same basis for comparison, it might be seem relatively more intense.</div></blockquote><br/><br/>Neither do I. This might not be the best point to make for my argument (not that I'm convinced it's true or anything) but if two people are madly in love and on a date or whatever, it would probably be a mood kill if they started talking about the complex neural algorithms that are involved in what they feel for one another or how their feelings were favored by natural selection for whatever reason. When you see a pretty sunset or listen to beautiful music, you don't want to think about it or analyze it, you just want to feel it.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9143">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9144">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9144">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-27T01:10:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>To say that private subjective experience is inter-subjectively observable neurological activity is to say that consciousness is something other than what it appears to be, it is an 'illusion'. What 'appears' to be my perception of color or my experience of pain is not what appears to be neurons firing and carrying out whatever algorithms that they do, they are clearly two separate things. To say that what 'appears' to be consciousness (and consciousness must be as it appears to, appearance itself is consciousness) is really neurological activity violates the law of identity.</div></blockquote><br/><br/>Maybe what consciousness looks like from the inside is different from what it looks like from the outside?  I'm not sure I fully understand what you're trying to say, but the idea of an "illusion" suggests to me that it somehow isn't real, not just that it is not what it appears to be.<br/><br/><blockquote class="uncited"><div>I have a hard time understanding why some pleasurable states would have more inherent value than others by some objective standard other than how good they actually feel. I also think the idea of qualitatively higher and lower pleasurable states is incoherent. It might intuitively seem otherwise because the quantitative difference between a mild amount of happiness or distress and an extreme amount of happiness or suffering can be huge ; like the difference between a raindrop and the Pacific Ocean.</div></blockquote><br/><br/>It's not that there are some pleasurable states that are more valuable, but rather that there may be some kind of "objective state" that is more valuable than just our subjective experiences.  For instance, image a situation where you could take a pill that would cause you to hallucinate that you were achieving all your hopes and dreams, be the perfect Utilitarian, or whatever you value most.  Would this be equally good as actually achieving all your hopes and dreams, actually being the perfect Utilitarian, and actually achieving whatever your values are?  Some would argue that this objective state of self-actualization is actually more good than just the feeling of happiness itself.<br/><br/><blockquote class="uncited"><div>I wouldn't argue against the idea that all beings 'deserve' (are worthy of, not entitled to) happiness but I don't think we are due happiness. If we are, I still think happiness should be maximized because it's good and not because it's due. If by some objective standard a man like Hitler really was due suffering, I would still think that his suffering was intrinsically dis-valuable and should be minimized (if doing so wouldn't conflict with minimizing a greater amount of suffering or maximizing a greater amount of happiness). I think that we should be 'fair' if fairness is just giving people equal consideration but I don't believe in equalizing advantages between privileged and less fortunate people for it's own sake. I can't find the article online but there was a study done that showed that participants preferred to earn less if it meant that nobody earned more than they did. I can't imagine why someone would sacrifice improving their own situation just to prevent other people from being better off.</div></blockquote><br/><br/>Well, what I'm suggesting is that one of the basic principles built into the maximizing happiness principle of Utilitarianism -is- fairness, as the reason why we want to maximize the happiness of everyone and not just people we arbitrarily decide to care about. <br/><br/>As for why someone would sacrifice improving their own situation just to prevent other people from being better off, as far as I can tell it's because people are irrational and often care more about relative success than actual success.<br/><br/><blockquote class="uncited"><div>A deontologist isn't just someone who follows a convenient heuristic to avoid having to think and calculate what the likely consequences of a decision will be. A deontologist is someone who adheres to a moral rule forbidding a certain action or demanding another for it's own sake. Someone who follows a general rule that they expect to have the best consequences for that reason and not for the sake of following the rule itself is not a deontologist. Even a less intelligent person can realize, in at least some scenarios, how unlikely it is that following a normally wise rule will have the best consequences. A deontologist's commitment to rules is unconditional. Following a general rule in moments when we lack the time, energy or information to carry out detailed calculations is probably a good idea for everyone.<br/><br/>...<br/><br/>Again, if someone assumes that cheating on one's partner, stealing money for needed food or medicine or telling a lie is wrong because it causes unnecessary suffering/unnecessarily minimizing happiness and not because the action itself is unconditionally bad and would condone doing so in at least some hypothetical scenarios then they're not a deontologist. An intelligent deontologist (who happens to regard these actions as bad) would view these decisions as immoral even in scenarios when they are virtually guaranteed to have the 'best' (most beneficial) consequences (and the actors would justify making them under the assumption that they would not cause unnecessary suffering/unnecessarily minimize happiness so - if you're only concerned with happiness/suffering- you couldn't criticize their intentions or character). A deontologist follows the rule for the sake of the rule and not just on the assumption that it will have the 'best' (most beneficial) consequences.</div></blockquote><br/><br/>I know what a deontologist is.  I'm not saying that the deontologist would be right, only that it might produce the best consequences to teach some people deontological-resembling rule sets rather than teaching them strict Act Utilitarianism.  Admittedly, I don't know if this is true.  Maybe I'm being arrogant to assume that less intelligent people might not be able to use proper Utilitarianism to as good effect as a deontological-resembling rule set.  Maybe we should just teach everyone Two-Level Utilitarianism and ask the less intelligent folk to use Rule level Utilitarianism for more things.<br/><br/><blockquote class="uncited"><div>Neither do I. This might not be the best point to make for my argument (not that I'm convinced it's true or anything) but if two people are madly in love and on a date or whatever, it would probably be a mood kill if they started talking about the complex neural algorithms that are involved in what they feel for one another or how their feelings were favored by natural selection for whatever reason. When you see a pretty sunset or listen to beautiful music, you don't want to think about it or analyze it, you just want to feel it.</div></blockquote><br/><br/>True dat.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9144">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9145">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9145">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-27T18:42:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>Maybe what consciousness looks like from the inside is different from what it looks like from the outside?</div></blockquote><br/><br/>What does that mean? How can an experience look different from the inside as opposed to the outside? How does an experience have an 'outside'? I think of the mind or consciousness itself as the 'inside' to the body's 'outside'.<br/><br/><blockquote class="uncited"><div> I'm not sure I fully understand what you're trying to say, but the idea of an "illusion" suggests to me that it somehow isn't real, not just that it is not what it appears to be.</div></blockquote><br/><br/>There are eliminative materialists who will say with a straight face that consciousness does not exist.<br/><br/>An illusion (according to one online dictionary) : <br/><br/>1.something that deceives by producing a false or misleading impression of reality.<br/><br/>2. the state or condition of being deceived; misapprehension.<br/><br/>3. an instance of being deceived.<br/><br/>4.Psychology . a perception, as of visual stimuli (optical illusion)  that represents what is perceived in a way different from the way it is in reality.<br/><br/>Our sensory perception of the external, physical world may be misleading but experience itself is exactly the way that it appears to be.<br/><br/><blockquote class="uncited"><div>It's not that there are some pleasurable states that are more valuable, but rather that there may be some kind of "objective state" that is more valuable than just our subjective experiences. For instance, image a situation where you could take a pill that would cause you to hallucinate that you were achieving all your hopes and dreams, be the perfect Utilitarian, or whatever you value most. Would this be equally good as actually achieving all your hopes and dreams, actually being the perfect Utilitarian, and actually achieving whatever your values are? Some would argue that this objective state of self-actualization is actually more good than just the feeling of happiness itself.</div></blockquote><br/><br/>I assumed that your position was closer to mine than it appears to be. I think that there are altruistic reasons that would justify someone not plugging into a Virtual Reality machine for the rest of their life (their loved ones would miss them and they couldn't help or benefit anyone else) but the experience people would or do have plugged into a V.R machine or hallucinating or dreaming would be or is 100 % authentic and real. We many not live in a world with werewolves or vampires or magic but the 'simulated' experience of living in a world with these things would be identical to what we would experience if we actually did live in a world where these things existed or were possible. Hedonistic utilitarianism has implications that are counter-intuitive to me (like brutally torturing someone in order to prevent a billion people from each getting a speck of dust in their eye, a lot of this has to do with scope insensitivity) but I think the basic idea that the actual experience of happiness is the only intrinsic good and the felt experience of pain is the only intrinsic bad fits in perfectly- or almost perfectly- with my intuitions.<br/><br/>I'll probably read more about this later but, if you don't mind, what exactly is the difference between Eudaimonism and objective list theory of value?<br/><br/><blockquote class="uncited"><div>Well, what I'm suggesting is that one of the basic principles built into the maximizing happiness principle of Utilitarianism -is- fairness, as the reason why we want to maximize the happiness of everyone and not just people we arbitrarily decide to care about. </div></blockquote><br/><br/>If 'fairness' just means egalitarianism (specifically equal consideration of interests) then I don't have an issue with it. But I think 'fairness', as many people use the term, has connotations that aren't consistent with utilitarianism. The word doesn't matter.<br/><br/>I believe that the reason why we should want to maximize the happiness of everyone and not just some people is because of happiness itself, fairness by any definition isn't the starting point of my moral world view. If I met someone who didn't want their partner to cheat on them yet they cheated on their partner - despite believing that a person is better off when their preference for a monogamous or honest ('honest' in the sense of literal truth telling) is fulfilled even when it doesn't affect their emotional state-, their not treating their partner the way that they wanted to be treated is not what I would criticize. What I would criticize is a willingness to harm their partner (depending on how certain they are that their partner won't suspect or find out or be harmed indirectly in any way and how much effort they put into ensuring this). And I would criticize them for not allowing or encouraging their partner to sleep with other people if they believed it would make them happy but no more than I would criticize a monogamous person who demanded of their partner what they were willing to do themselves if they had reason to believe that their partner would enjoy sleeping or having romantic affairs with other people. My position is inherently egalitarian but I don't care about moral consistency or egalitarianism per se, at least not as a starting point. I don't admire a man who believes that it benefits someone to have their left hand cut off, regardless of whether or not they want or like this, and, in the spirit of equal consideration, cuts off the left hand of as many other people as he can just as he cut off his own left hand. I would rather he be hypocritical and not cut off anyone's hand despite criticizing others for not doing so or that he be selfish and only cut off his own hand if he must cut off anyone's.<br/><br/><br/><blockquote class="uncited"><div>I know what a deontologist is.</div></blockquote><br/><br/>No disrespect intended. I was just trying to give my 2 cents on what I think a consistent deontology implies.<br/><br/><blockquote class="uncited"><div>I'm not saying that the deontologist would be right, only that it might produce the best consequences to teach some people deontological-resembling rule sets rather than teaching them strict Act Utilitarianism.</div></blockquote><br/><br/>My understanding (correct me if I'm wrong) is that an act-utilitarian evaluates the rightness or wrongness of decisions according to whether or not those decisions bring about the best overall consequences (or at least help to) and rule utilitarianism evaluates the rightness or wrongness of decisions based on whether or not they are in accordance with rules that <span style="font-style: italic">tend</span> to bring about the best consequences. Rule utilitarianism seems to me to be about more than just general rules, it's deontology but deontology in which the favored rules are determined by their typical consequences. How unintelligent does someone have to be to not realize that in at least some scenarios an action which typically or sometimes has bad consequences will have good consequences? This isn't just hypothetical, I could probably think of many examples in which a 6 year old could realize that one normally good or bad action will probably have overall bad, good or neutral consequences in a specific scenario. By 'good' and 'bad' and 'best' I mean beneficial and harmful, I'm sure a deontologist would view unconditional obedience to moral rules as good in itself.<br/><br/><blockquote class="uncited"><div> Admittedly, I don't know if this is true. Maybe I'm being arrogant to assume that less intelligent people might not be able to use proper Utilitarianism to as good effect as a deontological-resembling rule set. Maybe we should just teach everyone Two-Level Utilitarianism and ask the less intelligent folk to use Rule level Utilitarianism for more things.</div></blockquote><br/><br/>What I want to know is how you'll go about determining exactly who falls into the relatively more or less intelligent camp and how most people might feel being treated as less intelligent than other people (even if some people are naturally more intelligent than others and, from my point of view, intelligence is only a tool or an advantage and not a virtue). I still think you overestimate the importance of 'intelligence' in helping someone to determine which decisions are more likely to maximize happiness and minimize suffering and underestimate imagination and cognitive empathy. It's one thing to encourage more intelligent people to become politicians, scientists, economists etc. but not all of the moral decisions we make require the kind of intelligence needed to make the decisions that politicians, scientists, doctors etc. make. Someone is a consequentialist if their assumption that an action or inaction will have the best overall consequences is their justification for making that decision. Even if you argue for encouraging less intelligent people to be rule utilitarians instead of deontologists, how are there not some scenarios in which the exact same actions will not probably have different consequences, this has to be obvious to most people in at least some situations.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9145">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9146">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9146">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-27T19:45:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>What does that mean? How can an experience look different from the inside as opposed to the outside? How does an experience have an 'outside'? I think of the mind or consciousness itself as the 'inside' to the body's 'outside'.</div></blockquote><br/><br/>Well, yes.  The mind is like the 'inside' to the brain's 'outside'.  From the inside, we have the experience of consciousness.  From the outside we have the matter that makes up the brain.  The idea is that things can "appear" different depending on your point of view.  When you are the brain, you experience it from the inside.  Everyone else can only experience it from the outside.<br/><br/><blockquote class="uncited"><div>There are eliminative materialists who will say with a straight face that consciousness does not exist.<br/><br/>An illusion (according to one online dictionary) : <br/><br/>1.something that deceives by producing a false or misleading impression of reality.<br/><br/>2. the state or condition of being deceived; misapprehension.<br/><br/>3. an instance of being deceived.<br/><br/>4.Psychology . a perception, as of visual stimuli (optical illusion) that represents what is perceived in a way different from the way it is in reality.<br/><br/>Our sensory perception of the external, physical world may be misleading but experience itself is exactly the way that it appears to be.</div></blockquote><br/><br/>I agree with your last statement.<br/><br/><blockquote class="uncited"><div>I assumed that your position was closer to mine than it appears to be. I think that there are altruistic reasons that would justify someone not plugging into a Virtual Reality machine for the rest of their life (their loved ones would miss them and they couldn't help or benefit anyone else) but the experience people would or do have plugged into a V.R machine or hallucinating or dreaming would be or is 100 % authentic and real. We many not live in a world with werewolves or vampires or magic but the 'simulated' experience of living in a world with these things would be identical to what we would experience if we actually did live in a world where these things existed or were possible. Hedonistic utilitarianism has implications that are counter-intuitive to me (like brutally torturing someone in order to prevent a billion people from each getting a speck of dust in their eye, a lot of this has to do with scope insensitivity) but I think the basic idea that the actual experience of happiness is the only intrinsic good and the felt experience of pain is the only intrinsic bad fits in perfectly- or almost perfectly- with my intuitions.<br/><br/>I'll probably read more about this later but, if you don't mind, what exactly is the difference between Eudaimonism and objective list theory of value?</div></blockquote><br/><br/>My position is actually not firmly in one camp or the other right now.  While I like the idea of Eudaimonia, I'm also willing to seriously consider the more hedonistic idea of straight up happiness as being the only thing to absolutely value.  In practice right now, I'm functionally a classical utilitarian, because Eudaimonic Utilitarianism is still too incomplete a theory, and too difficult to actually practice, given that it seems to demand a God-like amount of knowledge.<br/><br/>Eudaimonism is arguably a subset of the objective list theory of value, where there is only one value on the list, which is this concept of Eudaimonia.  Other objective list theories tend to be pluralistic and have many possible values in the list.  To be honest, I'm still not sure I have a coherent enough definition of Eudaimonia to really be sure what the difference is.<br/><br/><blockquote class="uncited"><div>If 'fairness' just means egalitarianism (specifically equal consideration of interests) then I don't have an issue with it. But I think 'fairness', as many people use the term, has connotations that aren't consistent with utilitarianism. The word doesn't matter.</div></blockquote><br/><br/>I use fairness instead of equality because it's possible that it may be "fair" to give preference to more sentient creatures over less sentient creatures.<br/><br/><blockquote class="uncited"><div>I believe that the reason why we should want to maximize the happiness of everyone and not just some people is because of happiness itself, fairness by any definition isn't the starting point of my moral world view. If I met someone who didn't want their partner to cheat on them yet they cheated on their partner - despite believing that a person is better off when their preference for a monogamous or honest ('honest' in the sense of literal truth telling) is fulfilled even when it doesn't affect their emotional state-, their not treating their partner the way that they wanted to be treated is not what I would criticize. What I would criticize is a willingness to harm their partner (depending on how certain they are that their partner won't suspect or find out or be harmed indirectly in any way and how much effort they put into ensuring this). And I would criticize them for not allowing or encouraging their partner to sleep with other people if they believed it would make them happy but no more than I would criticize a monogamous person who demanded of their partner what they were willing to do themselves if they had reason to believe that their partner would enjoy sleeping or having romantic affairs with other people. My position is inherently egalitarian but I don't care about moral consistency or egalitarianism per se, at least not as a starting point. I don't admire a man who believes that it benefits someone to have their left hand cut off, regardless of whether or not they want or like this, and, in the spirit of equal consideration, cuts off the left hand of as many other people as he can just as he cut off his own left hand. I would rather he be hypocritical and not cut off anyone's hand despite criticizing others for not doing so or that he be selfish and only cut off his own hand if he must cut off anyone's.</div></blockquote><br/><br/>That's fine.  I'm not saying you have to agree with the Principle of Fairness(TM) in order to want to maximize happiness.  I'm only noting that the Principle of Fairness(TM), seems to be at least partly assumed by the Greatest Happiness Principle, and is compatible with it.<br/><br/><blockquote class="uncited"><div>No disrespect intended. I was just trying to give my 2 cents on what I think a consistent deontology implies.</div></blockquote><br/><br/>Fair enough.<br/><br/><blockquote class="uncited"><div>My understanding (correct me if I'm wrong) is that an act-utilitarian evaluates the rightness or wrongness of decisions according to whether or not those decisions bring about the best overall consequences (or at least help to) and rule utilitarianism evaluates the rightness or wrongness of decisions based on whether or not they are in accordance with rules that tend to bring about the best consequences. Rule utilitarianism seems to me to be about more than just general rules, it's deontology but deontology in which the favored rules are determined by their typical consequences. How unintelligent does someone have to be to not realize that in at least some scenarios an action which typically or sometimes has bad consequences will have good consequences? This isn't just hypothetical, I could probably think of many examples in which a 6 year old could realize that one normally good or bad action will probably have overall bad, good or neutral consequences in a specific scenario. By 'good' and 'bad' and 'best' I mean beneficial and harmful, I'm sure a deontologist would view unconditional obedience to moral rules as good in itself.</div></blockquote><br/><br/>Your understanding is correct I think.  However, I also think you'd be surprised at just how bad some people can be at predicting consequences, especially when they have particular biases that make them want certain consequences to happen.  Yes, there are easy examples that a 6 year old could figure out, but there are also hard examples that an above average adult might have considerable trouble with.<br/><br/><blockquote class="uncited"><div>What I want to know is how you'll go about determining exactly who falls into the relatively more or less intelligent camp and how most people might feel being treated as less intelligent than other people (even if some people are naturally more intelligent than others and, from my point of view, intelligence is only a tool or an advantage and not a virtue). I still think you overestimate the importance of 'intelligence' in helping someone to determine which decisions are more likely to maximize happiness and minimize suffering and underestimate imagination and cognitive empathy. It's one thing to encourage more intelligent people to become politicians, scientists, economists etc. but not all of the moral decisions we make require the kind of intelligence needed to make the decisions that politicians, scientists, doctors etc. make. Someone is a consequentialist if their assumption that an action or inaction will have the best overall consequences is their justification for making that decision. Even if you argue for encouraging less intelligent people to be rule utilitarians instead of deontologists, how are there not some scenarios in which the exact same actions will not probably have different consequences, this has to be obvious to most people in at least some situations.</div></blockquote><br/><br/>Admittedly this is a tough question.  I could argue perhaps that IQ or some other standardized test might work, but there's always concerns about biases and the limits of standardized testing.  And it's a fair point that discriminating against less intelligent people might hurt them and have bad consequences generally.  I'm willing to concede that teaching everyone Two Level Utilitarianism, and especially how to best judge when to use Rule Utilitarianism and when to use Act Utilitarianism, may be the best way forward.<br/><br/>I'm also considering that practically speaking, some people may be unwilling to adopt any kind of Utilitarianism, and so for them, if they are more amenable to Virtue Ethics or Deontology, to find a form of Virtue Ethics or Deontology that is functionally like a kind of Rule Utilitarianism, or at least has similar consequences.  I see it as using the alternative moral paradigms as a means to the end of maximizing the good.  Ideally, people should know Utilitarianism, but realistically, some people may just prefer to operate under different paradigms, and the consequences of forcefully indoctrinating people are generally bad enough that it's probably better to work with the other moral theories and find common ground so more people can practice moral behaviour.<br/><br/>For instance, I actually see Kantianism as being potentially compatible with Utilitarianism if you really look closely at it.  The Kantian notion of treating people as ends rather than just as means?  Utilitarianism does that better than any other system, because we include everyone's happiness as an end of the calculation.  Arguably traditional Kantianism fails to live up to its own principle, because when you refuse to lie to the potential murderer, you're essentially treating the murderer's potential victim as a means to the end of your being "moral".<br/><br/>Similarly, the Categorical Imperative of doing only that which should be a universal law?  Would not maximizing the happiness of everyone be the best if universalized?  The Categorical Imperative itself actually has consequentialist reasoning built into it.  So at the end of the day, I can argue that a true Kantian -should- be a Utilitarian! <img alt=":D" src="../images/smilies/icon_e_biggrin.gif"/><br/><br/>And even if the Kantian's don't agree with me, I don't consider having a few Kantian's in the world a bad thing.  They never lie, steal, kill, or do any things that are usually bad, so they make pretty reliable individuals in terms of knowing exactly where they stand, at least compared to the average more self-interest individual.  I'm of the opinion that any moral system is better than nothing, because there's enough common ground on most situations that in the majority of cases, Virtue Ethics, Deontology, and Consequentialism will usually argue for the same things, like having human rights and not killing people who annoy you.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9146">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9147">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9147">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/59.html">DanielLC</a></strong> on 2014-02-28T04:26:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>However, I also think you'd be surprised at just how bad some people can be at predicting consequences, especially when they have particular biases that make them want certain consequences to happen.</div></blockquote><br/><br/>There's a difference between following rules because you don't trust yourself to know when breaking them yields better results, and following rules because you think it's better in principle even if breaking them does yield better results.</div><div class="diff hidden"></div></div>
<div class="signature">Consequentialism: The belief that doing the right thing makes the world a better place.</div>
</div>
<dl class="postprofile" id="profile9147">
<dt>
<a href="../user/59.html"></a><br/>
<a href="../user/59.html">DanielLC</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 703</dd>
<dd><strong>Joined:</strong> Fri Oct 10, 2008 4:29 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9154">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9154">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-28T18:26:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>There's a difference between following rules because you don't trust yourself to know when breaking them yields better results, and following rules because you think it's better in principle even if breaking them does yield better results.</div></blockquote><br/><br/>Yes indeed.  But at the same time, we as Utilitarians are flexible in the sense that our ideology cares about consequences more than anything else.  Thus, even if we disagree on some very fundamental principles with the deontologists, we can still find some practical common ground and use their own beliefs in ways that contribute to the greatest good.  At least, that's my thinking.  Admittedly, it might be easier to just convert them to Utilitarianism, but if that's not possible, we should be flexible and open to making the best of use of what we have to work with.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9154">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9155">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9155">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-02-28T18:33:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>The idea is that things can "appear" different depending on your point of view. When you are the brain, you experience it from the inside. Everyone else can only experience it from the outside.</div></blockquote><br/><br/><br/>But we're not talking about the same thing. Different people perceive the same external world differently (some birds and insects can see colors that we can't, cats and dogs are partially color blind). A brain is a spatial object and brains only 'experience' (perceive) themselves through the same sensory perception that other people perceive them with. Sensory perception itself and emotion is non-spatial (you can't measure subjective experience in terms of width or length) and can't appear differently to other people because it is fundamentally subjective.<br/><br/><br/><blockquote class="uncited"><div>My position is actually not firmly in one camp or the other right now. While I like the idea of Eudaimonia, I'm also willing to seriously consider the more hedonistic idea of straight up happiness as being the only thing to absolutely value. In practice right now, I'm functionally a classical utilitarian, because Eudaimonic Utilitarianism is still too incomplete a theory, and too difficult to actually practice, given that it seems to demand a God-like amount of knowledge.<br/><br/>Eudaimonism is arguably a subset of the objective list theory of value, where there is only one value on the list, which is this concept of Eudaimonia. Other objective list theories tend to be pluralistic and have many possible values in the list. To be honest, I'm still not sure I have a coherent enough definition of Eudaimonia to really be sure what the difference is.</div></blockquote><br/><br/>Thanks.<br/><br/><br/><blockquote class="uncited"><div>I use fairness instead of equality because it's possible that it may be "fair" to give preference to more sentient creatures over less sentient creatures.</div></blockquote><br/><br/>I completely reject the concept of some animals being less sentient  than others if 'sentience' refers to a capacity to experience and not cognition. By less sentient do you mean lacking in self-awareness or autonomy? Would this distinction be relevant to eudaimonism and, if not, wouldn't you be juggling two different theories of welfare? How would fairness as opposed to equality justifying giving preference to some creatures over others?<br/><br/><br/><blockquote class="uncited"><div>That's fine. I'm not saying you have to agree with the Principle of Fairness(TM) in order to want to maximize happiness. I'm only noting that the Principle of Fairness(TM), seems to be at least partly assumed by the Greatest Happiness Principle, and is compatible with it.</div></blockquote><br/><br/>If I don't need to agree with the Principle of Fairness in order to adopt the Greatest Happiness principle then how is it at least partly assumed by it? If one does not imply the other and they are two fundamentally different positions then aren't you rejecting value monism?<br/><br/><blockquote class="uncited"><div> Your understanding is correct I think. However, I also think you'd be surprised at just how bad some people can be at predicting consequences, especially when they have particular biases that make them want certain consequences to happen. Yes, there are easy examples that a 6 year old could figure out, but there are also hard examples that an above average adult might have considerable trouble with.</div></blockquote><br/><br/>I agree and I also think people can use ad hoc utilitarian reasoning to justify their decisions but, as DanielLC pointed out, if their intentions are to maximize the best consequences and they choose not to make the decision that probably would have the best consequences only because they're not convinced that it would but would make that same decision in a hypothetical scenario when they would have little to no uncertainty as to what the consequences of that or any alternative decision would be then they are consequentialists. How are less intelligent people more likely to make better decisions if they operate under the principle that some decisions are forbidden in any conceivable scenario and not just following a general rule as the default assumption about what will have the best consequences? Are you saying that less intelligent people should be encouraged to adopt a rule utilitarian position on some issues but not all?<br/><br/><blockquote class="uncited"><div>and especially how to best judge when to use Rule Utilitarianism and when to use Act Utilitarianism, may be the best way forward.</div></blockquote><br/><br/>Why not make the distinction between when to use a general rule and when to make an exception? I'm sure that most people who donate to charity and want to make a difference will take an economist's advice on which charities are more cost effective (what do you think of Dambisa Moyo, by the way?) but what specific examples do you have in mind  when you think lower IQ, everyday people with no particular political power should adopt a rule utilitarian position as opposed to attempting to calculate what the best consequences will actually be? If act utilitarianism should be promoted for higher IQ people then we should want more act-utilitarian politicians to be put into positions of power but how would you convince rule utilitarians to support this if their ethical position contradicts their own? <br/><br/><blockquote class="uncited"><div>I'm also considering that practically speaking, some people may be unwilling to adopt any kind of Utilitarianism, and so for them, if they are more amenable to Virtue Ethics or Deontology, to find a form of Virtue Ethics or Deontology that is functionally like a kind of Rule Utilitarianism, or at least has similar consequences. I see it as using the alternative moral paradigms as a means to the end of maximizing the good. Ideally, people should know Utilitarianism, but realistically, some people may just prefer to operate under different paradigms, and the consequences of forcefully indoctrinating people are generally bad enough that it's probably better to work with the other moral theories and find common ground so more people can practice moral behaviour.</div></blockquote><br/><br/>I agree that forcefully indoctrinating people would have overwhelmingly bad consequences. And I can understand acknowledging that many people will never adopt utilitarianism and looking for common ground with the ethical theories that they do adopt, I still don't really think utilitarians should avoid criticizing these positions where they diverge. Moral behavior to me (at least in terms of intentions and character) is an impartial concern for the experience of happiness and suffering so while I can understand promoting or working with/tolerating views other than hedonistic utilitarianism and although there are many relatively moral non-utilitarians, I don't consider them to be moral beyond their concern for felt-well being, even if they are concerned with what they believe to be good or beneficial to others.<br/><br/><br/><br/><blockquote class="uncited"><div>For instance, I actually see Kantianism as being potentially compatible with Utilitarianism if you really look closely at it. The Kantian notion of treating people as ends rather than just as means? Utilitarianism does that better than any other system, because we include everyone's happiness as an end of the calculation. Arguably traditional Kantianism fails to live up to its own principle, because when you refuse to lie to the potential murderer, you're essentially treating the murderer's potential victim as a means to the end of your being "moral".<br/><br/>Similarly, the Categorical Imperative of doing only that which should be a universal law? Would not maximizing the happiness of everyone be the best if universalized? The Categorical Imperative itself actually has consequentialist reasoning built into it. So at the end of the day, I can argue that a true Kantian -should- be a Utilitarian!</div></blockquote><br/><br/>I don't entirely agree but I'm not really in the mood to get into why.<br/><br/><blockquote class="uncited"><div>I don't consider having a few Kantian's in the world a bad thing. They never lie, steal, kill, or do any things that are usually bad, so they make pretty reliable individuals in terms of knowing exactly where they stand, at least compared to the average more self-interest individual.</div></blockquote><br/><br/>People can rely on consistent utilitarians to give equal consideration (or at least some serious consideration since perfect utilitarians will never exist) to all beings. I don't see it as virtuous to not do bad or normally bad things in scenarios when you believe they would probably have the best overall consequences.<br/><br/><blockquote class="uncited"><div> I'm of the opinion that any moral system is better than nothing, because there's enough common ground on most situations that in the majority of cases, Virtue Ethics, Deontology, and Consequentialism will usually argue for the same things</div></blockquote><br/><br/>The same things for different reasons and I think those reasons are important, not because I care what people believe or what ideology they adhere to per se but because they will lead to practical differences in decision making. In my view, a system is only moral to the extent that it involves a concern for happiness and suffering unconditionally. Like I said, the starting point of my ethical world view is hedonism as a theory of value (not just welfare) and everything else that I identify with or support (ideologically, at least), including utilitarianism, is just an implication of that.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9155">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9156">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9156">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-02-28T21:58:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>But we're not talking about the same thing. Different people perceive the same external world differently (some birds and insects can see colors that we can't, cats and dogs are partially color blind). A brain is a spatial object and brains only 'experience' (perceive) themselves through the same sensory perception that other people perceive them with. Sensory perception itself and emotion is non-spatial (you can't measure subjective experience in terms of width or length) and can't appear differently to other people because it is fundamentally subjective.</div></blockquote><br/><br/>I guess so.  To be honest I'm really not certain how to classify subjective experience.  There's a reason why they call it the <a class="postlink" href="http://en.wikipedia.org/wiki/Hard_problem_of_consciousness">Hard Problem of Consciousness</a>.<br/><br/>[quoteI completely reject the concept of some animals being less sentient than others if 'sentience' refers to a capacity to experience and not cognition. By less sentient do you mean lacking in self-awareness or autonomy? Would this distinction be relevant to eudaimonism and, if not, wouldn't you be juggling two different theories of welfare? How would fairness as opposed to equality justifying giving preference to some creatures over others?[/quote]<br/><br/>By less sentient I literally mean, that they feel less and are less conscious because they have fewer neurons and connections.  Like, I think being an insect would be kind of like being a human heavily drugged with anti-psychotics, such that their whole experience of everything is diminished (people heavily on anti-psychotics basically turn into zombies in terms of how they feel).  It's similar to if they have a lobotomy.  They literally feel less happiness and suffering than a non-drugged or non-lobotomized normal person would given the exact same stimulus.<br/><br/>Self-awareness suggests greater sentience, but isn't conditional for it.  Autonomy is more associated with sapience than sentience.  As for Eudaimonism, it would only be relevant in the same way it would be relevant to hedonism I think.<br/><br/>Fairness suggests that if some entity actually feels less, they should be assigned a proportionally lesser value in the hedonistic calculus.  Equality would suggest that all entities should be assigned the exact same value regardless of how sentient they were.  Like, consider a photo-diode.  They arguably "experience" the difference between light and dark, but their level of sentience is so low that we probably won't assign much value to the experiences of photo-diodes.<br/><br/>I mean, how do you deal with the fact that if panpsychism is true, then bacteria are probably somewhat sentient and they should overwhelm our calculations for what matters due to their sheer numbers.  I prefer to think that sentience is graded and that creatures that experience more deserve greater relative consideration.  It fits my intuitions better about the relative importance of human experience.  Though I know Brian probably still disagrees with me, so you're not alone in defending the more egalitarian view.<br/><br/><blockquote class="uncited"><div>If I don't need to agree with the Principle of Fairness in order to adopt the Greatest Happiness principle then how is it at least partly assumed by it? If one does not imply the other and they are two fundamentally different positions then aren't you rejecting value monism?</div></blockquote><br/><br/>Fairness to me is not an intrinsic value.  It is rather, a principle that has usefulness.  If I had to choose between fairness and happiness for everyone, I'd be inclined choose the latter.  It's just convenient that fairness seems to agree with the Greatest Happiness Principle, and it might suggest that seemingly different moral considerations are actually interrelated.<br/><br/><blockquote class="uncited"><div>I agree and I also think people can use ad hoc utilitarian reasoning to justify their decisions but, as DanielLC pointed out, if their intentions are to maximize the best consequences and they choose not to make the decision that probably would have the best consequences only because they're not convinced that it would but would make that same decision in a hypothetical scenario when they would have little to no uncertainty as to what the consequences of that or any alternative decision would be then they are consequentialists. How are less intelligent people more likely to make better decisions if they operate under the principle that some decisions are forbidden in any conceivable scenario and not just following a general rule as the default assumption about what will have the best consequences? Are you saying that less intelligent people should be encouraged to adopt a rule utilitarian position on some issues but not all?</div></blockquote><br/><br/>Okay, fine, I concede that it's probably better to teach everyone Utilitarianism if possible.  My own conscience was nagging me about how treating lower intelligence people differently was a double standard, and that I should be giving the benefit of the doubt to them.<br/><br/><blockquote class="uncited"><div>Why not make the distinction between when to use a general rule and when to make an exception? I'm sure that most people who donate to charity and want to make a difference will take an economist's advice on which charities are more cost effective (what do you think of Dambisa Moyo, by the way?) but what specific examples do you have in mind when you think lower IQ, everyday people with no particular political power should adopt a rule utilitarian position as opposed to attempting to calculate what the best consequences will actually be? If act utilitarianism should be promoted for higher IQ people then we should want more act-utilitarian politicians to be put into positions of power but how would you convince rule utilitarians to support this if their ethical position contradicts their own? </div></blockquote><br/><br/>I haven't heard of Dambisa Moyo before, but it seems like she's a good economist?<br/><br/>Again, I admit the double standard is probably not the best idea after all.<br/><br/><blockquote class="uncited"><div>I agree that forcefully indoctrinating people would have overwhelmingly bad consequences. And I can understand acknowledging that many people will never adopt utilitarianism and looking for common ground with the ethical theories that they do adopt, I still don't really think utilitarians should avoid criticizing these positions where they diverge. Moral behavior to me (at least in terms of intentions and character) is an impartial concern for the experience of happiness and suffering so while I can understand promoting or working with/tolerating views other than hedonistic utilitarianism and although there are many relatively moral non-utilitarians, I don't consider them to be moral beyond their concern for felt-well being, even if they are concerned with what they believe to be good or beneficial to others.</div></blockquote><br/><br/>Well, I'm just saying you should be understanding to other moral views.  They probably think you're the one who's immoral for emphasizing consequences in ways that they might find abhorrent.  It doesn't help if we just get into a huge flame war between our different moral camps over the nitty gritty details.  Though if we can civilly convince them to change their views, then by all means.<br/><br/><blockquote class="uncited"><div>People can rely on consistent utilitarians to give equal consideration (or at least some serious consideration since perfect utilitarians will never exist) to all beings. I don't see it as virtuous to not do bad or normally bad things in scenarios when you believe they would probably have the best overall consequences.</div></blockquote><br/><br/>And there will be people who disagree with you, and they might even argue that equal consideration is not enough, that rights should be absolute to protect everyone from abuses.  I'm not arguing that, and right now you're basically preaching to the choir, but just keep in that in mind.<br/><br/><blockquote class="uncited"><div>The same things for different reasons and I think those reasons are important, not because I care what people believe or what ideology they adhere to per se but because they will lead to practical differences in decision making. In my view, a system is only moral to the extent that it involves a concern for happiness and suffering unconditionally. Like I said, the starting point of my ethical world view is hedonism as a theory of value (not just welfare) and everything else that I identify with or support (ideologically, at least), including utilitarianism, is just an implication of that.</div></blockquote><br/><br/>And aside from my adventures dabbling in Eudaimonism, I essentially agree with you.  But other people won't, and it may be practically beneficial to be able to "talk in their language" in order to bring about better consequences.  The practical differences in decision making are still important, but in life, sometimes we must make compromises to avoid losing the war for hearts and minds.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9156">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9159">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9159">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-03-02T19:06:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>To be honest I'm really not certain how to classify subjective experience.</div></blockquote><br/><br/>We can only classify a thing in contrast with different things. Subjective experience is fundamentally different than the external, spatial/physical world, even if the two are undeniably connected.<br/><br/><br/><br/><blockquote class="uncited"><div>By less sentient I literally mean, that they feel less and are less conscious because they have fewer neurons and connections. Like, I think being an insect would be kind of like being a human heavily drugged with anti-psychotics, such that their whole experience of everything is diminished (people heavily on anti-psychotics basically turn into zombies in terms of how they feel). It's similar to if they have a lobotomy. They literally feel less happiness and suffering than a non-drugged or non-lobotomized normal person would given the exact same stimulus.</div></blockquote><br/><br/>I don't think there's any evidence for fewer neural connections implying a weaker emotional response to stimuli and I'm not sure how you would test for this. The nervous systems of invertebrates are surprisingly complicated and most neural connections in human brains don't have anything to do with our conscious experience. I think it's a huge mistake to emphasize quantity over 'quality'. Lady bugs are believed to have an unusually acute sense of hearing, far superior to human hearing (or maybe it's smell and not hearing, I can't remember, but it's one of the senses). By your reasoning they are 'more sentient' in this regard.<br/><br/>The concept of one person being less conscious than another seems fundamentally nonsensical to me. It may be that members of some species typically feel emotions less intensely in response to the same stimuli but how intensely individuals experience emotion may vary even among humans (depending on personality and influenced by heredity and environment) and this would be a quantitative difference, not a black and white difference. If one person experiences emotion half as intensely as another they would still benefit or be harmed more from some stimuli in some circumstances and there would still be some scenarios in which their interests should be given priority.<br/><br/><blockquote class="uncited"><div>Self-awareness suggests greater sentience, but isn't conditional for it. Autonomy is more associated with sapience than sentience. As for Eudaimonism, it would only be relevant in the same way it would be relevant to hedonism I think.</div></blockquote><br/><br/>Self-awareness is cognitive, we never experience a static self separate from moment to moment experience. I don't see why we should assume a baby screeching at the top of his lungs every 5 minutes is less capable of distress because he lacks self-awareness. The reason why I asked is because I thought maybe you were saying that animals who can form long-term preferences should be given priority over those who cannot which would create a hierarchy between them - contradicting the idea of equality- but would be 'fair' because those preferences warranted consideration.<br/><br/><blockquote class="uncited"><div>Fairness suggests that if some entity actually feels less, they should be assigned a proportionally lesser value in the hedonistic calculus. Equality would suggest that all entities should be assigned the exact same value regardless of how sentient they were. Like, consider a photo-diode. They arguably "experience" the difference between light and dark, but their level of sentience is so low that we probably won't assign much value to the experiences of photo-diodes.</div></blockquote><br/><br/>I completely disagree.<br/><br/>The hedonistic calculus is concerned with the actual experience of happiness and suffering and not the capacity for happiness and suffering. How capable someone is of emotion (which doesn't make sense because a being either is or is not capable of some degree of emotion, instead I should say how intensely they are predisposed to experience emotion) is relevant only in calculating how much happiness or suffering they actually will feel as a result of some decision.<br/><br/><br/>The equality I favor is equal consideration of interests. If one person would benefit mildly from X and another person would benefit greatly, giving both of their interests equal consideration allows for prioritizing the second person's interests only because they stand to benefit more than the first person would. <br/><br/>I've never heard of photo-diodes. I'm curious about what kind of experience sea stars might have. I'd give anything to see the world from another animal's eyes.<br/><br/><blockquote class="uncited"><div>I mean, how do you deal with the fact that if panpsychism is true, then bacteria are probably somewhat sentient and they should overwhelm our calculations for what matters due to their sheer numbers. I prefer to think that sentience is graded and that creatures that experience more deserve greater relative consideration. It fits my intuitions better about the relative importance of human experience. Though I know Brian probably still disagrees with me, so you're not alone in defending the more egalitarian view.</div></blockquote><br/><br/>I'm kind of surprised to hear you say this because it seems to completely contradict the basic premise of utilitarianism.<br/><br/>If bacteria are sentient so are the individual cells in our body so I think that justifies taking medicine or antibiotics. As for bacteria in the world generally, I don't know what can be done for them. If they can feel pain then their pain should be given equal consideration, even if their being sentient is inconvenient. A being who experiences emotion more intensely doesn't deserve more consideration than a being who experiences emotion less intensely, there's just more potential happiness and suffering to consider.<br/><br/>Personally, I would rather there be a heaven that all beings go to when they die and even the traditional Hindu/Jain concept of reincarnation sounds more interesting to me than pan-psychism does but regardless of what I'd prefer, I think pan-psychism is true. If pan-psychism is true then we can take comfort in the fact that there will probably always be happiness in the universe. If consciousness ends with the death of the brain then we could take comfort in the fact that all suffering will eventually end (unless you believe in multiple universes in which case happiness would probably exist forever as well).<br/><br/><br/><blockquote class="uncited"><div>Fairness to me is not an intrinsic value. It is rather, a principle that has usefulness. If I had to choose between fairness and happiness for everyone, I'd be inclined choose the latter. It's just convenient that fairness seems to agree with the Greatest Happiness Principle, and it might suggest that seemingly different moral considerations are actually interrelated.</div></blockquote><br/><br/>I think I understand your concept of fairness less now than I did before. For what is fairness useful in accomplishing? I wouldn't disagree that different moral outlooks are interrelated.<br/><br/><br/><blockquote class="uncited"><div>Okay, fine, I concede that it's probably better to teach everyone Utilitarianism if possible. My own conscience was nagging me about how treating lower intelligence people differently was a double standard, and that I should be giving the benefit of the doubt to them.</div></blockquote><br/><br/>I would say 'persuading' or 'encouraging' others to consider utilitarianism instead of 'teaching'. I don't see anything necessarily wrong with treating people differently, only with giving their interests less consideration. I don't think utilitarianism should be thought of as 'hyper-logical', intelligence can be useful but imagination and empathy are fundamental, they are the traits that I would expect hedonistic utilitarians to necessarily have more of.<br/><br/><br/><blockquote class="uncited"><div>I haven't heard of Dambisa Moyo before, but it seems like she's a good economist?</div></blockquote><br/><br/>She is a Zambian economist who argues that most foreign aid to sub-saharan African countries indirectly causes more harm then good. She wrote a book called 'Dead Aid' (I haven't read most of it) that you might be interested in. I think I understand the basic premise of her argument but I was wondering if there was some third alternative to her solution and the aid system as it exists.<br/><br/><br/><blockquote class="uncited"><div>Well, I'm just saying you should be understanding to other moral views. They probably think you're the one who's immoral for emphasizing consequences in ways that they might find abhorrent. It doesn't help if we just get into a huge flame war between our different moral camps over the nitty gritty details. Though if we can civilly convince them to change their views, then by all means.</div></blockquote><br/><br/>I understand that and I'm sure it would help to be more diplomatic but people are starting with a different set of core values when they analyze moral issues and these values are conflicting. The 'war' is not with the people who hold different views.<br/><br/><br/><blockquote class="uncited"><div>But other people won't, and it may be practically beneficial to be able to "talk in their language" in order to bring about better consequences. The practical differences in decision making are still important, but in life, sometimes we must make compromises to avoid losing the war for hearts and minds.</div></blockquote><br/><br/>I haven't denied this and I wouldn't necessarily disagree, in the past few posts my primary argument has been against promoting deontology or rule utilitarianism for 'less intelligent' people, not against tolerating, promoting or working with non-utilitarian views. The latter would not, however, require my privately adopting their views or beliefs. I think it is chilling to the bone that (as one example) someone would want to prevent terminally ill patients who are in excruciating and shocking pain from ending lives that will never improve because they believe in the sanctity of life, they may be acting out of some version of love or respect for the patient but I don't view their position as well-intentioned but misguided, I view their disregard for the victim's suffering (it is being disregarded to the extent that it takes second place to other values) as fundamentally immoral. I have no issue with the people who hold this absolute anti-euthanasia position but I'm not "tolerant" of their view. If a father really loves (and cares about..) his child he is not going to compromise his position on whether or not torturing his kid for fun could be an all right thing, he will be completely dogmatic about it being a bad thing. That's what really 'caring' about something involves.<br/><br/>This might be off but the impression I have from some of your posts is that you consider yourself to be a utilitarian first and foremost (and this is justified by a concept of fairness - of everyone being given their due and being considered equally because it is just to) and the theory of value or welfare you ascribe to is secondary to that but you aren't really concerned first and foremost with happiness per se. For me, what's 'moral' begins with happiness-suffering. <br/><br/>Again, I'm not opposed to working with other views and looking for common ground, 'talking in their language' or flat out promoting contrary positions but that's 'politics'.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9159">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9161">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9161">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-03-02T23:37:00</p>
<div class="content"><div class="postrev" data-snap="2"><blockquote class="uncited"><div>We can only classify a thing in contrast with different things. Subjective experience is fundamentally different than the external, spatial/physical world, even if the two are undeniably connected.</div></blockquote><br/><br/>I agree.<br/><br/><blockquote class="uncited"><div>I don't think there's any evidence for fewer neural connections implying a weaker emotional response to stimuli and I'm not sure how you would test for this. The nervous systems of invertebrates are surprisingly complicated and most neural connections in human brains don't have anything to do with our conscious experience. I think it's a huge mistake to emphasize quantity over 'quality'. Lady bugs are believed to have an unusually acute sense of hearing, far superior to human hearing (or maybe it's smell and not hearing, I can't remember, but it's one of the senses). By your reasoning they are 'more sentient' in this regard.<br/><br/>The concept of one person being less conscious than another seems fundamentally nonsensical to me. It may be that members of some species typically feel emotions less intensely in response to the same stimuli but how intensely individuals experience emotion may vary even among humans (depending on personality and influenced by heredity and environment) and this would be a quantitative difference, not a black and white difference. If one person experiences emotion half as intensely as another they would still benefit or be harmed more from some stimuli in some circumstances and there would still be some scenarios in which their interests should be given priority.</div></blockquote><br/><br/>As I mentioned in <a class="postlink" href="../thread/139.html#p9069">this thread</a>, the evidence seems to be from studies that show that damaging the anterior cingulate cortex of the brain reduces their emotional response to pain.  In other words, while the threshold to trigger the nociceptors is the same, the "feeling" of pain being unpleasant is diminished.<br/><br/>Lady bugs still have much fewer neurons with which to process that sensory perception.  To me it doesn't matter how acute your senses are.  What matters is how complex the parts of the brain that experience emotional valence are.  Number of neurons is just a rough approximation of how complex we should expect those elements of the brain to be.<br/><br/>I don't consider people being less conscious as being nonsensical.  I have personally experienced considerable sleep deprivation and also psychiatric medications, and I know that it's possible to feel a lot less aware and "conscious" under certain circumstances.<br/><br/>Yes, but you should still weigh things by the net happiness and suffering.  If someone can suffer less intensely under the same conditions than another person, then it makes sense that if you have to choose who suffers, it should be the one who will suffer less intensely.<br/><br/><blockquote class="uncited"><div>Self-awareness is cognitive, we never experience a static self separate from moment to moment experience. I don't see why we should assume a baby screeching at the top of his lungs every 5 minutes is less capable of distress because he lacks self-awareness. The reason why I asked is because I thought maybe you were saying that animals who can form long-term preferences should be given priority over those who cannot which would create a hierarchy between them - contradicting the idea of equality- but would be 'fair' because those preferences warranted consideration.</div></blockquote><br/><br/>We don't even know that the baby lacks self-awareness.  Maybe the baby just lacks the neural organization to remember being conscious later.  Interestingly, there have been studies that show that even an unborn fetus can remember music that was played to it while it was in the womb.<br/><br/>As for long-term preferences giving priority, I sort of agree with the idea to an extent, but I would fold it into a more general notion that more sentient beings are more likely to develop long-term preferences and so the hierarchy is about relative sentience, and that would be 'fair' if not equal.<br/><br/><blockquote class="uncited"><div>I completely disagree.<br/><br/>The hedonistic calculus is concerned with the actual experience of happiness and suffering and not the capacity for happiness and suffering. How capable someone is of emotion (which doesn't make sense because a being either is or is not capable of some degree of emotion, instead I should say how intensely they are predisposed to experience emotion) is relevant only in calculating how much happiness or suffering they actually will feel as a result of some decision.<br/><br/><br/>The equality I favor is equal consideration of interests. If one person would benefit mildly from X and another person would benefit greatly, giving both of their interests equal consideration allows for prioritizing the second person's interests only because they stand to benefit more than the first person would. <br/><br/>I've never heard of photo-diodes. I'm curious about what kind of experience sea stars might have. I'd give anything to see the world from another animal's eyes.</div></blockquote><br/><br/>Well, the actual experience of happiness and suffering is arguably different at different levels of sentience.  Again, the neuroscience suggests that it -is- possible to experience more or less emotion.<br/><br/><blockquote class="uncited"><div>I'm kind of surprised to hear you say this because it seems to completely contradict the basic premise of utilitarianism.<br/><br/>If bacteria are sentient so are the individual cells in our body so I think that justifies taking medicine or antibiotics. As for bacteria in the world generally, I don't know what can be done for them. If they can feel pain then their pain should be given equal consideration, even if their being sentient is inconvenient. A being who experiences emotion more intensely doesn't deserve more consideration than a being who experiences emotion less intensely, there's just more potential happiness and suffering to consider.<br/><br/>Personally, I would rather there be a heaven that all beings go to when they die and even the traditional Hindu/Jain concept of reincarnation sounds more interesting to me than pan-psychism does but regardless of what I'd prefer, I think pan-psychism is true. If pan-psychism is true then we can take comfort in the fact that there will probably always be happiness in the universe. If consciousness ends with the death of the brain then we could take comfort in the fact that all suffering will eventually end (unless you believe in multiple universes in which case happiness would probably exist forever as well).</div></blockquote><br/><br/>I mean that practically speaking, the fact that a being experiences emotions more intensely means that we'll end up putting more emphasis on their experiences by virtue of that additional potential happiness and suffering to consider.  Regardless of what they deserve, they get considered according to the net happiness and suffering that they experience.<br/><br/>I too would rather there was some kind of heaven for every being.<br/><br/><blockquote class="uncited"><div>I think I understand your concept of fairness less now than I did before. For what is fairness useful in accomplishing? I wouldn't disagree that different moral outlooks are interrelated.</div></blockquote><br/><br/>Fairness is just a principle that says to take the impartial position.  It is related to maximizing happiness in the sense that it is the default position of the Greatest Happiness Principle in relation to how it treats different beings.  It is useful for us to understand what the Greatest Happiness Principle actually entails.<br/><br/><blockquote class="uncited"><div>I would say 'persuading' or 'encouraging' others to consider utilitarianism instead of 'teaching'. I don't see anything necessarily wrong with treating people differently, only with giving their interests less consideration. I don't think utilitarianism should be thought of as 'hyper-logical', intelligence can be useful but imagination and empathy are fundamental, they are the traits that I would expect hedonistic utilitarians to necessarily have more of.</div></blockquote><br/><br/>What's interesting is that there were some studies before that seemed to show that more psychopathic individuals tended to use Utilitarian reasoning on certain tough moral questions (like the trolley problems).<br/><br/><blockquote class="uncited"><div>She is a Zambian economist who argues that most foreign aid to sub-saharan African countries indirectly causes more harm then good. She wrote a book called 'Dead Aid' (I haven't read most of it) that you might be interested in. I think I understand the basic premise of her argument but I was wondering if there was some third alternative to her solution and the aid system as it exists.</div></blockquote><br/><br/>Hmm, I don't know that I agree with her, but I haven't read her yet, so I'll probably give her works a chance to convince me when I have more time.<br/><br/><blockquote class="uncited"><div>I understand that and I'm sure it would help to be more diplomatic but people are starting with a different set of core values when they analyze moral issues and these values are conflicting. The 'war' is not with the people who hold different views.</div></blockquote><br/><br/>True.<br/><br/><blockquote class="uncited"><div>I haven't denied this and I wouldn't necessarily disagree, in the past few posts my primary argument has been against promoting deontology or rule utilitarianism for 'less intelligent' people, not against tolerating, promoting or working with non-utilitarian views. The latter would not, however, require my privately adopting their views or beliefs. I think it is chilling to the bone that (as one example) someone would want to prevent terminally ill patients who are in excruciating and shocking pain from ending lives that will never improve because they believe in the sanctity of life, they may be acting out of some version of love or respect for the patient but I don't view their position as well-intentioned but misguided, I view their disregard for the victim's suffering (it is being disregarded to the extent that it takes second place to other values) as fundamentally immoral. I have no issue with the people who hold this absolute anti-euthanasia position but I'm not "tolerant" of their view. If a father really loves (and cares about..) his child he is not going to compromise his position on whether or not torturing his kid for fun could be an all right thing, he will be completely dogmatic about it being a bad thing. That's what really 'caring' about something involves.<br/><br/>This might be off but the impression I have from some of your posts is that you consider yourself to be a utilitarian first and foremost (and this is justified by a concept of fairness - of everyone being given their due and being considered equally because it is just to) and the theory of value or welfare you ascribe to is secondary to that but you aren't really concerned first and foremost with happiness per se. For me, what's 'moral' begins with happiness-suffering. <br/><br/>Again, I'm not opposed to working with other views and looking for common ground, 'talking in their language' or flat out promoting contrary positions but that's 'politics'.</div></blockquote><br/><br/>I go back and forth on what I believe in.  It's not that happiness isn't first and foremost.  I actually do think that the meaning of life is to maximize the happiness of everyone.  But I also try to incorporate notions of fairness and justice as being connected to this ideal, that I value happiness because it's the right thing to do.  And at the same time, I tend to be motivated to be moral because of empathy as well.<br/><br/>I understand your position that what's moral begins with happiness-suffering.  I'm not against it by any means.  It's just that I construct my morality with Happiness being the top, and the legs of the table being notions like Justice, Liberty, Life, Love, and Truth.  These are both the how and the why foundation of my morality.  Happiness is the apex, the goal, the Greatest Good that we are maximizing.  And to achieve this we have these other principles, which in turn help to justify why happiness is so important.  They're all connected in my view.  At least, that's the amorphous little philosophy that I have thrown together.  It is admittedly not the most robust thing ever.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9161">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9163">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9163">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-03-03T18:03:00</p>
<div class="content"><div class="postrev" data-snap="2"><blockquote class="uncited"><div>As I mentioned in this thread, the evidence seems to be from studies that show that damaging the anterior cingulate cortex of the brain reduces their emotional response to pain. In other words, while the threshold to trigger the nociceptors is the same, the "feeling" of pain being unpleasant is diminished.<br/><br/>Lady bugs still have much fewer neurons with which to process that sensory perception. To me it doesn't matter how acute your senses are. What matters is how complex the parts of the brain that experience emotional valence are. Number of neurons is just a rough approximation of how complex we should expect those elements of the brain to be.</div></blockquote><br/><br/>If an animal's brain is damaged in a way that minimizes their capacity to experience pain then we should expect their capacity for pain avoiding behaving to be minimized as well. There's no more of an evolutionary reason for humans to feel pain than there is for other animals to feel pain. In different species different regions of the brain can handle the same function (and you see this in humans as well when they undergo damage to one hemisphere or certain regions). This may be semantics but we don't have an emotional response to pain, pain itself is the negative emotional response that we have to sensory and cognitive stimuli. In some respects, invertebrate nervous systems are more complicated than vertebrate neurons (Joan Dunayer has a section on invertebrates in her book Speciesism that you might be interested in). Men tend to have bigger brains than women (relative to their size and absolutely and some ethnic groups tend to have bigger brains than other ethnic groups do) but you probably don't assume that some psychologically normal human adults are more sentient than others. Also, we should expect smaller animals to have smaller brains because they are smaller animals, neurons and other cells are the same size in all species so of course bigger animals will have bigger brains with more neurons. Sperm whales have larger brains than humans. An ant has a brain that makes up 1/3rd of her body.<br/><br/>To say that a ladybug's sense of hearing is more acute than our hearing means that they hear more efficiently than we do, this necessarily negates their being less sentient. It would be one thing for you to deny that they actually do have a more acute sense of hearing but how could they possibly experience less than we do despite having a more detailed or intense experience?<br/><br/><br/><blockquote class="uncited"><div>I don't consider people being less conscious as being nonsensical. I have personally experienced considerable sleep deprivation and also psychiatric medications, and I know that it's possible to feel a lot less aware and "conscious" under certain circumstances.</div></blockquote><br/><br/>Sleep deprivation is not fun. I've never been on psychiatric medication and I don't know what that would feel like but I have had these seemingly 'half-aware' moments in between dreaming and being awake.<br/><br/>I think it might be that the reason we tend to think of dreams as vague and 'less real' is because, not being as fully self aware as we are when we are awake, the experience doesn't imprint on our episodic memory as strongly so it's our memory of the experience that is vague and fuzzy but, when we actually dream, the experience itself was as concrete and real as our waking moments. Just because we can be affected in a way that makes us less lucid doesn't mean that other animals spend their entire lives in a less lucid state (and if lucid means self-awareness or higher cognition then I don't think it matters directly).<br/><br/><blockquote class="uncited"><div>Yes, but you should still weigh things by the net happiness and suffering. If someone can suffer less intensely under the same conditions than another person, then it makes sense that if you have to choose who suffers, it should be the one who will suffer less intensely.</div></blockquote><br/><br/>I agree but this wouldn't be justified on the premise that one being deserves more consideration than the other, equal consideration would demand this. There would still be some scenarios in which we should prioritize the interests of a being who feels emotion less intensely (maybe because an excess amount of stimuli will cause them more pain than a much smaller amount will cause someone who feels pain more intensely or maybe if we have to choose between saving someone who feels happiness less intensely but will have a very long overall happy life and someone who feels happiness very intensely but will have a much shorter life).<br/><br/><br/><blockquote class="uncited"><div>We don't even know that the baby lacks self-awareness. </div></blockquote><br/><br/>And we could never know but considering that they fail the mirror self-recognition test, we have no more reason to believe that they are sentient than we do the non-human animals who also fail the test. <br/><br/><blockquote class="uncited"><div>Maybe the baby just lacks the neural organization to remember being conscious later. </div></blockquote><br/><br/>I don't understand but I agree that we will never know. Maybe the mirror test is more useful for determining a capacity for pattern recognition rather than self-awareness or maybe infants and most non-human animals just don't care about their appearance. I still think it's probably the best evidence we have for the time being.<br/><br/><blockquote class="uncited"><div>As for long-term preferences giving priority, I sort of agree with the idea to an extent, but I would fold it into a more general notion that more sentient beings are more likely to develop long-term preferences and so the hierarchy is about relative sentience, and that would be 'fair' if not equal.</div></blockquote><br/><br/>This is an example of what I mean when I say that it doesn't seem to me that your position is really hedonistic. There may be practical, indirect reasons to prioritize the interests of beings who can form long-term preferences in at least some scenarios but why is the capacity relevant in itself? Even if there are beings who can feel emotion more intensely than others (which doesn't sound that far fetched to me, I just don't think it would be related to brain size or cognition), that doesn't justify a hierarchy between them. If we give a very sick person the last available medicine it shouldn't be because we care more about her, it should be because she would benefit from it more than anyone else would; if someone else would benefit more than we should give it to them instead. <br/><br/>A quantitative difference in how intensely beings experience emotion doesn't justify a black and white absolute distinction or hierarchy in principle.<br/><br/><blockquote class="uncited"><div> Interestingly, there have been studies that show that even an unborn fetus can remember music that was played to it while it was in the womb.</div></blockquote><br/><br/>Explicitly or implicitly? I'm pretty sure that all animals show evidence of implicit memory, of being affected by past experience unconsciously but that doesn't mean that they can consciously recall what happened to them in the past. I don't remember learning to read or write yet here I am.<br/><br/><blockquote class="uncited"><div>Well, the actual experience of happiness and suffering is arguably different at different levels of sentience. Again, the neuroscience suggests that it -is- possible to experience more or less emotion.</div></blockquote><br/><br/>What could that mean? Everyone's basic experience of happiness (using 'happiness' as an umbrella term for all inherently likeable or positive emotional states) is the same (hence, calling it 'happiness' in the same way red, blue and green are all 'colors' rather than numbers). The idea of qualitatively higher or lower forms of happiness is incoherent (which doesn't deny that there are different kinds of happiness - love, excitement, humor etc. but -qualitatively- they are all equally pleasant). I completely agree that we can experience more or less emotion but the difference is quantitative, not qualitative.<br/><br/><blockquote class="uncited"><div>I mean that practically speaking, the fact that a being experiences emotions more intensely means that we'll end up putting more emphasis on their experiences by virtue of that additional potential happiness and suffering to consider. Regardless of what they deserve, they get considered according to the net happiness and suffering that they experience.</div></blockquote><br/><br/>You said something along the lines of 'we should place more value on those beings who are more sentient'. My counter is that all beings deserve equal consideration and this justifies prioritizing the interests of some people in some scenarios only because they will benefit more or be harmed more by a decision than the 'less sentient' being would but this doesn't involve a fundamental hierarchy. All beings are still considered equals and at least some scenarios would justify favoring the interests of 'less sentient' beings over 'more sentient' beings (in addition to the other examples I gave earlier, we might be justified in prioritizing the collective interests of large groups of 'less sentient' beings over the interests of a single individual who is 'more sentient'.).<br/><br/><br/><blockquote class="uncited"><div>Fairness is just a principle that says to take the impartial position. It is related to maximizing happiness in the sense that it is the default position of the Greatest Happiness Principle in relation to how it treats different beings. It is useful for us to understand what the Greatest Happiness Principle actually entails.</div></blockquote><br/><br/>I view impartiality as right because you cannot be concerned with happiness per se if you only care about some happiness and not all happiness but because my world view begins with happiness-suffering, impartiality alone is not enough because impartiality doesn't necessarily involve a concern for happiness (or it could involve a concern for things I don't believe are inherently valuable). My moral world view doesn't begin with a principle of impartiality per se. If that makes sense. I think people should be impartial but being impartial is not enough, what constitutes interests or benefit isn't second to that, it precedes it.<br/><br/>I think I understand what you're trying to say but the starting point, for me, is happiness. I don't see any moral value in caring about anything other than happiness. Maybe that would sound pushy to some people, and I wouldn't want to come off that way, but it's a matter of priorities and I just don't care about anything else directly ( at the very least, my intuitions are perfectly welfare hedonist).<br/><br/><blockquote class="uncited"><div>What's interesting is that there were some studies before that seemed to show that more psychopathic individuals tended to use Utilitarian reasoning on certain tough moral questions (like the trolley problems).</div></blockquote><br/><br/>I think those those studies are unfair. These psychopaths weren't explicit utilitarians who consciously analyzed every issue on the basis of what will produce the greatest good/least bad in the world. They simply had a utilitarian response to a specific moral question. Of course psychopaths are going to be less squeamish about killing others so can stomach the utilitarian position on the trolley problem more easily than most people could (under the pretense of doing it for the benefit of the people who would be saved) but they probably don't have a utilitarian position on gun control, economics, altruism etc. Even if utilitarianism really does correlate with psychopathy for whatever reasons, utilitarianism can't possibly be an inherently psychopathic view considering the amount of altruism it demands. There's a psychological difference between harming someone because you don't care and doing so only to prevent more suffering or maximize more happiness. What's interesting is that libertarians are supposedly more likely to give 'utilitarian' responses to the trolley problem when libertarians are supposed to live by the N.A.P. If I was ever in a situation where I had to push someone in from of a train to save more people or experiment on someone to produce a vaccine that would cure AIDS or cancer or some other disease, I would probably want to off myself immediately after. Causing a single person an unbearable, excruciating amount of pain felt at a continued moment in time (ie. not small amounts intermittently stretched out over a long period of time like a speck of dust in the eye every day for a year) is intuitively even more unacceptable to me than just painlessly killing them, a certain amount of suffering is just impossible to make sense of or deal with ; it just can't be 'all right'. You never adjust to it or get used to it, it consumes your entire existence and you have no identity beyond it ; it's just fundamentally unacceptable by it's very nature. If suffering could somehow be abolished then we wouldn't have to worry about possibly justified necessary evils like vivisection (which, by the way, I think should be performed on humans and not non-humans if it is a necessary evil and the drugs we're trying to create are for the benefit of humans), prison, war, pushing someone in front of a train etc.<br/><br/><br/><blockquote class="uncited"><div>But I also try to incorporate notions of fairness and justice as being connected to this ideal, that I value happiness because it's the right thing to do. And at the same time, I tend to be motivated to be moral because of empathy as well.</div></blockquote><br/><br/><blockquote class="uncited"><div>I understand your position that what's moral begins with happiness-suffering. I'm not against it by any means. It's just that I construct my morality with Happiness being the top, and the legs of the table being notions like Justice, Liberty, Life, Love, and Truth. </div></blockquote><br/><br/>Connecting notions of fairness and justice (and truth, life and liberty) to the greatest happiness ideal seems to me a rejection of value monism.<br/><br/><blockquote class="uncited"><div>And to achieve this we have these other principles, which in turn help to justify why happiness is so important.</div></blockquote><br/><br/>If they're only useful in helping to achieve happiness then they aren't fundamental principles. In my view, happiness justifies itself.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9163">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9165">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9165">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-03-03T20:35:00</p>
<div class="content"><div class="postrev" data-snap="2"><blockquote class="uncited"><div>If an animal's brain is damaged in a way that minimizes their capacity to experience pain then we should expect their capacity for pain avoiding behaving to be minimized as well. There's no more of an evolutionary reason for humans to feel pain than there is for other animals to feel pain. In different species different regions of the brain can handle the same function (and you see this in humans as well when they undergo damage to one hemisphere or certain regions). This may be semantics but we don't have an emotional response to pain, pain itself is the negative emotional response that we have to sensory and cognitive stimuli. In some respects, invertebrate nervous systems are more complicated than vertebrate neurons (Joan Dunayer has a section on invertebrates in her book Speciesism that you might be interested in). Men tend to have bigger brains than women (relative to their size and absolutely and some ethnic groups tend to have bigger brains than other ethnic groups do) but you probably don't assume that some psychologically normal human adults are more sentient than others. Also, we should expect smaller animals to have smaller brains because they are smaller animals, neurons and other cells are the same size in all species so of course bigger animals will have bigger brains with more neurons. Sperm whales have larger brains than humans. An ant has a brain that makes up 1/3rd of her body.</div></blockquote><br/><br/>Actually, there's some evidence that especially short lived species might have evolved not to feel pain because the benefit to feeling pain is in avoiding negative stimulus and staying alive longer.<br/><br/>Men may have more grey matter (neurons), but women actually have more white matter (connections) so it arguably all evens out.<br/><br/>Actually, sperm whales have bigger neurons and thus, fewer neurons than humans.  The same is true of elephants.<br/><br/><blockquote class="uncited"><div>To say that a ladybug's sense of hearing is more acute than our hearing means that they hear more efficiently than we do, this necessarily negates their being less sentient. It would be one thing for you to deny that they actually do have a more acute sense of hearing but how could they possibly experience less than we do despite having a more detailed or intense experience?</div></blockquote><br/><br/>I'm not even sure how you could measure the intensity of their experience, much less be certain that their hearing is more acute.  What I'm suggesting however, is that even if they have more sensitive sensory organs, they still have fewer neurons to process that sensory information with.<br/><br/><blockquote class="uncited"><div>Sleep deprivation is not fun. I've never been on psychiatric medication and I don't know what that would feel like but I have had these seemingly 'half-aware' moments in between dreaming and being awake.<br/><br/>I think it might be that the reason we tend to think of dreams as vague and 'less real' is because, not being as fully self aware as we are when we are awake, the experience doesn't imprint on our episodic memory as strongly so it's our memory of the experience that is vague and fuzzy but, when we actually dream, the experience itself was as concrete and real as our waking moments. Just because we can be affected in a way that makes us less lucid doesn't mean that other animals spend their entire lives in a less lucid state (and if lucid means self-awareness or higher cognition then I don't think it matters directly).</div></blockquote><br/><br/>I'm just offering an example to show that it's possible to feel less "conscious".<br/><br/><blockquote class="uncited"><div>I agree but this wouldn't be justified on the premise that one being deserves more consideration than the other, equal consideration would demand this. There would still be some scenarios in which we should prioritize the interests of a being who feels emotion less intensely (maybe because an excess amount of stimuli will cause them more pain than a much smaller amount will cause someone who feels pain more intensely or maybe if we have to choose between saving someone who feels happiness less intensely but will have a very long overall happy life and someone who feels happiness very intensely but will have a much shorter life).</div></blockquote><br/><br/>Fair enough.<br/><br/><blockquote class="uncited"><div>And we could never know but considering that they fail the mirror self-recognition test, we have no more reason to believe that they are sentient than we do the non-human animals who also fail the test. <br/>...<br/>I don't understand but I agree that we will never know. Maybe the mirror test is more useful for determining a capacity for pattern recognition rather than self-awareness or maybe infants and most non-human animals just don't care about their appearance. I still think it's probably the best evidence we have for the time being.</div></blockquote><br/><br/>Well, insects and most animals that aren't particularly intelligent birds or mammals fail the mirror test.  If I'm not mistaken, you've been arguing that even those animals are as sentient as humans no?<br/><br/>Sentience is not the same thing as self-awareness.  The mirror test explicitly tests for self-awareness, but in my view the only requirement for sentience is the ability to feel.<br/><br/><blockquote class="uncited"><div>This is an example of what I mean when I say that it doesn't seem to me that your position is really hedonistic. There may be practical, indirect reasons to prioritize the interests of beings who can form long-term preferences in at least some scenarios but why is the capacity relevant in itself? Even if there are beings who can feel emotion more intensely than others (which doesn't sound that far fetched to me, I just don't think it would be related to brain size or cognition), that doesn't justify a hierarchy between them. If we give a very sick person the last available medicine it shouldn't be because we care more about her, it should be because she would benefit from it more than anyone else would; if someone else would benefit more than we should give it to them instead. </div></blockquote><br/><br/>Like I said, I lean hedonistic, but I'm not certain that I am 100% satisfied with hedonism.  Though I agree with you about the medicine example.<br/><br/><blockquote class="uncited"><div>A quantitative difference in how intensely beings experience emotion doesn't justify a black and white absolute distinction or hierarchy in principle.</div></blockquote><br/><br/>No, but it may suggest we will end up effectively weighing beings differently in practice.<br/><br/><blockquote class="uncited"><div>Explicitly or implicitly? I'm pretty sure that all animals show evidence of implicit memory, of being affected by past experience unconsciously but that doesn't mean that they can consciously recall what happened to them in the past. I don't remember learning to read or write yet here I am.</div></blockquote><br/><br/><a class="postlink" href="http://news.psu.edu/story/141254/2009/02/23/research/probing-question-can-babies-learn-utero">http://news.psu.edu/story/141254/2009/0 ... earn-utero</a><br/><br/><a class="postlink" href="http://onlinelibrary.wiley.com/doi/10.1046/j.1469-0705.2002.00845.x/pdf">http://onlinelibrary.wiley.com/doi/10.1 ... 0845.x/pdf</a><br/><br/><blockquote class="uncited"><div>What could that mean? Everyone's basic experience of happiness (using 'happiness' as an umbrella term for all inherently likeable or positive emotional states) is the same (hence, calling it 'happiness' in the same way red, blue and green are all 'colors' rather than numbers). The idea of qualitatively higher or lower forms of happiness is incoherent (which doesn't deny that there are different kinds of happiness - love, excitement, humor etc. but -qualitatively- they are all equally pleasant). I completely agree that we can experience more or less emotion but the difference is quantitative, not qualitative.</div></blockquote><br/><br/>I figure it means that you "care" more or less about the feeling that you are experiencing.<br/><br/><blockquote class="uncited"><div>You said something along the lines of 'we should place more value on those beings who are more sentient'. My counter is that all beings deserve equal consideration and this justifies prioritizing the interests of some people in some scenarios only because they will benefit more or be harmed more by a decision than the 'less sentient' being would but this doesn't involve a fundamental hierarchy. All beings are still considered equals and at least some scenarios would justify favoring the interests of 'less sentient' beings over 'more sentient' beings (in addition to the other examples I gave earlier, we might be justified in prioritizing the collective interests of large groups of 'less sentient' beings over the interests of a single individual who is 'more sentient'.).</div></blockquote><br/><br/>Again, I'm not suggesting a fundamental hierarchy, so much as a practical weighting of importance.<br/><br/><blockquote class="uncited"><div>I view impartiality as right because you cannot be concerned with happiness per se if you only care about some happiness and not all happiness but because my world view begins with happiness-suffering, impartiality alone is not enough because impartiality doesn't necessarily involve a concern for happiness (or it could involve a concern for things I don't believe are inherently valuable). My moral world view doesn't begin with a principle of impartiality per se. If that makes sense. I think people should be impartial but being impartial is not enough, what constitutes interests or benefit isn't second to that, it precedes it.<br/><br/>I think I understand what you're trying to say but the starting point, for me, is happiness. I don't see any moral value in caring about anything other than happiness. Maybe that would sound pushy to some people, and I wouldn't want to come off that way, but it's a matter of priorities and I just don't care about anything else directly ( at the very least, my intuitions are perfectly welfare hedonist).</div></blockquote><br/><br/>Again, fair enough.<br/><br/><blockquote class="uncited"><div>I think those those studies are unfair. These psychopaths weren't explicit utilitarians who consciously analyzed every issue on the basis of what will produce the greatest good/least bad in the world. They simply had a utilitarian response to a specific moral question. Of course psychopaths are going to be less squeamish about killing others so can stomach the utilitarian position on the trolley problem more easily than most people could (under the pretense of doing it for the benefit of the people who would be saved) but they probably don't have a utilitarian position on gun control, economics, altruism etc. Even if utilitarianism really does correlate with psychopathy for whatever reasons, utilitarianism can't possibly be an inherently psychopathic view considering the amount of altruism it demands. There's a psychological difference between harming someone because you don't care and doing so only to prevent more suffering or maximize more happiness. What's interesting is that libertarians are supposedly more likely to give 'utilitarian' responses to the trolley problem when libertarians are supposed to live by the N.A.P. If I was ever in a situation where I had to push someone in from of a train to save more people or experiment on someone to produce a vaccine that would cure AIDS or cancer or some other disease, I would probably want to off myself immediately after. Causing a single person an unbearable, excruciating amount of pain felt at a continued moment in time (ie. not small amounts intermittently stretched out over a long period of time like a speck of dust in the eye every day for a year) is intuitively even more unacceptable to me than just painlessly killing them, a certain amount of suffering is just impossible to make sense of or deal with ; it just can't be 'all right'. You never adjust to it or get used to it, it consumes your entire existence and you have no identity beyond it ; it's just fundamentally unacceptable by it's very nature. If suffering could somehow be abolished then we wouldn't have to worry about possibly justified necessary evils like vivisection (which, by the way, I think should be performed on humans and not non-humans if it is a necessary evil and the drugs we're trying to create are for the benefit of humans), prison, war, pushing someone in front of a train etc.</div></blockquote><br/><br/>Interesting.  I could get into a debate about necessary evils here, but I think we're already debating a lot. <img alt=":P" src="../images/smilies/icon_razz.gif"/><br/><br/><blockquote class="uncited"><div>Connecting notions of fairness and justice (and truth, life and liberty) to the greatest happiness ideal seems to me a rejection of value monism.</div></blockquote><br/><br/>Perhaps it is.  I'm not sure I "value" value monism itself, so I'm not necessarily attached to it.  I go where my philosophical adventures lead me.<br/><br/><blockquote class="uncited"><div>If they're only useful in helping to achieve happiness then they aren't fundamental principles. In my view, happiness justifies itself.</div></blockquote><br/><br/>Well, I guess their secondary near-fundamental principles?  I'm uncertain on whether happiness really justifies itself.  Yes, the experience seems absolutely good, but I can still sort of ask, so what?  Why should I care how I feel?  And the only answer I can give is that it is consistent with notions like truth and fairness that I value what I value.  The truth says that it is correct to feel happy.  It is also fair to feel happy.  It is consistent with the meaning of life to feel happy.  It is consistent with love to value happiness not only of myself but of those I love.  And it is consistent with my liberty and autonomy as a sentient being that I should be able to feel happy.<br/><br/>In a way, all these notions are interconnected to form a nexus of morality, of what should be.  They work to justify each other.  Or at least, that's how it seems to me.  I'll admit that a simpler view that just has happiness as the one and only principle of everything is also appealing, and perhaps even more logical.  I just like the idea of incorporating all these positive notions together into one neat little package.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9165">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9168">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9168">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-03-04T17:56:00</p>
<div class="content"><div class="postrev" data-snap="2"><blockquote class="uncited"><div>Actually, there's some evidence that especially short lived species might have evolved not to feel pain because the benefit to feeling pain is in avoiding negative stimulus and staying alive longer.</div></blockquote><br/><br/>What evidence for this is there? As far as natural selection is concerned, animals only need to live long enough to propagate their genes but they still have to avoid negative stimuli for them to do so and they still have to pursue food and sex. I haven't heard of any group of animals who don't avoid danger or have a fight or flight system.<br/><br/><blockquote class="uncited"><div>Men may have more grey matter (neurons), but women actually have more white matter (connections) so it arguably all evens out.</div></blockquote><br/><br/>I remember reading that women have more left-right brain connectivity but male brains are still larger and so are the brains of some ethnic groups in comparison to others (statistically speaking, I'm sure). You're admitting that a smaller brain could have more neural connections than a larger brain.<br/><br/><blockquote class="uncited"><div>Actually, sperm whales have bigger neurons and thus, fewer neurons than humans. The same is true of elephants.</div></blockquote><br/><br/>If this is true the cells of all animals are still roughly equivalent (the difference in size can't be that drastic) so considering how large the brains of sperm whales are even their having bigger neurons couldn't justify assuming they are 'less sentient'.  <span style="font-weight: bold">Elephants have around 257 billion neurons, humans have around 100 billion neurons</span>. I've read consistently that bigger brains do not = greater intelligence and I think the same is true of sentience.<br/><br/><br/><blockquote class="uncited"><div>Brain sizes vary greatly among different creatures: A whale's brain weighs 20 pounds (with more than 200 billion nerve cells), a human brain varies between 2.8 and 3.2 pounds (with an estimated 85 billion nerve cells), and a honeybee's brain weighs only 0.000035 ounces (with fewer than a million nerve cells).<br/>However, biologists have suggested that insects, despite their small brain sizes, can be as intelligent as much larger animals.<br/>“We know that body size is the single best way to predict an animal's brain size,” said Lars Chittka, a professor at the University of London, in a review paper published in Current Biology. “However, contrary to popular belief, we can't say that brain size predicts their capacity for intelligent behavior. Animals with bigger brains are not necessarily more intelligent.”<br/>Past research has shown that insects are capable of clever behaviors that scientists previously thought were exclusive to larger animals. For example, honeybees can count, categorize similar objects, and differentiate between shapes that are symmetrical and asymmetrical.<br/>Results from computer modeling suggest that consciousness can be generated with very small neural circuits, which theoretically can fit into an insect’s brain. A creature can count with only a few hundred nerve cells and can generate consciousness with only a few thousand nerve cells, said Chittka.<br/>Research has suggested that bigger animals may need bigger brains only because the brains need to control more. For instance, they need bigger nerves to move bigger muscles. The size increase allows the brain to function in greater detail, with finer resolution, higher sensitivity, or greater precision.<br/>“In bigger brains we often don't find more complexity, just an endless repetition of the same neural circuits over and over. This might add detail to remembered images or sounds, but not add any degree of complexity. To use a computer analogy, bigger brains might in many cases be bigger hard drives, not necessarily better processors," said Chittka.</div></blockquote><br/><br/><a class="postlink" href="http://www.theepochtimes.com/n2/science/bigger-brain-does-not-mean-higher-intelligence-26091.html">http://www.theepochtimes.com/n2/science ... 26091.html</a><br/><br/>Some scientists believe that larger animals need bigger brains simply to control larger bodies. <br/><br/><blockquote class="uncited"><div>I'm not even sure how you could measure the intensity of their experience, much less be certain that their hearing is more acute. What I'm suggesting however, is that even if they have more sensitive sensory organs, they still have fewer neurons to process that sensory information with</div></blockquote><br/><br/>If you can admit that they process more sensory information then we can why are you assuming this information isn't processed subjectively? No one can claim to be certain about how acute a ladybug's sense of hearing is, it's a matter of evidence and not proof. I don't think there is any evidence linking how intensely an animal can feel pain or enjoy something and how many neurons they have beyond the baseline amount needed for subjective experience (assuming, for conversation sake, that emergence is true). We can both only argue from evidence.<br/><br/><blockquote class="uncited"><div>Well, insects and most animals that aren't particularly intelligent birds or mammals fail the mirror test. If I'm not mistaken, you've been arguing that even those animals are as sentient as humans no?</div></blockquote><br/><br/>Yes. Only a handful of animals pass the mirror self-recognition test. Some animals have actually failed when other members of their species have passed under different circumstances (gorillas view eye contact as confrontational, as one example of a reason why members of one species have failed when others have passed).<br/><br/><blockquote class="uncited"><div>Sentience is not the same thing as self-awareness. The mirror test explicitly tests for self-awareness, but in my view the only requirement for sentience is the ability to feel.</div></blockquote><br/><br/>I agree completely. I was only arguing that we don't assume babies are 'less sentient' despite lacking self-awareness and we have no reason at all - at this point - to think that infants under 1.5-2 years old have self-awareness.  Even a preference utilitarian can not make an overtly species based distinction between humans and non-human animals. At best, the distinction would have to be between psychologically normal human adults AND a handful of probably self-aware animals like the non-human great apes, dolphins, rats, magpies etc. in contrast with severely retarded humans, humans under the age of 1.5-2 and most non-human animals. The idea of viewing and treating newborn human infants the same way we do pigs and cows doesn't sit well with most people, even though adults cows, pigs and chickens are probably more cognitively developed.<br/><br/><blockquote class="uncited"><div>No, but it may suggest we will end up effectively weighing beings differently in practice.</div></blockquote><br/><br/>We're not weighing the beings differently, we're weighing their interests differently and then only because some interests are quantitatively greater than other interests.<br/><br/><blockquote class="uncited"><div>I figure it means that you "care" more or less about the feeling that you are experiencing.</div></blockquote><br/><br/>I don't think I understand (this or happiness/suffering being different at different levels of sentience - a capacity for happiness/suffering falls under sentience). I don't care whether or not cognitively less developed persons 'care' about their happiness in the sense of rationally judging it to be good or forming an abstract preference for it. I care whether or not it feels good for them. I'll 'care' about it for them.<br/><br/><blockquote class="uncited"><div>Again, I'm not suggesting a fundamental hierarchy, so much as a practical weighting of importance.</div></blockquote><br/><br/>OK but it's the interests that are being weighed as quantitatively more or less important, not the beings. The beings are equals.<br/><br/><blockquote class="uncited"><div>Perhaps it is. I'm not sure I "value" value monism itself, so I'm not necessarily attached to it. I go where my philosophical adventures lead me.</div></blockquote><br/><br/>You said that you lean toward hedonism (I understand you're not really settled on the issue) but I understand hedonism to be a monist position, happiness being regarded as the only intrinsic good and not just a good.<br/><br/><blockquote class="uncited"><div> Yes, the experience seems absolutely good, but I can still sort of ask, so what? Why should I care how I feel?</div></blockquote><br/><br/>I would argue that the answer lies in the experience, (everyone's) happiness is worth caring about, caring about it is warranted. I'm a moral realist, I believe that a universe with more happiness and less suffering is objectively better. My 'should' only means 'it would be better'. I wouldn't say we're doing something incorrect in causing pain, only that it's undesirable.<br/><br/><blockquote class="uncited"><div> And the only answer I can give is that it is consistent with notions like truth and fairness that I value what I value. </div></blockquote><br/><br/>I don't understand this at all.<br/><br/><blockquote class="uncited"><div>The truth says that it is correct to feel happy.</div></blockquote><br/><br/>I don't think it's 'correct', just desirable. Someone can argue that maximizing happiness or minimizing suffering is not inherently desirable but this contradicts direct experience and experience (or evidence which shows something to be probable if not definitive) is what we use to settle issues with contradicting propositions that are all logically coherent.<br/><br/><blockquote class="uncited"><div> It is also fair to feel happy.</div></blockquote><br/><br/>You believe that it is unfair to not experience happiness?<br/><br/><blockquote class="uncited"><div> It is consistent with the meaning of life to feel happy.</div></blockquote><br/><br/>I don't believe life has 'meaning' or purpose, personally. I've never understand what the 'meaning of life' was supposed to mean.<br/><br/><blockquote class="uncited"><div> It is consistent with love to value happiness not only of myself but of those I love.</div></blockquote><br/><br/>Depending on what you mean by 'love' I don't think we do justice to people by viewing them as objects of affection and not imagining - and identifying with - their subjective point of view (what they experience, not necessarily what they believe or think). I think many people genuinely love (feel affection for) people whose private emotional experience they care very little about. This is why I think a strong distinction should be made between compassion and emotional attachment. Although the psychology of love and compassion seem clearly related, I think it would be much better-morally - to completely despise and hate someone yet genuinely care about their emotional well-being than it would be to 'love' them and think very little about how they actually feel. The emotion of love itself is a form of happiness so for selfish reasons it's better to love everyone to the extent that you have any control over how you feel about other people.<br/><br/><blockquote class="uncited"><div> And it is consistent with my liberty and autonomy as a sentient being that I should be able to feel happy.</div></blockquote><br/><br/>I think that being able to feel happiness is only useful to the extent that you actually do feel happiness as a result. I don't think autonomy per se has any inherent value or that people have a natural right to it.<br/><br/>I'm not really trying to 'debunk' your position, just contrasting it with my own 2 cents.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9168">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9169">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9169">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-03-04T19:27:00</p>
<div class="content"><div class="postrev" data-snap="2"><blockquote class="uncited"><div>What evidence for this is there? As far as natural selection is concerned, animals only need to live long enough to propagate their genes but they still have to avoid negative stimuli for them to do so and they still have to pursue food and sex. I haven't heard of any group of animals who don't avoid danger or have a fight or flight system.</div></blockquote><br/><br/>This <a class="postlink" href="http://www.newscientist.com/article/mg22129570.600">New Scientist article</a> used to be available to everyone, but now seems to require a subscription which is rather annoying.<br/><br/>But the gist of the article was that certain crustaceans show behaviours that suggest they do feel pain, but much shorter lived insects do not show these behaviours, such as favouring injured limbs.<br/><br/>There's also this <a class="postlink" href="http://www.parl.gc.ca/Content/SEN/Committee/372/lega/witn/shelly-e.htm">Canadian Senate Committee Report</a> if you consider that at all authoritative.<br/><br/>It does make the point that even bacteria avoid negative stimuli, but most scientists don't think that bacteria actually feel pain.  Rather, the process that controls bacteria is more like a <a class="postlink" href="http://en.wikipedia.org/wiki/Braitenberg_vehicle">Braitenburg Vehicle</a>.<br/><br/>And there's <a class="postlink" href="http://ilarjournal.oxfordjournals.org/content/33/1-2/25.full">this as well.</a><br/><br/><blockquote class="uncited"><div>I remember reading that women have more left-right brain connectivity but male brains are still larger and so are the brains of some ethnic groups in comparison to others (statistically speaking, I'm sure). You're admitting that a smaller brain could have more neural connections than a larger brain.</div></blockquote><br/><br/>Yes, it's possible.  The true indicator of sentience is probably not number of neurons or number of connections, but the complexity of the overall network that is created.<br/><br/><blockquote class="uncited"><div>If this is true the cells of all animals are still roughly equivalent (the difference in size can't be that drastic) so considering how large the brains of sperm whales are even their having bigger neurons couldn't justify assuming they are 'less sentient'. Elephants have around 257 billion neurons, humans have around 100 billion neurons. I've read consistently that bigger brains do not = greater intelligence and I think the same is true of sentience.</div></blockquote><br/><br/>Interesting that there are different sources claiming different things about the number of neurons.  I went with <a class="postlink" href="http://en.wikipedia.org/wiki/List_of_animals_by_number_of_neurons#cite_note-HofmanFalk2012-26">Wikipedia's List of animals by number of neurons</a>.  But I've also found this <a class="postlink" href="http://blogs.scientificamerican.com/brainwaves/2014/02/26/searching-for-the-elephants-genius-inside-the-largest-brain-on-land/">Scientific American blog</a> which suggests you are correct.  Though it also notes that:<br/><br/><blockquote><div><cite>Scientific American Blog wrote:</cite>The vast majority of these neurons are found not in the cerebral cortex—the seat of abstract thinking in humans—but rather in the elephant’s cerebellum, which controls breathing, heart rate and movement, among other duties. The elephant cerebellum has 250 billion neurons; its cortex has 5.5 billion. Humans have about 70 billion neurons in the cerebellum and 16 billion in the cortex.</div></blockquote><br/><br/>Again, I think it's the overall complexity rather than sheer size that determines sentience.  The cortex is arguably a more complex structure than the cerebellum.<br/><br/><blockquote class="uncited"><div>http://www.theepochtimes.com/n2/science ... 26091.html<br/><br/>Some scientists believe that larger animals need bigger brains simply to control larger bodies. </div></blockquote><br/><br/>This is possible.  This is also why I have considered in another thread, that we should <a class="postlink" href="../thread/1146.html#p9096">measure sentience by the number of neurons per structure</a>, as a rough approximation.<br/><br/><blockquote class="uncited"><div>If you can admit that they process more sensory information then we can why are you assuming this information isn't processed subjectively? No one can claim to be certain about how acute a ladybug's sense of hearing is, it's a matter of evidence and not proof. I don't think there is any evidence linking how intensely an animal can feel pain or enjoy something and how many neurons they have beyond the baseline amount needed for subjective experience (assuming, for conversation sake, that emergence is true). We can both only argue from evidence.</div></blockquote><br/><br/>I already noted that the evidence is if you damage (reduce the number of neurons and connections in) the anterior cingulate cortex in humans, you reduce their response to pain, which to me is good evidence that intensity does depend on it.<br/><br/><blockquote class="uncited"><div>I agree completely. I was only arguing that we don't assume babies are 'less sentient' despite lacking self-awareness and we have no reason at all - at this point - to think that infants under 1.5-2 years old have self-awareness. Even a preference utilitarian can not make an overtly species based distinction between humans and non-human animals. At best, the distinction would have to be between psychologically normal human adults AND a handful of probably self-aware animals like the non-human great apes, dolphins, rats, magpies etc. in contrast with severely retarded humans, humans under the age of 1.5-2 and most non-human animals. The idea of viewing and treating newborn human infants the same way we do pigs and cows doesn't sit well with most people, even though adults cows, pigs and chickens are probably more cognitively developed.</div></blockquote><br/><br/>Well, there's an argument that we should factor in future potential happiness in decisions, and the fact of the matter is that the infant has the potential to develop that higher degree of sentience than the adult cow and pig.<br/><br/><blockquote class="uncited"><div>We're not weighing the beings differently, we're weighing their interests differently and then only because some interests are quantitatively greater than other interests.</div></blockquote><br/><br/>To some people, that would still seem like weighing the beings differently.<br/><br/><blockquote class="uncited"><div>I don't think I understand (this or happiness/suffering being different at different levels of sentience - a capacity for happiness/suffering falls under sentience). I don't care whether or not cognitively less developed persons 'care' about their happiness in the sense of rationally judging it to be good or forming an abstract preference for it. I care whether or not it feels good for them. I'll 'care' about it for them.</div></blockquote><br/><br/>No, I'm saying that they literally "emotionally feel" it less.  Caring and emotionally feeling in this instance are the same thing.  It's like the difference between trying to tickle yourself and having someone else tickle you.  It's effectively the exact same stimulus, but in one condition, you don't feel tickled because you know it's coming from yourself and the brain cancels it out, while in the other condition the surprise of the stimulus elicits the emotional response.<br/><br/><blockquote class="uncited"><div>OK but it's the interests that are being weighed as quantitatively more or less important, not the beings. The beings are equals.</div></blockquote><br/><br/>If you weigh the interests of a being as more or less important, then the beings are not effectively equals.<br/><br/><blockquote class="uncited"><div>You said that you lean toward hedonism (I understand you're not really settled on the issue) but I understand hedonism to be a monist position, happiness being regarded as the only intrinsic good and not just a good.</div></blockquote><br/><br/>True.<br/><br/><blockquote class="uncited"><div>I would argue that the answer lies in the experience, (everyone's) happiness is worth caring about, caring about it is warranted. I'm a moral realist, I believe that a universe with more happiness and less suffering is objectively better. My 'should' only means 'it would be better'. I wouldn't say we're doing something incorrect in causing pain, only that it's undesirable.  <br/>...<br/>I don't think it's 'correct', just desirable. Someone can argue that maximizing happiness or minimizing suffering is not inherently desirable but this contradicts direct experience and experience (or evidence which shows something to be probable if not definitive) is what we use to settle issues with contradicting propositions that are all logically coherent.<br/></div></blockquote><br/><br/>Why should desirability matter?<br/><br/><blockquote class="uncited"><div>You believe that it is unfair to not experience happiness?</div></blockquote><br/><br/>If other beings are experiencing happiness, it just seems unfair that some are happy while others are not.  In the ideal case I think all beings should be happy.<br/><br/><blockquote class="uncited"><div>I don't believe life has 'meaning' or purpose, personally. I've never understand what the 'meaning of life' was supposed to mean.</div></blockquote><br/><br/>The meaning of life is really whatever you as a free sapient agent decide it should be.  Whatever purpose you assign to your existence, that is the meaning of your individual life.  But more than that, the question of purpose is a "should" or "ought" question.  Morality concerns itself with what people "should" or "ought" to do, and so ultimately the best meaning of life you can assign yourself should be consistent with morality.  Thus, because my Utilitarian morality suggests that the best thing you can do is maximize happiness, then it makes sense to me to make this my purpose.<br/><br/><blockquote class="uncited"><div>Depending on what you mean by 'love' I don't think we do justice to people by viewing them as objects of affection and not imagining - and identifying with - their subjective point of view (what they experience, not necessarily what they believe or think). I think many people genuinely love (feel affection for) people whose private emotional experience they care very little about. This is why I think a strong distinction should be made between compassion and emotional attachment. Although the psychology of love and compassion seem clearly related, I think it would be much better-morally - to completely despise and hate someone yet genuinely care about their emotional well-being than it would be to 'love' them and think very little about how they actually feel. The emotion of love itself is a form of happiness so for selfish reasons it's better to love everyone to the extent that you have any control over how you feel about other people.</div></blockquote><br/><br/>My conception of love is similar to the Greek word <a class="postlink" href="http://en.wikipedia.org/wiki/Agape">Agape</a>.  It's not about having mere affection for someone, but of truly wanting what's best for them, wanting to maximize their happiness.<br/><br/><blockquote class="uncited"><div>I think that being able to feel happiness is only useful to the extent that you actually do feel happiness as a result. I don't think autonomy per se has any inherent value or that people have a natural right to it.</div></blockquote><br/><br/>I don't either, but even if I don't value it intrinsically, the truth is we are autonomous, and that this makes us responsible to an extent for the consequences of our actions.  And so we have a sort of responsibility to choose happiness over suffering, if that makes any sense at all.<br/><br/><blockquote class="uncited"><div>I'm not really trying to 'debunk' your position, just contrasting it with my own 2 cents.</div></blockquote><br/><br/>That's fine.  I don't mind seeing the contrast myself.  It helps to flesh out the position.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9169">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9172">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9172">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-03-05T18:09:00</p>
<div class="content"><div class="postrev" data-snap="2"><blockquote class="uncited"><div>The true indicator of sentience is probably not number of neurons or number of connections, but the complexity of the overall network that is created.</div></blockquote><br/><br/><blockquote class="uncited"><div>Again, I think it's the overall complexity rather than sheer size that determines sentience. </div></blockquote><br/><br/>As the article I posted claims, bigger brains do not necessarily imply greater neural complexity. And a being may only require a baseline of a few thousand neurons to generate consciousness (again, assuming for conversation sake that emergence is true - I don't think that it is).<br/><br/><blockquote class="uncited"><div>The cortex is arguably a more complex structure than the cerebellum.</div></blockquote><br/><br/>I'm not an expert on neuroscience but I think the reptilian brain and the limbic system play a greater role in emotional experience than the cerebral cortex does. No one is denying that psychologically normal human adults are cognitively more developed than other animals.<br/><br/><blockquote class="uncited"><div>I already noted that the evidence is if you damage (reduce the number of neurons and connections in) the anterior cingulate cortex in humans, you reduce their response to pain, which to me is good evidence that intensity does depend on it.</div></blockquote><br/><br/>I think 'damaging' a region of the brain involves more than just reducing the number of neurons and neural connections in it if it's still left functioning.<br/><br/><blockquote class="uncited"><div>Well, there's an argument that we should factor in future potential happiness in decisions, and the fact of the matter is that the infant has the potential to develop that higher degree of sentience than the adult cow and pig.</div></blockquote><br/><br/>Self-awareness, yes. Sentience, no. It's far from demonstrated that we have any reason to believe that adult cows and pigs are less capable of feeling pain anymore than we do that they hear, smell, taste, feel (tactile sensation) or see less than humans do. Even if their senses are weaker, a being can either see or they cannot see. Someone with 20/20 vision might see better than someone with poor eye sight but they don't see "more", their vision is just more detailed and efficient. A capacity to see is 'yes' or 'no'. <br/><br/>You might as well argue that sperm cells and zygotes should be prioritized over adult cows and pigs (if pan-psychism is true then I do think that sperm cells are sentient although I don't know how much we can do to better their lives). I do agree that the future happiness of potential beings should be given equal consideration with the future or near immediate happiness of existing beings but 'our' intuitions are not that infants deserve more consideration because of what they can become but because of what they are.<br/><br/><blockquote class="uncited"><div>To some people, that would still seem like weighing the beings differently.</div></blockquote><br/><br/>It isn't. There's a huge difference between giving the interests of one person less consideration because of who they are or what group they belong to and prioritizing someone else's interests only because those interests are greater.<br/><br/><blockquote class="uncited"><div>No, I'm saying that they literally "emotionally feel" it less. Caring and emotionally feeling in this instance are the same thing. It's like the difference between trying to tickle yourself and having someone else tickle you. It's effectively the exact same stimulus, but in one condition, you don't feel tickled because you know it's coming from yourself and the brain cancels it out, while in the other condition the surprise of the stimulus elicits the emotional response.</div></blockquote><br/><br/>In that case, I think your position is just unsupported by evidence.<br/><br/>Other animals desperately try to avoid danger just as much as we do, they nurture their offspring and form social bonds and groups, they play, they express pain and other emotional states etc. ; we shouldn't expect this if they felt emotion less intensely.<br/><br/><blockquote class="uncited"><div>If you weigh the interests of a being as more or less important, then the beings are not effectively equals.</div></blockquote><br/><br/>The question is <span style="font-weight: bold">why</span> their interests are being given less weight. First of all, utilitarians cannot give less <span style="font-style: italic">consideration</span> to the interests of some beings, they can can only prioritize greater interests over lesser interests.  The beings are equals because their interests are being given the same consideration. A 'racist' would not save the life of a racial in-group member over a racial out-group member because they - or their loved ones- would benefit more than the racial out-group member (or their loved ones) would from their being saved, a racist prioritizes the interests of his or her own race because they are members of his or her own race.<br/><br/>Your argument seems to be that a being with a greater capacity for happiness or suffering should be given greater consideration. This is completely inconsistent with the egalitarianism that utilitarianism necessarily implies. If John feels pain very intensely and Mark feels pain mildly and decision A will cause John to feel 20 points of pain whereas decision B will cause Mark to experience 15 points of pain, we prioritize John's pain over Marks pain not because John's pain is more bad but because <span style="font-weight: bold">there's more of it</span>. We're not giving John's interests greater consideration because John experiences pain more intensely, we're prioritizing John's pain because it`s quantitatively greater. Causing John 20 points of pain at once (we`ll ignore how the memory of the experience might affect him or any other indirect relationship it might have to his future mental states) would be better than causing Mark 5 points of pain every day for a year. Saying that John and Mark are equals is to say that their suffering (or at least the same amount of it) is equally bad.<br/><br/>I`m not that skeptical that some beings experience emotion more intensely than others (it`s seems that some people have a stronger disposition toward cheerfulness, positive emotions and a sensitivity to pleasure than others and others have a stronger disposition toward negative emotions), I only reject the claim that this is related to either cognition or brain size. On the philosophical side, never mind neuroscience, pleasure differs quantitatively, not qualitatively. The difference between someone who experiences pleasure intensely and someone who experiences it mildly is a difference in DEGREE, not KIND. A capacity for happiness is not intrinsically good, happiness is intrinsically good. If you believe that different species differ in terms of how intensely they experience emotion then you have to accept that this is true among humans as well because Darwin was clear in arguing that the differences between humans and other animals are differences in degree, not kind. Even if it were true that animals with smaller brains, or even brain regions associated with emotion, felt emotion less intensely, this still wouldn't justify the 'humans have the biggest dicks' chauvinism that you seem to be advocating (I can assure you, our dicks pale in comparison to the mighty sperm whale's).<br/><br/><blockquote class="uncited"><div>Why should desirability matter?</div></blockquote><br/><br/>The question is.. 'funny' to me. The concept of anything 'mattering' has no meaning without desirability.<br/><br/>If someone doesn't care about happiness - their own or anyone else's- then that's that but (I would argue), they are mistaken about what is valuable. Their disregard for happiness and suffering is criticizable.<br/><br/><blockquote class="uncited"><div>If other beings are experiencing happiness, it just seems unfair that some are happy while others are not. In the ideal case I think all beings should be happy.</div></blockquote><br/><br/>This is the concept of fairness that I have an issue with. The objective of (hedonistic) utilitarianism is to maximize happiness/minimize suffering, not equalize it. It's bad enough that some people suffer to the extent that they do but everyone suffering as much would be even worse. I agree with your last sentence but I'd rather be miserable in a world of happy people than miserable in a world of miserable people.<br/><br/><blockquote class="uncited"><div>The meaning of life is really whatever you as a free sapient agent decide it should be. Whatever purpose you assign to your existence, that is the meaning of your individual life. But more than that, the question of purpose is a "should" or "ought" question. Morality concerns itself with what people "should" or "ought" to do, and so ultimately the best meaning of life you can assign yourself should be consistent with morality. Thus, because my Utilitarian morality suggests that the best thing you can do is maximize happiness, then it makes sense to me to make this my purpose.</div></blockquote><br/><br/>-morality concerns itself with what people should do<br/>-because of this, the best purpose you can choose for life should be consistent with the question of what people should do<br/>-it follows from this that, because utilitarianism advocates maximizing happiness, it makes sense to make that your purpose<br/><br/>I don't understand.<br/><br/>I do agree that we make our own 'purpose' although some purposes are better than others.<br/><br/><blockquote class="uncited"><div> It's not about having mere affection for someone, but of truly wanting what's best for them, wanting to maximize their happiness.</div></blockquote><br/><br/>I respect that (even though I don't think the affection people have for other people is 'mere', just not 'moral'), I just think people should distinguish between the two because there is a definite difference.<br/><br/><blockquote class="uncited"><div>And so we have a sort of responsibility to choose happiness over suffering</div></blockquote><br/><br/>Do you mean that we have a responsibility to experience happiness over pain or to try to maximize happiness generally?</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9172">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9173">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9173">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-03-06T17:42:00</p>
<div class="content"><div class="postrev" data-snap="2"><blockquote class="uncited"><div>I'm not an expert on neuroscience but I think the reptilian brain and the limbic system play a greater role in emotional experience than the cerebral cortex does. No one is denying that psychologically normal human adults are cognitively more developed than other animals.</div></blockquote><br/><br/>My Cognitive Science courses suggested to me that emotional experience is affected by many different regions of the brain, including the reptilian brain, limbic system, and cerebral cortex.  The former parts influence the feeling itself, but the cerebral cortex influences the content of those feelings.  After all, it takes a concept of a mother to really have feelings for one's mother.  Similarly, suffering is often cognitively influenced, we can suffer from rejection, from failure, from fear of the future, and from other "thoughts" that come from the cortex.  The emotional process of pain is complex and multi-faceted, and I don't think it's just a matter of nociceptors relying physical signals to one region of the brain.  There is one region of the brain that does have special influence, the anterior cingulate cortex, and it may well be a bottleneck, but the overall experience of pain is mediated by many things, including our cognition.<br/><br/>This is why things like Cognitive Behavioural Therapy are effective at helping people with their emotions.  Even though the targets of the therapy are our cognitions, the way in which are cognitions influence our emotions means that changing our beliefs and our cognitive responses, actually has an effect on how we feel about things.  There's also some evidence from studies of cultural beliefs, that what you think can affect whether or not you feel pain at certain things like religious ceremonies that involve self-flagellation, and similar things.<br/><br/><blockquote class="uncited"><div>I think 'damaging' a region of the brain involves more than just reducing the number of neurons and neural connections in it if it's still left functioning.</div></blockquote><br/><br/>I'm not sure how 'damaging' a region of the brain would do anything else.  The neurons and the connections are the brain.  Everything else is support structure.<br/><br/><blockquote class="uncited"><div>Self-awareness, yes. Sentience, no. It's far from demonstrated that we have any reason to believe that adult cows and pigs are less capable of feeling pain anymore than we do that they hear, smell, taste, feel (tactile sensation) or see less than humans do. Even if their senses are weaker, a being can either see or they cannot see. Someone with 20/20 vision might see better than someone with poor eye sight but they don't see "more", their vision is just more detailed and efficient. A capacity to see is 'yes' or 'no'. <br/><br/>You might as well argue that sperm cells and zygotes should be prioritized over adult cows and pigs (if pan-psychism is true then I do think that sperm cells are sentient although I don't know how much we can do to better their lives). I do agree that the future happiness of potential beings should be given equal consideration with the future or near immediate happiness of existing beings but 'our' intuitions are not that infants deserve more consideration because of what they can become but because of what they are.</div></blockquote><br/><br/>It's simplistic to say that something is yes or no.  There are people who suffer from partial blindness.  Where do they fit in your binary division?  It's more accurate to say that things exist on a spectrum from "perfect vision" to "total blindness".  So I have to disagree with you on this one.<br/><br/>Again, I take the view that the infant lies on a continuum of sentience, from non-sentient at conception, to highly sentient as an adult.  The probability that the infant, left to itself will develop higher sentience is how I weigh it in terms of value.  Most sperm cells are not going to develop into humans, so their probability is minuscule.<br/><br/><blockquote class="uncited"><div>In that case, I think your position is just unsupported by evidence.<br/><br/>Other animals desperately try to avoid danger just as much as we do, they nurture their offspring and form social bonds and groups, they play, they express pain and other emotional states etc. ; we shouldn't expect this if they felt emotion less intensely.</div></blockquote><br/><br/>Bacteria also try to avoid noxious stimulus.  Sentience is not a requirement for that kind of behaviour in an agent.  I can program a non-sentient robot to behave the exact same way.  Just because they might feel the emotion less intensely, does not mean that they won't feel and act in similar ways.  I think there are thresholds of sentience that once reached allow these behaviours, but that we can go beyond these thresholds in terms of actual experience intensity.  And we know that in some circumstances, like insects, they don't express pain in the way that we do.<br/><br/><blockquote class="uncited"><div>The question is why their interests are being given less weight. First of all, utilitarians cannot give less consideration to the interests of some beings, they can can only prioritize greater interests over lesser interests. The beings are equals because their interests are being given the same consideration. A 'racist' would not save the life of a racial in-group member over a racial out-group member because they - or their loved ones- would benefit more than the racial out-group member (or their loved ones) would from their being saved, a racist prioritizes the interests of his or her own race because they are members of his or her own race.<br/><br/>Your argument seems to be that a being with a greater capacity for happiness or suffering should be given greater consideration. This is completely inconsistent with the egalitarianism that utilitarianism necessarily implies. If John feels pain very intensely and Mark feels pain mildly and decision A will cause John to feel 20 points of pain whereas decision B will cause Mark to experience 15 points of pain, we prioritize John's pain over Marks pain not because John's pain is more bad but because there's more of it. We're not giving John's interests greater consideration because John experiences pain more intensely, we're prioritizing John's pain because it`s quantitatively greater. Causing John 20 points of pain at once (we`ll ignore how the memory of the experience might affect him or any other indirect relationship it might have to his future mental states) would be better than causing Mark 5 points of pain every day for a year. Saying that John and Mark are equals is to say that their suffering (or at least the same amount of it) is equally bad.<br/><br/>I`m not that skeptical that some beings experience emotion more intensely than others (it`s seems that some people have a stronger disposition toward cheerfulness, positive emotions and a sensitivity to pleasure than others and others have a stronger disposition toward negative emotions), I only reject the claim that this is related to either cognition or brain size. On the philosophical side, never mind neuroscience, pleasure differs quantitatively, not qualitatively. The difference between someone who experiences pleasure intensely and someone who experiences it mildly is a difference in DEGREE, not KIND. A capacity for happiness is not intrinsically good, happiness is intrinsically good. If you believe that different species differ in terms of how intensely they experience emotion then you have to accept that this is true among humans as well because Darwin was clear in arguing that the differences between humans and other animals are differences in degree, not kind. Even if it were true that animals with smaller brains, or even brain regions associated with emotion, felt emotion less intensely, this still wouldn't justify the 'humans have the biggest dicks' chauvinism that you seem to be advocating (I can assure you, our dicks pale in comparison to the mighty sperm whale's).</div></blockquote><br/><br/>I'm not sure what big dicks have to do with anything, and I'd appreciate it if you kept this debate as clean as possible.<br/><br/>I'm not advocating chauvinism here.  I'm just pointing out that in practice, we will end up preferring human concerns because they feel more than less advanced species.  The justification is not that humans are somehow better than the animals.  Rather it is exactly as you said, that the differences are in degree.<br/><br/><blockquote class="uncited"><div>The question is.. 'funny' to me. The concept of anything 'mattering' has no meaning without desirability.<br/><br/>If someone doesn't care about happiness - their own or anyone else's- then that's that but (I would argue), they are mistaken about what is valuable. Their disregard for happiness and suffering is criticizable.</div></blockquote><br/><br/>I tend to think that happiness and suffering matter regardless of how "desirable" it seems to the being.  But then, I associate the word "desire" with the notion of choice, that we are free to desire things and not desire things.  But the truth is, we don't have a choice to value or disvalue our positive and negative emotional experiences.  They are absolutely valuable to us by the nature of how we are hard-wired.<br/><br/><blockquote class="uncited"><div>This is the concept of fairness that I have an issue with. The objective of (hedonistic) utilitarianism is to maximize happiness/minimize suffering, not equalize it. It's bad enough that some people suffer to the extent that they do but everyone suffering as much would be even worse. I agree with your last sentence but I'd rather be miserable in a world of happy people than miserable in a world of miserable people.</div></blockquote><br/><br/>I don't disagree about your last point.  This is why I assume that it is most fair that everyone should be as happy as they can be, that is, that maximizing their and everyone's happiness -would- be the most fair thing to do.<br/><br/><blockquote class="uncited"><div>-morality concerns itself with what people should do<br/>-because of this, the best purpose you can choose for life should be consistent with the question of what people should do<br/>-it follows from this that, because utilitarianism advocates maximizing happiness, it makes sense to make that your purpose<br/><br/>I don't understand.<br/><br/>I do agree that we make our own 'purpose' although some purposes are better than others.</div></blockquote><br/><br/>It's just how I interpret the notion of the meaning of life, you're free to come up with your own.<br/><br/><blockquote class="uncited"><div>I respect that (even though I don't think the affection people have for other people is 'mere', just not 'moral'), I just think people should distinguish between the two because there is a definite difference.</div></blockquote><br/><br/>Perhaps I should have said "true love" or "Agape love" instead to clarify.<br/><br/><blockquote class="uncited"><div>Do you mean that we have a responsibility to experience happiness over pain or to try to maximize happiness generally?</div></blockquote><br/><br/>Both?</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9173">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9175">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9175">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/286.html">Ubuntu</a></strong> on 2014-03-06T19:29:00</p>
<div class="content"><div class="postrev" data-snap="2">I've never denied that cognition affects emotional states. Both cognitive and sensory stimuli affect how we feel. In some scenarios, a cognitively more developed animal will suffer more than a cognitively less developed animal will. In other scenarios, I would expect a cognitively less developed animal to suffer more than a cognitively more developed animal would (maybe because they lack an effective coping mechanism as one example).<br/><br/><blockquote class="uncited"><div> After all, it takes a concept of a mother to really have feelings for one's mother</div></blockquote><br/><br/>No, it doesn't. Infants and non-human animals (or at least mammals and birds) are conditioned to have affection for their caregivers, even if they don't think about them when they're out of sight or can't form an abstract concept of a 'mother'. The human mother-child bond didn't spring up out of thin air, it's origin lies in the shared ancestry we share with other mammals.<br/><br/>I think that 'damaging' a region of the brain is more than just reducing the number of neurons or neural connections but affecting that brain region's ability to function. I think the emphasis you place on quantity is baseless (not just quantity of neurons but of neural connections). More neural connections may correspond with greater emotional intensity but I don't think you've shown this to be likely.<br/><br/><blockquote class="uncited"><div>It's simplistic to say that something is yes or no. </div></blockquote><br/><br/>Some things are simple. This is one of them.<br/><br/><blockquote class="uncited"><div> There are people who suffer from partial blindness. Where do they fit in your binary division? It's more accurate to say that things exist on a spectrum from "perfect vision" to "total blindness". So I have to disagree with you on this one.</div></blockquote><br/><br/>What counts as legal blindness is determined by how well one can see. For example, if I close my eyes I can still see blackness even though, for all intents and purposes, I am 'blind'.<br/><br/><blockquote class="uncited"><div>Again, I take the view that the infant lies on a continuum of sentience, from non-sentient at conception, to highly sentient as an adult. The probability that the infant, left to itself will develop higher sentience is how I weigh it in terms of value. Most sperm cells are not going to develop into humans, so their probability is minuscule.</div></blockquote><br/><br/>The probability of becoming something valuable has nothing to do with one's actual value.<br/><br/><br/><blockquote class="uncited"><div>Bacteria also try to avoid noxious stimulus. Sentience is not a requirement for that kind of behaviour in an agent. I can program a non-sentient robot to behave the exact same way. Just because they might feel the emotion less intensely, does not mean that they won't feel and act in similar ways.</div></blockquote><br/><br/>I agree. Even behavior that suggests sentience doesn't prove it but it's evidence.<br/><br/><br/><br/><blockquote class="uncited"><div> And we know that in some circumstances, like insects, they don't express pain in the way that we do.</div></blockquote><br/><br/>And we know that they do express fear, pain and desire in many circumstances. Fruit flies who aren't allowed to mate are more likely to sip alcohol. Grasshoppers are more hesitant to engage in fighting if they have a history of losing. Cockroaches have been conditioned to perform certain actions that will lead to being given a sugar treat and avoid those actions that lead to harmful injury.<br/><br/><blockquote class="uncited"><div>I'm not advocating chauvinism here.</div></blockquote><br/><br/>I was kidding (my apologies) but your position is completely chauvinistic and it's inconsistent with the egalitarianism that's intrinsic to utilitarianism. And your actual claims are not supported by evidence, they stem (I suspect) from a speciesist bias in favor of beings who remind you of yourself.<br/><br/><blockquote class="uncited"><div> I'm just pointing out that in practice, we will end up preferring human concerns because they feel more than less advanced species.</div></blockquote><br/><br/>You haven't supported this. First you claimed that more sentient beings have bigger brains (<blockquote class="uncited"><div>Actually, sperm whales have bigger neurons and thus, fewer neurons than humans. The same is true of elephants</div></blockquote>, <blockquote class="uncited"><div>Elephants have around 257 billion neurons, humans have around 100 billion neurons</div></blockquote>). Elephants, sperm whales and I'm sure many other animals have bigger brains than humans do. I countered this. You argued that humans have a more developed cerebral cortex, besides big not = neural complexity the cerebral cortex has less to do with emotional experience than other regions of the brain like the limbic system and the reptilian brain and in different animals different regions of the brain can handle the same functions. You ignored the fact that men tend to have bigger brains (both absolutely and relative to their general body size) and even if you counter that women have more neural connections you're only making my point. Research has actually shown men and women using different regions of the brain for the same task (sounding out different words), <span style="font-weight: bold">the men relied on a smaller region of the left brain with<span style="font-style: italic"> fewer neural connections</span> whereas women tended to use areas of the brain located in both hemispheres and yet <span style="font-style: italic">both men and women sounded out these words equally well</span></span> ( <a class="postlink" href="http://science.howstuffworks.com/life/men-women-different-brains1.htm">http://science.howstuffworks.com/life/m ... rains1.htm</a> ). You also ignored the fact that brain size differs among ethnic groups as well. East Asians have larger brains than Caucasians who in turn have larger brains than Blacks (these differences are 50-80% genetic, if I'm not mistaken). It's not inconceivable that humans tend to experience emotion more intensely than other animals but you haven't shown this to be probable in any way, you're just asserting it on some unsupported claim of 'neural complexity' that you haven't demonstrated. How would you even test for this besides behavior or self-reporting?  Again = you must realize that whether it's related to cognition and neural complexity or not, <span style="font-weight: bold">if emotional intensity varies between species then it also varies within species... </span> Autistic people, for example, have more neural connections than most people - are they more sentient? <br/><br/><br/><a class="postlink" href="http://news.softpedia.com/news/The-Autistic-Brain-Features-More-Neural-Connections-401275.shtml">http://news.softpedia.com/news/The-Auti ... 1275.shtml</a><br/><br/><br/><blockquote class="uncited"><div>I don't disagree about your last point. This is why I assume that it is most fair that everyone should be as happy as they can be, that is, that maximizing their and everyone's happiness -would- be the most fair thing to do.</div></blockquote><br/><br/>But there's a difference between maximizing happiness because happiness has value and maximizing happiness so that no one experiences less happiness than anyone else. The inequality of happiness isn't a bad thing, in my view. <br/><br/><blockquote class="uncited"><div>Both?</div></blockquote><br/><br/>A person has a limited control over their emotional state, don't you think? Not no control, but a limited control.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile9175">
<dt>
<a href="../user/286.html"></a><br/>
<a href="../user/286.html">Ubuntu</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 162</dd>
<dd><strong>Joined:</strong> Tue Sep 07, 2010 1:30 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p9316">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p9316">Re: How Do You Argue With Libertarians and Anarcho-Capitalists</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/1190.html">Darklight</a></strong> on 2014-05-01T22:41:00</p>
<div class="content"><div class="postrev" data-snap="2">My apologies for taking so very long to reply, I had to drop some things to focus on finishing up my Masters Thesis, and various related things.<br/><br/><blockquote class="uncited"><div>No, it doesn't. Infants and non-human animals (or at least mammals and birds) are conditioned to have affection for their caregivers, even if they don't think about them when they're out of sight or can't form an abstract concept of a 'mother'. The human mother-child bond didn't spring up out of thin air, it's origin lies in the shared ancestry we share with other mammals.</div></blockquote><br/><br/>I would still argue that the infant and imprinting animal have a very basic level concept of the "caregiver" entity.  Given that perhaps this concept is formed from genetics rather than learned.<br/><br/><blockquote class="uncited"><div>I think that 'damaging' a region of the brain is more than just reducing the number of neurons or neural connections but affecting that brain region's ability to function. I think the emphasis you place on quantity is baseless (not just quantity of neurons but of neural connections). More neural connections may correspond with greater emotional intensity but I don't think you've shown this to be likely.</div></blockquote><br/><br/>How else do you reduce a brain region's ability to function than by destroying neurons or connections?  More neural connections mean more possible associations and more volume of signal transmission, which I would think to be correlated with our subjective experience of intensity.  A single pinprick is less intensely painful than a cut off limb at least in part because of the sheer volume of Nociceptive signals.<br/><br/><blockquote class="uncited"><div>Some things are simple. This is one of them.</div></blockquote><br/><br/>Debatable.<br/><br/><blockquote class="uncited"><div>The probability of becoming something valuable has nothing to do with one's actual value.</div></blockquote><br/><br/>But in this instance, we cannot know the actual value of a life that hasn't been lived yet.  As probability is the degree of our belief that a particular state could be true, it is often used as a substitute for the actual value, when making decisions about something.<br/><br/><blockquote class="uncited"><div>I was kidding (my apologies) but your position is completely chauvinistic and it's inconsistent with the egalitarianism that's intrinsic to utilitarianism. And your actual claims are not supported by evidence, they stem (I suspect) from a speciesist bias in favor of beings who remind you of yourself.</div></blockquote><br/><br/>On the contrary, my claims are consistent with the evidence that more neurologically complex brains show more elaborate emotional behaviours.<br/><br/><blockquote class="uncited"><div>). Elephants, sperm whales and I'm sure many other animals have bigger brains than humans do. I countered this. You argued that humans have a more developed cerebral cortex, besides big not = neural complexity the cerebral cortex has less to do with emotional experience than other regions of the brain like the limbic system and the reptilian brain and in different animals different regions of the brain can handle the same functions. You ignored the fact that men tend to have bigger brains (both absolutely and relative to their general body size) and even if you counter that women have more neural connections you're only making my point. Research has actually shown men and women using different regions of the brain for the same task (sounding out different words), the men relied on a smaller region of the left brain with fewer neural connections whereas women tended to use areas of the brain located in both hemispheres and yet both men and women sounded out these words equally well ( <a class="postlink" href="http://science.howstuffworks.com/life/m">http://science.howstuffworks.com/life/m</a> ... rains1.htm ). You also ignored the fact that brain size differs among ethnic groups as well. East Asians have larger brains than Caucasians who in turn have larger brains than Blacks (these differences are 50-80% genetic, if I'm not mistaken). It's not inconceivable that humans tend to experience emotion more intensely than other animals but you haven't shown this to be probable in any way, you're just asserting it on some unsupported claim of 'neural complexity' that you haven't demonstrated. How would you even test for this besides behavior or self-reporting? Again = you must realize that whether it's related to cognition and neural complexity or not, if emotional intensity varies between species then it also varies within species... Autistic people, for example, have more neural connections than most people - are they more sentient? <br/><br/><br/><a class="postlink" href="http://news.softpedia.com/news/The-Auti">http://news.softpedia.com/news/The-Auti</a> ... 1275.shtml</div></blockquote><br/><br/>You're assuming that I still mean that brain size is the number of neurons, when I already argued that number of neurons is at best an approximation, and that overall neural complexity, which is likely a function of number of neurons and number of connections, is likely to more accurately describe differences in sentience.  If you really want a way to estimate neural complexity, may I suggest <a class="postlink" href="http://en.wikipedia.org/wiki/Integrated_information_theory">Integrated Information Theory</a>.<br/><br/>It's possible that emotional intensity varies within species, but it's not likely to vary as much as between species.  And it is quite possible that Autistic people could be more sentient by a small degree.<br/><br/><blockquote class="uncited"><div>But there's a difference between maximizing happiness because happiness has value and maximizing happiness so that no one experiences less happiness than anyone else. The inequality of happiness isn't a bad thing, in my view. </div></blockquote><br/><br/>This is something I'm a bit iffy about, because it means that if for some reason the Law of Diminishing Marginal Utility didn't hold, then it would be equally good for all the happiness in the universe to be concentrated on one being, as it would be for the happiness to be spread out equally between all beings (assuming a constant amount of happiness).  I feel like the completely unfair first arrangement however is somehow less moral than the second arrangement, mostly on the basis that morality is concerned with all sentient beings, and giving all the happiness to one being just seems to go against the spirit of morality.<br/><br/><blockquote class="uncited"><div>A person has a limited control over their emotional state, don't you think? Not no control, but a limited control.</div></blockquote><br/><br/>Yes, but that we have any control at all over our emotional state, even indirectly in the sense that we can effect the external state of the world that in turn determines our emotional state, means that we have at least some degree of responsibility.</div><div class="diff hidden"></div></div>
<div class="signature">"The most important human endeavor is the striving for morality in our actions. Our inner balance and even our existence depend on it. Only morality in our actions can give beauty and dignity to life." - Albert Einstein</div>
</div>
<dl class="postprofile" id="profile9316">
<dt>
<a href="../user/1190.html"><img alt="User avatar" height="100" src="../file/1190_1360790240.jpg" width="100"/></a><br/>
<a href="../user/1190.html">Darklight</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 117</dd>
<dd><strong>Joined:</strong> Wed Feb 13, 2013 9:13 pm</dd>
<dd><strong>Location:</strong> Canada</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<input type="hidden" value="20140303075915/viewtopic.php?f=10&amp;p=9072"/><input type="hidden" value="20150321045408/viewtopic.php?f=10&amp;t=1136&amp;sid=31ed43bf0f028ca9e2746a13e975c060"/><input type="hidden" value="20150321050623/viewtopic.php?f=10&amp;t=1136&amp;p=9316&amp;sid=31ed43bf0f028ca9e2746a13e975c060"/>
                        <hr>
                        <div class="topic-actions">
                            <div class="pagination">
                                49 posts
                            </div>
                        </div>
                        <p><a href="./viewforum.php?f=10" class="left-box left" accesskey="r">Return to General discussion</a></p>
                    </div>
                    <div id="page-footer">
                    </div>
                </div>
                <div>
                    <a id="bottom" name="bottom" accesskey="z"></a>
                </div>
            </div>
            <div class="positioncorrection-bottom"></div>
        </div>
        <div class="bottom-left"></div>
        <div class="bottom-middle"></div>
        <div class="bottom-right"></div>
    </body>
</html>
