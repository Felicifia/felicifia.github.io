<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Felicifia: global utilitarian discussion &bull; View topic - Cost-effectiveness of charities including existential risks</title>
        <script type="text/javascript" src="../styles/nexus/template/styleswitcher.js"></script>
        <script type="text/javascript" src="../styles/nexus/template/forum_fn.js"></script>
        <script type="text/javascript" src="../styles/custom.js"></script>
        <link href="../styles/nexus/theme/print.css" rel="stylesheet" type="text/css" media="print" title="printonly"/>
        <link href="../styles/prosilver.css" rel="stylesheet" type="text/css" media="screen, projection"/>
        <link href="../styles/nexus/theme/normal.css" rel="stylesheet" type="text/css" title="A"/>
        <link href="../styles/nexus/theme/medium.css" rel="alternate stylesheet" type="text/css" title="A+"/>
        <link href="../styles/nexus/theme/large.css" rel="alternate stylesheet" type="text/css" title="A++"/>
        <link href="../styles/custom.css" rel="stylesheet" type="text/css"/>
        <script type="text/javascript"><!--
            var spoiler_show = "[Reveal]";
            var spoiler_hide = "[Obscure]";
            //-->
        </script>
        <script type="text/javascript" src="../styles/nexus/template/prime_bbcode_spoiler.js"></script>
        <link href="../styles/nexus/theme/prime_bbcode_spoiler.css" rel="stylesheet" type="text/css"/>
    </head>
    <body id="phpbb" class="section-viewtopic ltr">
        <div id="mainframe">
        <div class="top-left"></div>
        <div class="top-middle"></div>
        <div class="top-right"></div>
        <div class="inner-wrap">
            <div class="positioncorrection-top">
                <div id="wrap">
                    <a id="top" name="top" accesskey="t"></a>
                    <div id="page-header">
                        <div class="headerbar">
                            <div class="inner">
                                <span class="corners-top"><span></span></span>
                                <div id="site-description">
                                    <a href="../forum/index.html" title="Board index" id="logo"><img src="../styles/nexus/imageset/simple%20logo.png" alt="" title="" width="766" height="126"></a>
                                    <p style="display: none;"><a href="#start_here">Skip to content</a></p>
                                </div>
                                <span class="corners-bottom"><span></span></span>
                            </div>
                        </div>
                        <div class="navbar">
                            <div class="inner">
                                <span class="corners-top"><span></span></span>
                                <ul class="linklist navlinks">
                                    <li class="icon-home"><a href="../forum/index.html" accesskey="h">Board index</a>  <strong>‹</strong> <a href="../forum/25.html">Philanthropy</a></li>
                                    <li class="rightside"><a href="#" onclick="fontsizeup(); return false;" onkeypress="fontsizeup(); return false;" class="fontsize" title="Change font size">Change font size</a></li>
                                </ul>
                                <span class="corners-bottom"><span></span></span>
                            </div>
                        </div>
                    </div>
                    <!--
                        <div class="google">

                        </div>
                        -->
                    <a name="start_here"></a>
                    <div id="page-body">
                        <h2><a href="#">Cost-effectiveness of charities including existential risks</a></h2>
                        <!-- NOTE: remove the style="display: none" when you want to have the forum description on the topic body --><span style="display: none">Whether it's pushpin, poetry or neither, you can discuss it here.<br></span>
                        <div class="topic-actions">
                            <div class="buttons">
                            </div>
                            <div class="pagination">
                                21 posts
                            </div>
                        </div>
                        <div class="clear"></div>
                        <div class="post bg2" id="p3900">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3900">Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/183.html">Recumbent</a></strong> on 2011-09-21T14:08:00</p>
<div class="content"><div class="postrev" data-snap="0">I have spent much of my free time over the last seven years trying to<br/>find the most important cause on which to work. I started with climate<br/>change, but when I compared it to global poverty, I found that global<br/>poverty was about two orders of magnitude more cost effective from a<br/>human perspective. From a biodiversity perspective, it was not clear<br/>whether climate change or rain forest destruction was the most<br/>cost-effective. In the last few years, I've become interested in<br/>existential risks. A lot of important work on this topic has been done<br/>recently by people like Nick Bostrom, Eliezer Yudkowsky, and Ray<br/>Kurzweil. Yudkowsky in particular has made the argument that since the<br/>impact of existential risk is so large and the current amount of work<br/>being done is so small, it is the most cost-effective area to work on.<br/>I have gone out on a limb and tried to actually quantify this<br/>statement. One has to make many assumptions in order to do this, so<br/>there is large uncertainty. However, as long you as you believe the<br/>uncertainty in my analysis is less than 10 orders of magnitude, we can<br/>draw some conclusions about priorities.<br/><br/>Please see my spreadsheet at: <a class="postlink" href="http://utilitarian-essays.com/cost-effectiveness-of-charities-variable-extrapolation.xlsx">http://utilitarian-essays.com/cost-effe ... ation.xlsx</a> . First I will talk about some<br/>conclusions, and then I will consider the assumptions and uncertainty.<br/>Working on physics disasters, the singularity (which includes trying<br/>to eliminate suffering in simulations and gradients in bliss), gray<br/>goo, and an asteroid large enough to cause extinction are clear<br/>winners from the perspective of economics, biodiversity, and positive<br/>utilitarians (maximizing happiness). The difficulty is the negative<br/>utilitarians, who want to minimize suffering. As has been discussed on<br/>this website, these disasters could actually be good things from this<br/>perspective. However, if we think that the galaxy is likely to be<br/>colonized by some civilization, and we think that we might have less<br/>suffering than a random civilization, even negative utilitarians might<br/>be convinced that preventing existential risks is a good thing. The<br/>extremely high cost effectiveness numbers blindly extrapolated mean<br/>that we should be spending more than our entire economy at solving<br/>these problems. This is problematic, but in reality the effectiveness<br/>of putting more and more money into it would eventually fall off. An<br/>interesting conclusion is that the cost-effectiveness of the typical<br/>American spending money on preventing existential risks relative to<br/>spending money on themselves is much greater than the very rich<br/>American funding American poverty or even global poverty relative to<br/>spending money on themselves. So this means that even people of modest<br/>means should be giving to charity.<br/><br/>A very important assumption that affects the relative importance of<br/>human extinction versus a smaller catastrophe is how much you lose<br/>with extinction. Even if you only think there is a 1% chance of going<br/>to computer consciousnesses and a 10% chance of going to a Dyson<br/>sphere (and not even considering expanding into the galaxy), the<br/>expected number of future consciousness is is at least 1E30. The basic<br/>framework for cost-effectiveness of working on disasters where we have<br/>little direct information is to scale with the expected damage, and<br/>inversely with the amount of effort. I even allow you to change the<br/>functional form, for instance where the cost-effectiveness scales<br/>inversely with the square root of the current effort. But this only<br/>changes the result a couple orders of magnitude. Of course there is<br/>uncertainty in extrapolating the cost-effectiveness from one problem<br/>to another. I have used grey to indicate uncertainty greater than one<br/>order of magnitude, and red to indicate uncertainty greater than 10<br/>orders of magnitude. Many of these numbers are knowable, like the<br/>current effort on different problems, so I am very open to people's<br/>input. Also, please play around with the assumptions, and see if the<br/>conclusions change. Some justification of many of my assumptions are<br/>in the comments for the relevant cells (just mouse over to see them).<br/>The main differences between the utilitarians and the economists are<br/>that utilitarians value humans equally, and the utilitarians do not<br/>discount.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3900">
<dt>
<a href="../user/183.html"></a><br/>
<a href="../user/183.html">Recumbent</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 17</dd>
<dd><strong>Joined:</strong> Sat Dec 26, 2009 8:17 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3902">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3902">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/341.html">rehoot</a></strong> on 2011-09-21T19:53:00</p>
<div class="content"><div class="postrev" data-snap="0">I think this post belongs in the "Utilitarian Future" category on the main page, but as far as the worksheet goes, I'm not sure how to interpret some of it.<br/><br/>One of the implications of the worksheet is the that it makes it clear (to me at least) that there are so many  unknowns that people have to decide how to respond to uncertainty.  There might not be a perfectly correct answer to your questions about the best charity when you include things that might happen but the probability of occurring is unknown, unknowable, or not known accurately enough to be conclusive.<br/><br/>For the problem of "rip fabric of space" does that mean something like the sun exploding, the heat death of the universe, contraction of the universe into a single black hole, a Star Trek disaster, or a general reference to all the above.  In the case of the first few, it is not a matter of <span style="font-style: italic">if</span> but <span style="font-style: italic">when</span>, so I recommend acceptance.  Given my lack of understanding of what that entry means, the stated values for dollar cost, likelihood, and ability to fix the problem seem arbitrary, so I don't give the benefit/cost ratio any credence at all.<br/><br/>What does "($ tn)" mean? Trillions of dollars?<br/><br/>As for the singularity, I question two of the benefits of a positive singularity, one is about the degree to which it can help social problems <a class="postlink" href="../thread/474.html#p3792">(posted here)</a>, and the other is about the degree to which it will make technology, robots, material goods, nearly free of cost (which is implied by the extrapolation of continued exponential growth in manufacturing productivity needed to support the theory).  I do not question the ability of a singularity to solve analysis problems: like finding cures for disease or solving the types of math and engineering problems that computers solve today, but <span style="font-weight: bold">the cost of building a physical object is affected by the availability of resources, and the distribution of wealth is driven by social processes that might not be amenable to the calculations of the computer</span> (see my post linked above).<br/><br/>There might be research on the following subject, I don't know, but I suspect that if we had a magic computer today and used it to create material goods and technology, it could give is this: free blueprints.  If it gave us blueprints for a really fuel-efficient car, that woud be great, benefits toward super low-cost transportation would progress in stages:<br/><br/>1) Costs to build the first version of the car would be about the same as they are now, cost to pull oil from the ground or make biofuel would be about the same as it is now. Costs to mine iron ore and other things from the ground would be the same.<br/>2) The fuel-efficient motors are used across the industry and help to reduce mining costs by  a few percent thereby slightly reducing the cost of input materials.<br/>3) The computer gives us blueprints for a mining robot with the idea that it might allow further automation.  <br/>4) To build the mining robot (or a super fast computer chip), we might need to build a new computer chip factory for the chip that goes into the robot, and also build new machines that will build the chip-manufacturing device.  All this will need to be built and tested by humans.  All the input materials to all these processes still cost approximately what they cost today.  Have you ever seen a computer-chip factory?  They can cost hundreds of millions of dollars, and people who build it will want a return on their money.  If the owners expect obsolescence in a few years, they will charge high rates for the chips that it makes for the few years that it exists.  The prices would eventually drop, but the question is when or if the cost of technology can drop so that it is affordable by all.<br/><br/>In the end, the theory of nearly infinite value of a singularity relies on a specific assertion about the ability of "free blue prints" to overcome the increased cost of finding natural resources that are being depleted.  If there is no justification for this assertion, then there is no justification for the nearly infinite value of a singularity in terms of material goods (I don't think extrapolation from past trends has any validity to projecting ad infinitum).  <br/><br/>Natural resources ARE limited, and the rich will always want more than the poor.  The poor who cannot build, operate, or fix the high-tech devices might continue to be poor EXACTLY AS THEY ARE POOR TODAY in this world of technology that is comparable to what Jules Verne imagined.  As long as the cost of capital of replacing a human with a machine is higher than the cost of hiring an uneducated worker, the vast benefits of a singularity will be unrealized to the poor.  If the cost of capital does drop, then what?  All work is done by machines? Does this implies perhaps 10 billion personal robots to act as cooks, maids, teachers, and performance artists?  I am skeptical that availability of natural resources and the technological base will allow this to happen, and if it does happen, it will do so at the likely cost of our ecosphere either from destruction caused by grabbing natural resources or by replacing the natural world with machines; cost-effective toys, cars, boats, and bigger houses.<br/><br/>Buddhists believe that people are best served by sitting silently and cultivating the skills needed to be happy in the current moment as it is now without high-tech.  In other words, the basis from which you count your utility could make a singularity directed toward manufacturing goods is actually a great detriment to the ecological balance of this planet.  That being said, it would be nice to cure diseases and use the computer to make people smart enough to voluntarily stop overpopulating the planet--if that is possible.<br/><br/>If you know of any research that explore the limiting factors of natural resources and economics, let me know.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3902">
<dt>
<a href="../user/341.html"></a><br/>
<a href="../user/341.html">rehoot</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 161</dd>
<dd><strong>Joined:</strong> Wed Dec 15, 2010 7:32 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3904">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3904">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/169.html">Jesper Östman</a></strong> on 2011-09-22T01:01:00</p>
<div class="content"><div class="postrev" data-snap="0">Impressive spreadsheet. I like the argument for that negative utilitarians should also aim to reduce x-risk (another one is the argument from cosmic rescue missions). However, it doesn't follow from it that x-risk reduction should be prioritized over striving to increase the probability of a suffering-free singularity as far as I can see.<br/><br/>Still, it seems to follow at least that, assuming that some civilization will likely colonize the galaxy and that our civilization *isn't worse* than average, it would be better for a NU to increase the probability of a good (suffering-free) post-humanity rather than to increase x-risk.<br/><br/> Although some negative utilitarians are quite certain that our hubble-volume is void of life the majority probably isn't.<br/><br/>I've only skimmed the spreadsheet this far, will have many more questions/comments when I can take the time to look through it carefully. There's one thing I wonder though. For the good singularity event, do you only calculate a single dyson sphere? In case you do, why (rather than including the space-colonization considerations eg from Bostroms astronomical waste paper)?<br/><br/>I agree with your general conclusions about the usefulness of x-riskreduction compared to other causes, did a post on it here: <a class="postlink-local" href="../thread/348.html">viewtopic.php?f=23&amp;t=348</a><br/><br/>Finally, have you thought about collaborating on making an even more detailed version?</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3904">
<dt>
<a href="../user/169.html"></a><br/>
<a href="../user/169.html">Jesper Östman</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 159</dd>
<dd><strong>Joined:</strong> Mon Oct 26, 2009 5:23 am</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3905">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3905">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/341.html">rehoot</a></strong> on 2011-09-22T04:00:00</p>
<div class="content"><div class="postrev" data-snap="0">There is another item that might belong on the list: conducting research on the formulation of the list itself including recommendations of behaviors that *individuals* can adopt in their daily lives that are utilitarian preferred.  Perhaps that is the proper starting point anyway so that either people can reach a consensus on the exact utilitarian metric to use or to frame an orderly set of alternative metrics and devise appropriate responses to the set of potentially desirable goals.<br/><br/>Some specific suggestions: <br/>a) Some of the probability estimates seem arbitrary or inaccurate. You addressed this with the "10 orders of magnitude" comment, but another way is to enter high/low/medium estimates and produce a range of benefit/cost numbers.  Entries based on greater uncertainty will have a wider confidence interval on the benefit/cost number than other entries have.<br/>b) For each scenario, you might need a separate document that lists the sources that you used to arrive at the estimates.  <br/>c) I don't understand the 1/50,000,000 black hole risk considering that the earth is billions of years old and we should have had many black hole incidents by now if your number is correct (unless I completely misunderstand what the scenario is). [edit: is this the 50 year risk assuming one black hole incident every 2.5 billion years?  still seems a bit off]<br/>d) I am exploring something related to the valuing of nature, which applies to your line for "habitat, etc species loss."  This is an example of an item that is strongly impacted by the utilitarian metric that is chosen and perhaps should get a range of benefit/cost values each with a corresponding statement of the utilitarian metric that is used.  If it is based on the purchase price of the land, you will get one number.  If it is based on the intrinsic value value of nature, I'm not sure how it would be measured.  If nature has any value other than instrumental value for humans, it will be a great loss when humans smother the earth with their homes, farms, and material things, but some will see zero loss.<br/>e) I don't understand what the net discount is doing.  If there is a 1/1,000,000 risk that the world will end in 1,000 years, what number do you want to list as the probability of risk?  I see an entry for a 50 year time horizon--are you trying to estimate the risk that the given event will happen some time in the next 50 years?  You might need multiple time horizons for a certain event that won't happen for 1,000 years (like an asteroid that will hit at a known point in the future).  The risk of that asteroid hitting in 50 years is 0 but in 1,000 it might rise to near 100%.<br/><br/>Philosophers sometimes focus mainly on one topic—if this is your focus, then it is not a bad one and could be the basis for a life's work.  Given my biases, I would say that it is a good candidate for experimental philosophy that combines psychological research about how and why we value things but with the issues framed in terms of philosophy.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3905">
<dt>
<a href="../user/341.html"></a><br/>
<a href="../user/341.html">rehoot</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 161</dd>
<dd><strong>Joined:</strong> Wed Dec 15, 2010 7:32 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3936">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3936">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/64.html">Brian Tomasik</a></strong> on 2011-10-02T12:55:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote><div><cite>Recumbent wrote:</cite>and we think that we might have less suffering than a random civilization, even negative utilitarians might be convinced that preventing existential risks is a good thing.<br/></div></blockquote><br/>This is an interesting question. Humans are more kind to each other than nature is to wild animals, so there may be some room for optimism about humanity reducing wild-animal suffering. However, humans also seem more likely to create new wild animals (and other kinds of minds that can suffer) because such minds are closer to their own. A paperclipper probably wouldn't need to create sentient minds at all. Finally, humans are also one of the most likely civilizations to perpetrate large-scale torture on each other as a means of warfare, etc. Many other civilizations may not be sentient/conscious by my criteria, so even if this happened for them, it wouldn't matter.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3936">
<dt>
<a href="../user/64.html"><img alt="User avatar" height="100" src="../file/64_1317625384.jpg" width="100"/></a><br/>
<a href="../user/64.html">Brian Tomasik</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 1130</dd>
<dd><strong>Joined:</strong> Tue Oct 28, 2008 3:10 am</dd>
<dd><strong>Location:</strong> USA</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3957">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3957">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/183.html">Recumbent</a></strong> on 2011-10-07T17:52:00</p>
<div class="content"><div class="postrev" data-snap="0">Thanks for the feedback. I am updating the spreadsheet to make it more understandable. "Rip the fabric of space" refers to the vacuum state transition that could be triggered by a physics experiment. This would destroy all level 1 universes (connected to our Hubble Sphere). Similarly, the strangelet and black hole are results of physics experiments, and would turn the Earth into a strangelet or black hole. The probability of all of these comes from a study done on the probability of disaster being one in 50 million over the roughly ten-year experiment: Rees, Martin, Our Final Hour, Basic Books, New York, 2003.<br/><br/>As for the future high utility in the singularity scenario, this is based on the singularity enabling computer consciousnesses (and you can support about 1E16 times as many computer consciousness is as human consciousnesses for the same energy (cell X8)), a 10% chance of going to Dyson sphere (cell AA8), and a 1% chance of expanding into the galaxy (cell AA9). This is a tremendous number of computer consciousnesses, so the total utility is extremely high.<br/><br/>But it is also interesting to think about what the singularity might mean for physical humans. As a starting point, we can consider the case of current technology, and I go through how 10 billion people can be supported at the US standard of living (see post below). On the mineral resources, the solutions basically are recycling and substituting for more abundant minerals.<br/>But the situation is far better (or worse) with the singularity, which would enable self replicating nanotechnology (SRN). <br/>Yudkowski (&lt;http://singinst.org/upload/artificial-intelligence-risk.pdf&gt;) paints a picture of how the super intelligence could not just make blueprints, but remake the earth and beyond toward its will:<br/>"Crack the protein folding problem, to the extent of being able to generate DNA strings whose folded peptide sequences fill specific functional roles in a complex chemical interaction. <br/>• Email sets of DNA strings to one or more online laboratories which offer DNA synthesis, peptide sequencing, and FedEx delivery. (Many labs currently offer this service, and some boast of 72-hour turnaround times.) <br/>• Find at least one human connected to the Internet who can be paid, blackmailed, or fooled by the right background story, into receiving FedExed vials and mixing them in a specified environment. <br/>• The synthesized proteins form a very primitive "wet" nanosystem which, ribosome-like, is capable of accepting external instructions; perhaps patterned acoustic vibrations delivered by a speaker attached to the beaker. <br/>• Use the extremely primitive nanosystem to build more sophisticated systems, which construct still more sophisticated systems, bootstrapping to molecular nanotechnology - or beyond. <br/>The elapsed turnaround time would be, imaginably, on the order of a week from when the fast intelligence first became able to solve the protein folding problem.<br/>An unFriendly AI with molecular nanotechnology (or other rapid infrastructure) need not bother with marching robot armies or blackmail or subtle economic coercion. The unFriendly AI has the ability to repattern all matter in the solar system according to its optimization target. This is fatal for us if the AI does not choose specifically according to the criterion of how this transformation affects existing patterns such as biology and people. The AI does not hate you, nor does it love you, but you are made out of atoms which it can use for something else."<br/><br/>But let's say we actually get a positive singularity. Then we get to control the SRN, and just using solar energy in deserts or hitting the biological desert ocean (low nutrient) areas, it could construct solar cells and electrolyzers to produce hydrogen and combine this with carbon dioxide in the atmosphere to create a hydrocarbon fuel. It could also assemble superhigh performance cars at no cost to us. With a conservative doubling time of one hour, starting at 1 cubic micron, it could cover much of the earth in about four days. Then it would be harnessing more than 100 times as much energy as we currently consume. Therefore, it could make these cars and other material goods for 10 billion people in a matter of months. The minerals required for these material things could largely come from the ocean. And this is only a one-time thing, because we could have perfect recycling with SRN. So everyone would be rich by our standards.<br/><br/>Reply to Jesper:<br/>I agree that we should work towards a suffering-free singularity, and in fact work towards the positive singularity comes out as the most cost-effective, except for preventing the vacuum state transition. But there are many different types of positive singularity, and that is what Alan Dawrst is most worried about, that we could have a positive singularity with respect to humans, but create many simulations of animals with lots of suffering. So I guess my definition of positive singularity is suffering-free. Because the singularity is so important, it probably makes sense to divide it out of different scenarios, but then assigning probabilities becomes even more difficult.<br/>Yes, I did read your post about cost effectiveness, and the source paper on asteroid prevention. I am trying to extend these types of analyses.<br/>I did consider a 1% probability of expanding into the galaxy (I personally think it is much higher, but I'm trying to build consensus). The issue is that assuming we are limited by the speed of light, discounting will make the impact small (the growth in number of entities would only go with the cube of time (volume of light cone), so it is overwhelmed by exponential discounting). So it enters more into the utilitarian analysis where you do not discount.<br/>I would love to collaborate to make the spreadsheet better. We could also try to get a conference or journal publication (this would address rehoot’s concern about references, though I am trying to incorporate them in the spreadsheet). Or maybe go straight to the public with an op-ed. But a lot of these issues are difficult to explain in small spaces. For some of these, it would be good to partner with someone who is well-known in the field.<br/>Perhaps the next step is, as rehoot suggests, to develop high, medium, and low estimates of the numbers. One difficulty is that many people don't believe a lot of these things are even possible, so the low estimate would be zero, which I don't think is very helpful.<br/><br/>As for the economic value of nature, I put in $1 million per species, which is generous, because currently it only applies to rich countries species. In reality, biodiversity is more than species, which is why, in my biodiversity section, I value each larger group of species an order of magnitude larger (an extinction of a genus is as bad as the extinction of 10 species). There are other factors, like complexity of interaction that are very difficult to measure. I think an important conclusion of this work is that even if you only care about divide biodiversity, the most important thing to work on is preventing existential risks.<br/>rehoot seems to be implying that even if we can preserve biodiversity, there is still a problem with human encroachment. Certainly there is value of wilderness to humans, but that comes in for the economic valuation. We also have to be concerned about the suffering of animals, and I have included this in the utilitarian perspective. However, I have weighted the suffering with brain size, which Alan Dawrst would disagree with. I have included his estimate of the cost effectiveness of humane pesticides with his number of 1% probability of the full suffering of humans. As Alan has pointed out, if there is net suffering in nature, we actually want to destroy nature in order to prevent suffering. I don't think that there is net suffering in nature, and I do see hope to eliminate suffering in nature with the singularity.<br/>I apologize that my handling of discounting is a little confusing. If something has a uniform probability of happening over time (or if you have a constant payment over time), then the discounted infinite sum is the first year value multiplied by the time horizon. The time horizon is the reciprocal of the net discount rate. I have estimated this discount rate by taking the inflation-adjusted (real) long-term return on investment of approximately 5% and subtracted the real economic growth rate of 3% to get 2%, or a 50 year time horizon. The rationale for discounting at the economic growth rate is that people will be richer in the future, so a marginal dollar is worth less to them than the people in present generations. However, the net discount rate, sometimes called the pure time preference, is more controversial. If people did not have a time preference, then they should save about two thirds of their income in order to maximize the discounted sum of welfare. So basically people do behave as if there is a pure time preference. The paper addressing the cost effectiveness of preventing asteroid impacts argues that we should not discount existential risks. So I think it is good that I have done the utilitarian scenario where I did not discount. But it turns out that the most important risks are likely to happen this century, and then discounting does not change the result very much. But to answer your question, with a 2% discount rate, the discount factor over 1000 years is about 1E-9 so I would say that discounted probability of your one in 1 million scenario would be 1E-15. With the expected number of human (or computer) consciousnesses even just in our solar system of ~1E32, this still could be a big deal. However, once we actually have self sustaining colonies beyond the Earth, the probability that our civilization as a whole will end is dramatically reduced. So this is why we really only have to worry about this century.<br/>I agree that a more complex formulation is required when the probabilities change significantly over time, but again I don't think that matters too much for the most important risks.<br/>I agree that fully vetting all of these potential causes with high accuracy is a tremendous undertaking. However, what I wish to show without that much more work is that we can prioritize things despite large uncertainty. Then if we can mobilize significant research and charity on these most important issues of physics disasters, singularity, and gray goo, we will have a tremendous overall impact on the future of our species and others.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3957">
<dt>
<a href="../user/183.html"></a><br/>
<a href="../user/183.html">Recumbent</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 17</dd>
<dd><strong>Joined:</strong> Sat Dec 26, 2009 8:17 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3958">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3958">Re: Cost-effectiveness of charities: running out of resource</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/183.html">Recumbent</a></strong> on 2011-10-07T17:55:00</p>
<div class="content"><div class="postrev" data-snap="0">Here is the text of the presentation I gave about two years back on running out of resources, including references.<br/><br/>Will We Run Out of Resources?<br/>David Denkenberger <br/>Ph.D. Candidate, Building Systems Program<br/>Civil, Environmental, and Architectural Engr, CU<br/>Introduction<br/>•	Economic includes time, aesthetics, taste etc.<br/>•	Conservation sacrifices these intangibles “freezing in the dark”<br/>•	Energy efficiency doesn’t sacrifice intangibles        “win, win, win:” environment, money, and intangibles<br/>•	Environment is that which primarily affects people, e.g. air and water pollution<br/>•	Nature is biodiversity and habitat protection<br/>•	Europe destroyed almost all its nature, but is doing well environmentally (far lower air and water pollution than 100 years ago)1 <br/>•	Million: mn; billion: bn; trillion: tn <br/>1Lomborg, B. The Skeptical Environmentalist. New York, Cambridge University Press, 2001.<br/>Sustainability<br/>•	Many people say that the earth simply cannot support 10 billion people at the US standard of living<br/>•	Won’t work with our current system, but will be forced to change eventually anyway<br/>•	Ecological footprint is the amount of land that is required to sustainably provide for our energy, minerals, living space, food, fiber, and water (~2.2 acres of usable land per person is our quota)1 <br/>1Palmer, A. “Evaluating Ecological Footprints.” Electronic Green Journal, Special Issue 9, December 1998.<br/><br/>Energy<br/>•	US per person primary energy use is ~10 kW1 <br/>•	If start with renewable electricity, need less primary energy, 4-8 kW, so say 6 kW<br/>•	So 10 bn people require 60 tn watts (TW)<br/>•	Current wind technology could provide 72 TW2 <br/>•	Solar max on land ~6,000 TW, but practical ~600 TW3 <br/>•	If 10% efficient and 200 W/sq m,3 ~0.1 acre/person: 5% of ecological footprint quota, but could be in desert or on rooftops<br/>•	Intermittency: vehicle batteries, building thermal, compressed air, or hydrogen (H2)<br/>1Energy Information Administration. “Annual Energy Review 2007.”<br/>2Archer, C. and M. Jacobson. “Evaluation of global wind power.” JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 110, D12110, doi:10.1029/2004JD005462, 2005.<br/>3Lewis, N.S. “Powering the Planet” California Institute of Technology presentation.<br/><br/>Minerals<br/>•	The mineral we spend the most on is…<br/>•	Cement (limestone)1 <br/>•	Non-energy resources cost 1% of GDP1 <br/>•	Most money is spent on abundant, e.g. iron and aluminum ~10x in general rock as copper ore2 <br/>•	Copper is not abundant, but worst case scenario is 0.5% GDP loss if we have to mine general rock because recycle and substitute1 (or even mine our landfills, like we are doing in some places3)<br/>•	May have to start recycling phosphorus (fertilizer) this century4 (general rock P                                                                concentration 10x copper)<br/>1Lomborg, B. The Skeptical Environmentalist. New York, Cambridge University Press, 2001.<br/>2Tarbuck, E.J. and F.K. Lutgens. Earth: An Introduction to Physical Geology. Prentice Hall, Upper Saddle River, 1999.<br/>3“Landfill mining” <a class="postlink" href="http://en.wikipedia.org/wiki/Landfill_mining_and_reclamation">http://en.wikipedia.org/wiki/Landfill_m ... eclamation</a> . Accessed February 2009.<br/>4http://en.wikipedia.org/wiki/Phosphorous Accessed Feb 2009.<br/><br/>Minerals for Energy<br/>•	Wind turbines, heat pumps, and electric          resistance: conventional materials<br/>•	Nuclear: uranium from ocean1 <br/>•	Thin film solar cells: amorphous silicon (not cadmium or indium)<br/>•	Batteries: lithium tough2, but nickel, lead, zinc and iron3 <br/>•	H2 electrolysis can be graphite or nickel4 <br/>•	Fuel cells: platinum: looking for substitutes; but can just burn H2<br/>•	Combining H2 with CO2 from air to make gasoline substitute: done industrially, cheap catalysts5 <br/>1Uranium can currently be filtered out of the ocean: “Uranium Depletion” <a class="postlink" href="http://en.wikipedia.org/wiki/Uranium_depletion">http://en.wikipedia.org/wiki/Uranium_depletion</a>.  Accessed February 2009.<br/>2http://www.ecogeek.org/content/view/2261/ <br/>3http://en.wikipedia.org/wiki/Super_iron_battery <br/>4Dopp, R. “HYDROGEN GENERATION VIA WATER ELECTROLYSIS USING HIGHLY EFFICIENT NANOMETAL ELECTRODES.”<br/>Quantum Sphere white paper, April 2007.<br/>Olah, G., Alain Goeppert, and G. K. Surya Prakash. “Chemical Recycling of Carbon Dioxide to Methanol and Dimethyl Ether: From Greenhouse Gas to Renewable, Environmentally Carbon Neutral Fuels and Synthetic Hydrocarbons.” Journal of Organic Chemistry Perspective VOLUME 74, NUMBER 2, January 16, 2009.<br/><br/>Living Space<br/>•	Typical half acre suburban plot with 3 people is 0.17 acres/person, or ~8% of ecological footprint quota<br/>•	Buildings ~0.5% of footprint (residential 1000 sq ft times 1.5 to include commercial)<br/>•	Parking ~0.6% of footprint1 <br/>•	Landfills ~0.0001% of footprint!2 <br/>•	Mining ~1% of footprint (based on Natural Capitalism material moved and assumed mine depth and coal reference)<br/>1Shoup, D. The high cost of free parking. Chicago, Ill. Planners Press, 2005.<br/>2Lomborg, B. The Skeptical Environmentalist. New York, Cambridge University Press, 2001.<br/><br/>Water<br/>•	If water is withdrawn and not consumed (evaporated), it is available downstream (and water pollution levels are falling)<br/>•	Agriculture is 70% of withdrawals, but 93% of consumption1 <br/>•	Including rain-fed, agriculture and silviculture (wood) are 99% of consumption1 <br/>•	I get lawns ~5% of US consumption, but non-plants (non-land) ~0.5% (industry, drinking, showers)<br/>•	Irrigation has reduced our direct ecological footprint ~10%1 and only 1/10 of irrigation is unsustainable,2 so we will only lose 1%<br/>•	Humans consume about ¼ of  evapotranspiration1 <br/>1University of Michigan. “Human Appropriation of the World's Fresh Water Supply.” 2006<br/>2Pimentel, D. and M. Giampietro. “FOOD, LAND, POPULATION and the U.S. ECONOMY.” 1994.<br/><br/>Fiber<br/>•	By mass of wood, not value (for plantations):<br/>•	Lumber ~5% of footprint quota1 <br/>•	Paper and cardboard ~5% of footprint1 <br/>•	Burning (industrial and personal) ~10% of footprint1 <br/>•	Cotton is ~1% of footprint2 <br/>1Plantation production in Denmark is 7.5 m3/ha/yr (Lomborg, B. The Skeptical Environmentalist. New York, Cambridge University Press, 2001.) Net primary productivity for typical farm and forest land is ~double that (Hirakoba, A., R. Shibasaki and S. Ochi. “Generating Global NPP Map for Estimating Agricultural Productivity.” Asian Conference on Remote Sensing 1997.) A US person uses ~1.3 tons/yr of forest products (Skog, K., P. Ince and Haynes, R. “Wood fiber supply and demand in the United States.” The Forest Products Society, ISBN 0-892529-08-4, 2000.)<br/>2http://www.cotton.org/news/meetings/2008annual/pltsteve.cfm Accessed Nov 2009.<br/><br/>Food/ Totals<br/>•	~70% of footprint with US productivity1<br/>      (if European productivity (similar to US in 1960, but now double US), only ~35%2); land loss, but CO2 up<br/>•	Total footprint of American is ~70% of quota, which is sustainable, but more natural forests would be converted to plantations and farming<br/>•	If problem and needed &gt;100%, price would increase: not build out of or burn wood, use farm residues for paper, waste less food, and eat less meat; all happening in drier countries: cut footprint                  in half (or future tech like algae flue)<br/>•	The problem is saving nature, not people<br/>1Palmer, A. “Evaluating Ecological Footprints.” Electronic Green Journal, Special Issue 9, December 1998.<br/>2Lomborg, B. The Skeptical Environmentalist. New York, Cambridge University Press, 2001.<br/><br/>Orders of magnitude of eco footprint quota <br/>•	300% food biomass all energy<br/>•	100% cellulosic biomass all energy, 10 ac lot (telecommuting), food + fiber if organic and 350 ppm <br/>•	30% food, fiber<br/>•	10% living space<br/>•	3% solar for all energy<br/>•	1% mining, roads<br/>•	0.3% wind for all energy, buildings, parking<br/>•	0.1% nuclear for all energy<br/>•	…<br/>•	0.0001% landfills</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3958">
<dt>
<a href="../user/183.html"></a><br/>
<a href="../user/183.html">Recumbent</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 17</dd>
<dd><strong>Joined:</strong> Sat Dec 26, 2009 8:17 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3959">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3959">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/53.html">RyanCarey</a></strong> on 2011-10-08T06:30:00</p>
<div class="content"><div class="postrev" data-snap="0">I'm posting only to say that I've read the thread. Thanks for all involved expressing these complex issues clearly. I'll look at all of this in more detail when I have time.</div><div class="diff hidden"></div></div>
<div class="signature">You can read my personal blog here: <a class="postlink" href="http://www.careyryan.com">CareyRyan.com</a></div>
</div>
<dl class="postprofile" id="profile3959">
<dt>
<a href="../user/53.html"><img alt="User avatar" height="100" src="../file/53_1225370811.gif" width="100"/></a><br/>
<a href="../user/53.html">RyanCarey</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 682</dd>
<dd><strong>Joined:</strong> Sun Oct 05, 2008 1:01 am</dd>
<dd><strong>Location:</strong> Melbourne, Australia</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3961">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3961">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/341.html">rehoot</a></strong> on 2011-10-08T23:16:00</p>
<div class="content"><div class="postrev" data-snap="0">Thx for the detailed post.  I'll review the thinking on the discount value and see if I understand it the way you do (I am familiar with discounting in the finance world, but I'll have to think about how it applies to existential risk with a [possibly] growing population).  As for the biological engineering--that would address the self-replication issues and introduce ethical issues.  It would seem to address lots of problems related to building high-tech machines to build robots (which will happen but would be less critical for biological systems).<br/><br/>I downloaded the Yudkowsky article, and I'll read that and review your presentation too.  <br/><br/>In the energy-use part, perhaps the US rate is 10 kW hours per day (as far as the units of measure go).  I have dealt with solar, and the devil is in the details.  The current method for home use is solar PV with everything connected by wires.  The cost of the panels themselves is not the difficult part, but building sturdy mounts, wiring it with expensive wire, and using expensive controllers and batteries adds to the cost and complexity.  There will probably be other technologies in the future that improve the delivery and storage system (such as converting to hydrogen at the PV panel and delivering hydrogen for part of the energy needs).<br/><br/>There was a story in the news recently about the global ecological debt.  Some nonprofit organization makes calculations of the day during the year when we use more resources than the earth can sustain.  I heard various criticisms of the methods, but at least they are collecting data and trying to improve their methods:<br/><a class="postlink" href="http://www.footprintnetwork.org/en/index.html/GFN/page/ecological_footprint_atlas_2008/">http://www.footprintnetwork.org/en/inde ... tlas_2008/</a><br/><br/>I have some deadlines over the next week, but I'll respond again on this issue.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3961">
<dt>
<a href="../user/341.html"></a><br/>
<a href="../user/341.html">rehoot</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 161</dd>
<dd><strong>Joined:</strong> Wed Dec 15, 2010 7:32 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3964">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3964">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/64.html">Brian Tomasik</a></strong> on 2011-10-09T04:22:00</p>
<div class="content"><div class="postrev" data-snap="0">Hi Recumbent,<br/><br/>I was chatting with your friend Supine yesterday. He said you were lazy for lounging around. Are you going to take that lying down?<br/><br/>Anyway....<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>However, I have weighted the suffering with brain size, which Alan Dawrst would disagree with.<br/></div></blockquote><br/>Yes, probably, though I'm <a class="postlink" href="../thread/139.html">not completely sure</a>.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>As Alan has pointed out, if there is net suffering in nature, we actually want to destroy nature in order to prevent suffering. I don't think that there is net suffering in nature,<br/></div></blockquote><br/>Why not? What do you make of the point that most species have vast numbers of offspring that die shortly after birth? For example, <a class="postlink" href="http://arzonetranscripts.wordpress.com/2011/03/19/professor-oscar-horta-interview/">from Oscar Horta</a>:<br/><blockquote class="uncited"><div>most animals have lots of offspring and that all of them except a handful of individuals die soon after coming to existence. They have little or no enjoyment in their lives, and their deaths are terrible. This is so because most animals follow what is called an “r-selection strategy” for reproduction. They lay thousands or millions of eggs. On average, only one or two survives, for instance, cods may lay up to 9000000 eggs.<br/></div></blockquote><br/>Granted, eggs almost certainly don't suffer, but even if a tiny fraction of those eggs turn into little fish, that's a lot of painful deaths.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>So basically people do behave as if there is a pure time preference.<br/></div></blockquote><br/>Yes, but people also have kin preference. And we humans do all sorts of things that aren't even plausibly in our interest, like injecting heroin despite high risk of AIDS.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3964">
<dt>
<a href="../user/64.html"><img alt="User avatar" height="100" src="../file/64_1317625384.jpg" width="100"/></a><br/>
<a href="../user/64.html">Brian Tomasik</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 1130</dd>
<dd><strong>Joined:</strong> Tue Oct 28, 2008 3:10 am</dd>
<dd><strong>Location:</strong> USA</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3976">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3976">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/183.html">Recumbent</a></strong> on 2011-10-10T01:50:00</p>
<div class="content"><div class="postrev" data-snap="0">Rehoot, my presentation is in the framework of the ecological footprint. We are currently unsustainable because we are emitting CO2 (which has to be absorbed by many acres of forest under the ecological footprint metric), and not exploiting currently available technology to reduce the footprint of food and fiber. It is true that solar is currently expensive. It may decrease  in cost in the future, or we could use lower-cost options, such as wind energy and breader reactors. The point of my presentation is not cost; it is that we can support 10 billion people at the US standard of living with currently available technology sustainably. In reality, because the cost of these options is higher, we will conserve (for instance, we would require less energy).</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3976">
<dt>
<a href="../user/183.html"></a><br/>
<a href="../user/183.html">Recumbent</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 17</dd>
<dd><strong>Joined:</strong> Sat Dec 26, 2009 8:17 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3977">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3977">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/183.html">Recumbent</a></strong> on 2011-10-10T02:05:00</p>
<div class="content"><div class="postrev" data-snap="0">Alan, with brain size weighting, I have estimated that the potential suffering of wild animals is of the same order of magnitude of humans. Granted, there is a lot of uncertainty in this estimate, so it could be two orders higher or two orders lower. <br/><br/>Even if you don't weight by brain size, when we can simulate brains, we are likely to simulate far more human consciousnesses than animal. So I would still contend that the most important issue is how we handle the singularity. For instance, your humane pesticides is extremely cost-effective by normal standards, but not as cost effective as working towards a positive singularity, especially because that positive singularity might be able to eliminate wild animal suffering.<br/><br/>By the way, I have not addressed the doomsday argument, which says that since about 60 billion people have ever lived, we can expect that about 60 billion people more will live. At current population and life expectancy, this only gives us a few centuries. As the Wikipedia article points out, some people are more pessimistic than this, like Ray Kurzweil who says we only have a 50% chance of making it through this century. However, the article also points out that a way around this is that this may only apply to the number of physical humans; if we go through the singularity, it is very possible to create far more humans. Furthermore, as we diversify into space, the extinction of our species becomes far less likely. That is why I think it is reasonable that the expected number of consciousnesses is extremely high.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3977">
<dt>
<a href="../user/183.html"></a><br/>
<a href="../user/183.html">Recumbent</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 17</dd>
<dd><strong>Joined:</strong> Sat Dec 26, 2009 8:17 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3978">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3978">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/183.html">Recumbent</a></strong> on 2011-10-10T02:32:00</p>
<div class="content"><div class="postrev" data-snap="0">Alan, I agree that just because people have a pure time preference does not make it correct or optimal. My point is that even with this pure time preference, we still conclude that working on existential risks is the most cost-effective.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3978">
<dt>
<a href="../user/183.html"></a><br/>
<a href="../user/183.html">Recumbent</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 17</dd>
<dd><strong>Joined:</strong> Sat Dec 26, 2009 8:17 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3984">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3984">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/64.html">Brian Tomasik</a></strong> on 2011-10-10T13:17:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote><div><cite>Recumbent wrote:</cite>Alan, with brain size weighting, I have estimated that the potential suffering of wild animals is of the same order of magnitude of humans. Granted, there is a lot of uncertainty in this estimate, so it could be two orders higher or two orders lower.<br/></div></blockquote><br/>Ah, I see. Those are the computations near U2?<br/><br/>Do you know the sources from which you got the brain-size figures and population figures? It would be great to compile these in more detail.<br/><br/><a class="postlink" href="http://www.lingolex.com/ants.htm">This page</a>, item #1, suggests that the ratio of neurons in the ant to neurons in the human is 2.5 * 10^-5. If an ant is representative of all insects (is it?), then with 10^18 total insects and 10^10 humans, there would be 2500 times more insect neurons.<br/><br/>Here's <a class="postlink" href="http://faculty.washington.edu/chudler/facts.html">a nice compendium of brain sizes</a> for all kinds of species. I wish I had estimates of the worldwide populations of those same animals. Rat brains are 2 g compared with 1200-1500 for humans. I would guess there are at least 1000 times as many rat-sized animals as humans, but I really don't know. It's hard to find good animal census data!<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>For instance, your humane pesticides is extremely cost-effective by normal standards, but not as cost effective as working towards a positive singularity, especially because that positive singularity might be able to eliminate wild animal suffering.<br/></div></blockquote><br/>Yeah, but I'm not going to actively support human extinction.<br/><br/>And despite lots of talk about friendly AI, it remains unclear to me what it looks like to "work towards a positive singularity" in a way that ensures that outgroup-type minds (animals, lower-level sims) have their interests accounted for, except to promote concern for animal suffering (which is one of the main points of the humane-insecticide campaign).<br/><br/>What ideas do you have for how to concretely work toward preventing massive suffering if a Singularity occurs?<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>However, the article also points out that a way around this is that this may only apply to the number of physical humans; if we go through the singularity, it is very possible to create far more humans.</div></blockquote><br/>I think the relevant reference class should be the set of all observer-moments (as Bostrom says), which includes non-physically-human human-like minds.<br/><br/>As far as resolutions to the Doomsday Argument, here are my candidates:<br/><ol style="list-style-type: decimal"><li> Bite the bullet.</li><li> We're in an ancestor simulation.</li><li> Adopt <a class="postlink" href="http://en.wikipedia.org/wiki/Self-Indication_Assumption">SIA</a>.</li></ol>At present, I lean toward #3, though any one of them sounds plausible.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3984">
<dt>
<a href="../user/64.html"><img alt="User avatar" height="100" src="../file/64_1317625384.jpg" width="100"/></a><br/>
<a href="../user/64.html">Brian Tomasik</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 1130</dd>
<dd><strong>Joined:</strong> Tue Oct 28, 2008 3:10 am</dd>
<dd><strong>Location:</strong> USA</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3991">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3991">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/183.html">Recumbent</a></strong> on 2011-10-11T03:33:00</p>
<div class="content"><div class="postrev" data-snap="0">Brain mass estimates:<br/><br/><a class="postlink" href="http://www.abdn.ac.uk/mammal/history.shtml">http://www.abdn.ac.uk/mammal/history.shtml</a><br/><br/>"The answer is about 285 million, we think, but most of these are small mammals, particularly Common Shrews, Bank Voles, Wood Mice and Field Voles. Only the Field Vole, with about 75 million in spring, is likely to be more numerous than people in Britain (about 53 million, according to the national census, but about 38 million adults for fairer comparison with just the breeding populations of other mammals)."<br/>So ~10x as many mammals as humans. But the UK has quite high population density. So I think globally, the ratio of total mammals to humans would be even higher. The United Kingdom is 640 people per square mile, while the world is 120. Of course in the deserts and tundra, there are not many people and not many other mammals. And we are giving a lot of food for rodents with agriculture in the UK. So maybe I will just go with a ratio of 10, so 1E11 mammals.<br/><br/><a class="postlink" href="http://lifeboat.com/ex/global.ecophagy">http://lifeboat.com/ex/global.ecophagy</a><br/><br/>"There are ~1018-1019 insects on Earth [75-77]. The average insect<br/>devotes ~35% of body volume to its respiratory system [78], which is<br/>mostly gas-phase diffusional but with some very primitive active<br/>ventilation. If average insect volume is ~0.6 mm3 [77],<br/>then the worldwide insect population has ~2 × 109 m3 of tracheal air<br/>volume which could accumulate ~1016 aerovores if insects are exposed<br/>to replibot-contaminated air at a concentration equivalent to ~1%<br/>atmospheric opacity."<br/>So ~.4 mg/insect (arthopod?)<br/><br/>There is also an order of magnitude variation in neuron volume, but that is within the uncertainty of the analysis, so I just went with brain mass:<br/><br/><a class="postlink" href="http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6W66-4H22YN5-6&amp;_user=918210&amp;_rdoc=1&amp;_fmt=&amp;_orig=search&amp;_sort=d&amp;view=c&amp;_acct=C000047944&amp;_version=1&amp;_urlVersion=0&amp;_userid=918210&amp;md5=51a44decba677ac96f05faa262661456">http://www.sciencedirect.com/science?_o ... a262661456</a><br/><br/>I was just going for the order of magnitude in the posted version of the spreadsheet. So I have updated the new version to include the numbers above (which I will post as I make more changes). The other inputs were mammal brain 10% of weight, vertebrate non-mammal 1%, and arthropod 0.1%. I think I have a source for the last one, but I couldn't find it. I estimated that the number of individuals of non-mammal vertebrate are dominated by small fish, and 10^14, but that is just a guess. If you want to get better numbers for this, I would recommend trying to find the biomass of these different types and finding more accurate estimates of the percentage brain mass. With my estimate, interestingly, the brain mass of each of these groups of animals is similar (with humans an order larger).<br/><br/>Let me clarify my statement that the positive singularity might be able to eliminate wild animal suffering. I meant that with the vast intelligence associated with the singularity, I think it would be feasible to implement gradients in bliss (instead of being motivated by pleasure and pain, one would be motivated by more bliss and less bliss) in wild ecosystems without extinction. Even if this is not possible, we could preserve species (for information sake), but reduce the number of individuals dramatically, especially for arthropods, and therefore dramatically reduce suffering. We could do some of the latter even without super intelligence.<br/><br/>A concrete way of working towards a positive singularity without suffering is to work with the people who actually have a shot of creating the singularity (like the people at the Singularity Institute for Artificial Intelligence) to increase the probability that the artificial intelligence is not just friendly to humans, but friendly to all sentient beings.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3991">
<dt>
<a href="../user/183.html"></a><br/>
<a href="../user/183.html">Recumbent</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 17</dd>
<dd><strong>Joined:</strong> Sat Dec 26, 2009 8:17 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p3992">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p3992">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/183.html">Recumbent</a></strong> on 2011-10-11T03:45:00</p>
<div class="content"><div class="postrev" data-snap="0">But I'm saying that even if we bite the bullet on the doomsday argument, it still gives us a few centuries to establish independent colonies, in which case I don't believe the doomsday argument applies (or it is much weaker).<br/><br/>I should add as a personal note that I am an optimist. I think this influenced the fact that even though I learned about the existential risks of unfriendly artificial intelligence and grey goo about 11 years ago, until recently I chose to work on problems that were more amenable solutions, like climate change, resource depletion, and global poverty. As has been noted elsewhere in this discussion board, it is difficult to get people to think about existential risks - most other topics are sexier.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile3992">
<dt>
<a href="../user/183.html"></a><br/>
<a href="../user/183.html">Recumbent</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 17</dd>
<dd><strong>Joined:</strong> Sat Dec 26, 2009 8:17 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p4007">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p4007">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/64.html">Brian Tomasik</a></strong> on 2011-10-11T13:05:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote><div><cite>Recumbent wrote:</cite>So maybe I will just go with a ratio of 10, so 1E11 mammals.<br/></div></blockquote><br/>Cool, thanks! That's encouragingly close to my estimate in "<a class="postlink" href="http://www.utilitarian-essays.com/number-of-wild-animals.html">How Many Wild Animals Are There?</a>" -- see the sections on Birds and Land Mammals.<br/><br/>Yeah, maybe it was a bit off to suggest that mammals are 1000 times more prevalent than humans. That said, there's an asymmetry here due to lack of knowledge: We know the human population exactly. We don't know the mammal population exactly, and our probability distribution has a right skew. So the expected value is higher than our median point estimate.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>And we are giving a lot of food for rodents with agriculture in the UK.</div></blockquote><br/>Side question: Do you think farming increases or decreases wild-animal populations on the whole? Count (a) insects and other animals on the crop lands, (b) insects and other animals supported elsewhere by the increased food production, and (c) habitats destroyed by using the land for agriculture.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>There is also an order of magnitude variation in neuron volume, but that is within the uncertainty of the analysis, so I just went with brain mass<br/></div></blockquote><br/>We used different methods for estimating total insect neurons, and it's too bad they differ by a few orders of magnitude (unlike for our mammal estimates).<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>Let me clarify my statement that the positive singularity might be able to eliminate wild animal suffering. I meant that with the vast intelligence associated with the singularity, I think it would be feasible to implement gradients in bliss (instead of being motivated by pleasure and pain, one would be motivated by more bliss and less bliss) in wild ecosystems without extinction.<br/></div></blockquote><br/>I totally support that vision (well, except that utilitronium would be more efficient). But I find it vastly less probable than the scenario in which we just destroy wild animals (e.g., by paperclipping).<br/><br/>In any event, how does one work toward gradients of bliss (without incurring risk of increasing the odds of human survival)? Just meme promotion and encouraging people to be more hedonistic?  (Hedonistic <span style="font-style: italic">utilitarians</span> that is  <img alt=";)" src="../images/smilies/icon_e_wink.gif"/> .)<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>A concrete way of working towards a positive singularity without suffering is to work with the people who actually have a shot of creating the singularity (like the people at the Singularity Institute for Artificial Intelligence)<br/></div></blockquote><br/>Do you think they have a shot? How? I think the best they could do would be to work on their own form of meme spreading within the public debate on AI, in order to reduce paperclipper risk and maybe promote transhumanist values. But the former is not something I'm particularly fond of.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>But I'm saying that even if we bite the bullet on the doomsday argument, it still gives us a few centuries to establish independent colonies, in which case I don't believe the doomsday argument applies (or it is much weaker).<br/></div></blockquote><br/>Hmm, why? Because we're not in that reference class? I think the reference class has to be <span style="font-style: italic">all</span> observers that are aware of their own existence; otherwise it'll be arbitrary. (See, e.g., "The reference class problem" <a class="postlink" href="http://www.anthropic-principle.com/preprints/inv/investigations.html">here</a>.)<br/><br/>I agree that extinction risk goes down a lot once we colonize other planets, but the point of the Doomsday Argument is to adjust whatever prior probabilities you've established by other means.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>I should add as a personal note that I am an optimist.<br/></div></blockquote><br/>As Jesper has said, it's good to be self-reflective about such things. <img alt=":)" src="../images/smilies/icon_e_smile.gif"/> As you know, I lean on the negative side relative to most of my friends (although I don't know if it's relative to most animals on earth). And the controversial hypothesis of <a class="postlink" href="http://en.wikipedia.org/wiki/Depressive_realism">depressive realism</a> may have something to it.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile4007">
<dt>
<a href="../user/64.html"><img alt="User avatar" height="100" src="../file/64_1317625384.jpg" width="100"/></a><br/>
<a href="../user/64.html">Brian Tomasik</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 1130</dd>
<dd><strong>Joined:</strong> Tue Oct 28, 2008 3:10 am</dd>
<dd><strong>Location:</strong> USA</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p4021">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p4021">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/183.html">Recumbent</a></strong> on 2011-10-12T01:46:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote class="uncited"><div>Side question: Do you think farming increases or decreases wild-animal populations on the whole? Count (a) insects and other animals on the crop lands, (b) insects and other animals supported elsewhere by the increased food production, and (c) habitats destroyed by using the land for agriculture.</div></blockquote><br/><br/>Sorry, my old link no longer works, so here's the new one:<br/><a class="postlink" href="http://www.mammal.org.uk/index.html?option=com_content&amp;view=article&amp;id=250&amp;Itemid=283">http://www.mammal.org.uk/index.html?opti ... Itemid=283</a><br/>This says that in the UK, the wild mammal biomass is about two thirds as much as it was 6000 years ago. I'm not sure about the number of individuals, but the biomass statistic works for the brain size calculation. For conventional agriculture, I think the number of insects would be considerably less than in nature (because pesticides prevent them). However, in organic agriculture, I think the number of insects would be considerably more than in nature. So if you are concerned about insects suffering, don't eat organic food!<br/><br/><blockquote class="uncited"><div>I totally support that vision (well, except that utilitronium would be more efficient).</div></blockquote><br/>I tried to look this up, but could you explain how this would work?<br/><br/><blockquote class="uncited"><div>In any event, how does one work toward gradients of bliss (without incurring risk of increasing the odds of human survival)? </div></blockquote><br/><br/>Are you seriously saying that increasing the odds of human survival is a bad thing? Even if you think insects have a net negative lives, you must think that humans as a whole have net positive lives.<br/><br/>I do think that people like Kurzweil and Yudkowski have a shot at creating self-modifying artificial intelligence. Kurzweil is currently writing a book called, "how to build a brain." So we should influence these people to create an intelligence that would actually be motivated to eliminate suffering in all sentient beings.<br/><br/><blockquote class="uncited"><div>I agree that extinction risk goes down a lot once we colonize other planets, but the point of the Doomsday Argument is to adjust whatever prior probabilities you've established by other means.</div></blockquote><br/><br/>How do you do that?</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile4021">
<dt>
<a href="../user/183.html"></a><br/>
<a href="../user/183.html">Recumbent</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 17</dd>
<dd><strong>Joined:</strong> Sat Dec 26, 2009 8:17 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p4026">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p4026">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/64.html">Brian Tomasik</a></strong> on 2011-10-14T12:35:00</p>
<div class="content"><div class="postrev" data-snap="0"><blockquote><div><cite>Recumbent wrote:</cite>This says that in the UK, the wild mammal biomass is about two thirds as much as it was 6000 years ago.<br/></div></blockquote><br/>Very cool! I'm glad we have humans around.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>However, in organic agriculture, I think the number of insects would be considerably more than in nature.<br/></div></blockquote><br/>Unfortunately, yes.<br/><br/>On utilitronium, <a class="postlink" href="http://wiki.lesswrong.com/wiki/Utilitronium">here</a> is a basic reference. Hedonistic utilitarians would want to maximize simulation of pleasurable experiences. The shockwave could be implemented by, say, <a class="postlink" href="http://en.wikipedia.org/wiki/Self-replicating_spacecraft">von Neumann probes</a>.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>Are you seriously saying that increasing the odds of human survival is a bad thing? Even if you think insects have a net negative lives, you must think that humans as a whole have net positive lives.<br/></div></blockquote><br/>Well, I don't necessarily weight by brain size. Moreover, the more important point is that I lean toward non-pinprick negative utilitarianism. See, e.g., <a class="postlink" href="../thread/457.html">this thread</a>, especially the first few posts.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>I do think that people like Kurzweil and Yudkowski have a shot at creating self-modifying artificial intelligence.<br/></div></blockquote><br/>Would this be in the basement without many more resources than they have now? What's the probability you'd assign for each of them in turn?<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>How do you do that?</div></blockquote><br/>Oh, just standard Bayesian update with the new evidence about which observer-moment you find yourself to be. See, e.g., some of the calculations in <a class="postlink" href="http://en.wikipedia.org/wiki/Doomsday_argument">Wikipedia's entry</a> on DA.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile4026">
<dt>
<a href="../user/64.html"><img alt="User avatar" height="100" src="../file/64_1317625384.jpg" width="100"/></a><br/>
<a href="../user/64.html">Brian Tomasik</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 1130</dd>
<dd><strong>Joined:</strong> Tue Oct 28, 2008 3:10 am</dd>
<dd><strong>Location:</strong> USA</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p4039">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p4039">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/183.html">Recumbent</a></strong> on 2011-10-15T15:11:00</p>
<div class="content"><div class="postrev" data-snap="0"><a class="postlink" href="http://www.celebritynetworth.com/richest-businessmen/ray-kurzweil-net-worth/">http://www.celebritynetworth.com/riches ... net-worth/</a><br/>Not the most reliable source, but they say Kurzweil's net worth is $27 million.<br/><br/>I think that Kurzweil is too optimistic, especially outside of his field. But that also should give us pause when he says he thinks we only have a 50% chance of not destroying ourselves with the singularity. I won't hazard a guess on the probability of an individual person creating self modifying artificial intelligence. But there is also a good chance that the Department of Defense is putting a ton of money into this. I'm not sure how much they would be worried about making the artificial intelligence friendly.  <img alt=":)" src="../images/smilies/icon_e_smile.gif"/> <br/><br/>Yudkowski says that when an expert says there is only a one in 1 million chance of something happening (without actuarial data), the data show more like one in 20 chance! So the overconfidence of the neuroscientist saying we can't reverse engineer the brain anytime soon should be questioned. By the same token, Kurzweil's position that the singularity is inevitable should also be questioned. But even with my 1% probability of negative singularity, it is the most cost-effective charity (other than physics disasters and extinction-producing asteroid) by about 20 orders of magnitude.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile4039">
<dt>
<a href="../user/183.html"></a><br/>
<a href="../user/183.html">Recumbent</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 17</dd>
<dd><strong>Joined:</strong> Sat Dec 26, 2009 8:17 pm</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<div class="post bg2" id="p4050">
<div class="inner"><span class="corners-top"><span></span></span>
<div class="postbody">
<h3><a href="#p4050">Re: Cost-effectiveness of charities including existential risks</a></h3>
<p class="author"><img alt="Post" height="9" src="../styles/nexus/imageset/icon_post_target.gif" title="Post" width="11"/>by <strong><a href="../user/64.html">Brian Tomasik</a></strong> on 2011-10-16T03:55:00</p>
<div class="content"><div class="postrev" data-snap="1"><blockquote><div><cite>Recumbent wrote:</cite>But that also should give us pause when he says he thinks we only have a 50% chance of not destroying ourselves with the singularity.<br/></div></blockquote><br/>I might put the odds that we don't destroy ourselves lower, like 25%. That said, it's underspecified what "destorying ourselves" means. I'm including paperclip maximization in that category, but I'm not sure the paperclips would agree.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>I won't hazard a guess on the probability of an individual person creating self modifying artificial intelligence. But there is also a good chance that the Department of Defense is putting a ton of money into this. I'm not sure how much they would be worried about making the artificial intelligence friendly.  <img alt=":)" src="../images/smilies/icon_e_smile.gif"/> <br/></div></blockquote><br/>Yes, exactly. IMO, the likelihood that SIAI creates an AGI in the basement themselves is miniscule. Rather, they're most likely to have an impact by raising social consciousness of the issue, which will then translate into more research on the topic as well as, eventually, political impact.<br/><br/><blockquote><div><cite>Recumbent wrote:</cite>But even with my 1% probability of negative singularity</div></blockquote><br/>Yep, I don't doubt your probabilities. I'd put the likelihood of a paperclipper at, umm, maybe 15%.<br/><br/>However, it seems plausible that the paperclipper would be net good for wild animals, from a negative-leaning utilitarian stance.</div><div class="diff hidden"></div></div>
<div class="signature"></div>
</div>
<dl class="postprofile" id="profile4050">
<dt>
<a href="../user/64.html"><img alt="User avatar" height="100" src="../file/64_1317625384.jpg" width="100"/></a><br/>
<a href="../user/64.html">Brian Tomasik</a>
</dt>
<dd> </dd>
<dd><strong>Posts:</strong> 1130</dd>
<dd><strong>Joined:</strong> Tue Oct 28, 2008 3:10 am</dd>
<dd><strong>Location:</strong> USA</dd>
</dl>
<div class="back2top"><a class="top" href="#wrap" title="Top">Top</a></div>
<span class="corners-bottom"><span></span></span></div>
</div>
<hr class="divider"/>
<input type="hidden" value="20111017003656/viewtopic.php?f=25&amp;p=3958&amp;sid=9abf4018c22f74c65ed899a1ce9a45de"/><input type="hidden" value="20111216005153/viewtopic.php?f=25&amp;t=484&amp;start=20"/>
                        <hr>
                        <div class="topic-actions">
                            <div class="pagination">
                                21 posts
                            </div>
                        </div>
                        <p><a href="./viewforum.php?f=10" class="left-box left" accesskey="r">Return to General discussion</a></p>
                    </div>
                    <div id="page-footer">
                    </div>
                </div>
                <div>
                    <a id="bottom" name="bottom" accesskey="z"></a>
                </div>
            </div>
            <div class="positioncorrection-bottom"></div>
        </div>
        <div class="bottom-left"></div>
        <div class="bottom-middle"></div>
        <div class="bottom-right"></div>
    </body>
</html>
